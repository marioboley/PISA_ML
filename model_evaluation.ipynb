{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.647140</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>1.263058</td>\n",
       "      <td>0.476161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.036842                0.003132   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.088377               0.033908          0.122612   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.010827         0.270439        0.105647   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.647140            0.038226            1.263058   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.476161  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.139766</td>\n",
       "      <td>0.172878</td>\n",
       "      <td>0.133714</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.364181</td>\n",
       "      <td>0.423148</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.052019</td>\n",
       "      <td>2.506141</td>\n",
       "      <td>3.413426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.040134                0.003514   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.139766               0.172878          0.133714   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.011004         0.364181        0.423148   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.671861            0.052019            2.506141   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.413426  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.647140</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>1.263058</td>\n",
       "      <td>0.476161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.036842                0.003132   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.088377               0.033908          0.122612   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.010827         0.270439        0.105647   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.647140            0.038226            1.263058   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.476161  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.139766</td>\n",
       "      <td>0.172878</td>\n",
       "      <td>0.133714</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.364181</td>\n",
       "      <td>0.423148</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.052019</td>\n",
       "      <td>2.506141</td>\n",
       "      <td>3.413426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.040134                0.003514   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.139766               0.172878          0.133714   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.011004         0.364181        0.423148   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.671861            0.052019            2.506141   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.413426  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Individual morphology error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.sharey(ax1) ########### here to share the y axis\n",
    "\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninformed', 'informed']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Log loss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'overall_performance.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
