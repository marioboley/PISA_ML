{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    \"\"\"This function is for the actual size (cm) of plots\n",
    "    Input: \n",
    "        tuple: for example (12, 13) means 12cm, 13 cm\n",
    "    Output:\n",
    "        tuple: for python figsize\n",
    "    \"\"\"\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1133.86x283.465 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True)\n",
    "fig.set_size_inches(cm2inch(40, 10))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Average phases error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full phase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
