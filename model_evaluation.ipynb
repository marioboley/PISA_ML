{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Individual morphology error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.sharey(ax1) ########### here to share the y axis\n",
    "\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninformed', 'informed']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full phase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
