{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    \"\"\"This function is for the actual size (cm) of plots\n",
    "    Input: \n",
    "        tuple: for example (12, 13) means 12cm, 13 cm\n",
    "    Output:\n",
    "        tuple: for python figsize\n",
    "    \"\"\"\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1133.86x283.465 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True)\n",
    "fig.set_size_inches(cm2inch(40, 10))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_train_hamming loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_train_hamming loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_train_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Average phases error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full phase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
