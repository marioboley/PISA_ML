{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Average phases error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full phase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
