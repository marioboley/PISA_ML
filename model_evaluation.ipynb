{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.207675</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>0.553817</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>0.571579</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>2.245177</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>2.348206</td>\n",
       "      <td>0.409243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.647140</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>1.263048</td>\n",
       "      <td>0.476165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.056754</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.018056</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.177456</td>\n",
       "      <td>0.085135</td>\n",
       "      <td>0.229125</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.910888</td>\n",
       "      <td>0.457557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_hamming loss  std_train_hamming loss  \\\n",
       "LR                      0.201363                0.008631   \n",
       "GAM                     0.036842                0.003132   \n",
       "RuleFit                 0.005737                0.001321   \n",
       "RF                      0.000015                0.000080   \n",
       "\n",
       "         mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "LR                     0.207675               0.047621          0.553817   \n",
       "GAM                    0.088377               0.033908          0.122612   \n",
       "RuleFit                0.056754               0.029144          0.018056   \n",
       "RF                     0.065461               0.026606          0.000058   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \\\n",
       "LR              0.038090         0.571579        0.132058   \n",
       "GAM             0.010827         0.270439        0.105647   \n",
       "RuleFit         0.004359         0.177456        0.085135   \n",
       "RF              0.000319         0.199298        0.067024   \n",
       "\n",
       "         mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "LR                  2.245177            0.084801            2.348206   \n",
       "GAM                 0.647140            0.038226            1.263048   \n",
       "RuleFit             0.229125            0.015097            0.910888   \n",
       "RF                  0.243237            0.003150            1.069053   \n",
       "\n",
       "         std_test_log loss  \n",
       "LR                0.409243  \n",
       "GAM               0.476165  \n",
       "RuleFit           0.457557  \n",
       "RF                0.685669  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204002</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.199708</td>\n",
       "      <td>0.166414</td>\n",
       "      <td>0.566550</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.608891</td>\n",
       "      <td>0.447396</td>\n",
       "      <td>2.273170</td>\n",
       "      <td>0.083029</td>\n",
       "      <td>2.674861</td>\n",
       "      <td>1.793803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.040066</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.146702</td>\n",
       "      <td>0.173823</td>\n",
       "      <td>0.133519</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>0.420958</td>\n",
       "      <td>0.671179</td>\n",
       "      <td>0.051213</td>\n",
       "      <td>2.544994</td>\n",
       "      <td>3.358591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.131695</td>\n",
       "      <td>0.175832</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.302883</td>\n",
       "      <td>0.392765</td>\n",
       "      <td>0.224562</td>\n",
       "      <td>0.019692</td>\n",
       "      <td>2.153337</td>\n",
       "      <td>2.820715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.118843</td>\n",
       "      <td>0.184329</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>0.388123</td>\n",
       "      <td>0.238704</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>1.640178</td>\n",
       "      <td>1.858515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204002                0.010628   \n",
       "GAM_pcc                   0.040066                0.003470   \n",
       "RuFit_pcc                 0.005270                0.001165   \n",
       "RF_pcc                    0.000294                0.000472   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.199708               0.166414          0.566550   \n",
       "GAM_pcc                  0.146702               0.173823          0.133519   \n",
       "RuFit_pcc                0.131695               0.175832          0.016251   \n",
       "RF_pcc                   0.118843               0.184329          0.000588   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.037625         0.608891        0.447396   \n",
       "GAM_pcc           0.010856         0.376702        0.420958   \n",
       "RuFit_pcc         0.003606         0.302883        0.392765   \n",
       "RF_pcc            0.000943         0.264250        0.388123   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.273170            0.083029            2.674861   \n",
       "GAM_pcc               0.671179            0.051213            2.544994   \n",
       "RuFit_pcc             0.224562            0.019692            2.153337   \n",
       "RF_pcc                0.238704            0.003475            1.640178   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.793803  \n",
       "GAM_pcc             3.358591  \n",
       "RuFit_pcc           2.820715  \n",
       "RF_pcc              1.858515  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.207675</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>0.553817</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>0.571579</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>2.245177</td>\n",
       "      <td>0.084801</td>\n",
       "      <td>2.348206</td>\n",
       "      <td>0.409243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.647140</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>1.263048</td>\n",
       "      <td>0.476165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.056754</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.018056</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.177456</td>\n",
       "      <td>0.085135</td>\n",
       "      <td>0.229125</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>0.910888</td>\n",
       "      <td>0.457557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.201363                0.008631   \n",
       "GAM_pcc                   0.036842                0.003132   \n",
       "RuFit_pcc                 0.005737                0.001321   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.207675               0.047621          0.553817   \n",
       "GAM_pcc                  0.088377               0.033908          0.122612   \n",
       "RuFit_pcc                0.056754               0.029144          0.018056   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.038090         0.571579        0.132058   \n",
       "GAM_pcc           0.010827         0.270439        0.105647   \n",
       "RuFit_pcc         0.004359         0.177456        0.085135   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.245177            0.084801            2.348206   \n",
       "GAM_pcc               0.647140            0.038226            1.263048   \n",
       "RuFit_pcc             0.229125            0.015097            0.910888   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.409243  \n",
       "GAM_pcc             0.476165  \n",
       "RuFit_pcc           0.457557  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204002</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.199708</td>\n",
       "      <td>0.166414</td>\n",
       "      <td>0.566550</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.608891</td>\n",
       "      <td>0.447396</td>\n",
       "      <td>2.273170</td>\n",
       "      <td>0.083029</td>\n",
       "      <td>2.674861</td>\n",
       "      <td>1.793803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.040066</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.146702</td>\n",
       "      <td>0.173823</td>\n",
       "      <td>0.133519</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.376702</td>\n",
       "      <td>0.420958</td>\n",
       "      <td>0.671179</td>\n",
       "      <td>0.051213</td>\n",
       "      <td>2.544994</td>\n",
       "      <td>3.358591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.131695</td>\n",
       "      <td>0.175832</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.302883</td>\n",
       "      <td>0.392765</td>\n",
       "      <td>0.224562</td>\n",
       "      <td>0.019692</td>\n",
       "      <td>2.153337</td>\n",
       "      <td>2.820715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.118843</td>\n",
       "      <td>0.184329</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.264250</td>\n",
       "      <td>0.388123</td>\n",
       "      <td>0.238704</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>1.640178</td>\n",
       "      <td>1.858515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204002                0.010628   \n",
       "GAM_pcc                   0.040066                0.003470   \n",
       "RuFit_pcc                 0.005270                0.001165   \n",
       "RF_pcc                    0.000294                0.000472   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.199708               0.166414          0.566550   \n",
       "GAM_pcc                  0.146702               0.173823          0.133519   \n",
       "RuFit_pcc                0.131695               0.175832          0.016251   \n",
       "RF_pcc                   0.118843               0.184329          0.000588   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.037625         0.608891        0.447396   \n",
       "GAM_pcc           0.010856         0.376702        0.420958   \n",
       "RuFit_pcc         0.003606         0.302883        0.392765   \n",
       "RF_pcc            0.000943         0.264250        0.388123   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.273170            0.083029            2.674861   \n",
       "GAM_pcc               0.671179            0.051213            2.544994   \n",
       "RuFit_pcc             0.224562            0.019692            2.153337   \n",
       "RF_pcc                0.238704            0.003475            1.640178   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.793803  \n",
       "GAM_pcc             3.358591  \n",
       "RuFit_pcc           2.820715  \n",
       "RF_pcc              1.858515  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Individual morphology error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.sharey(ax1) ########### here to share the y axis\n",
    "\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninformed', 'informed']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Log loss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'latest_overall_performance.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphere</th>\n",
       "      <th>worm</th>\n",
       "      <th>vesicle</th>\n",
       "      <th>other</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sphere   worm vesicle  other counts\n",
       "0   0.241  0.414   0.345    0.0   22.0\n",
       "1     1.0    0.0     0.0    0.0   16.0\n",
       "2   0.938    0.0     0.0  0.062   16.0\n",
       "3     0.5  0.312   0.188    0.0   15.0\n",
       "4   0.857    0.0     0.0  0.143   14.0\n",
       "5     1.0    0.0     0.0    0.0   11.0\n",
       "6     1.0    0.0     0.0    0.0    8.0\n",
       "7   0.875    0.0     0.0  0.125    8.0\n",
       "8     1.0    0.0     0.0    0.0    7.0\n",
       "9   0.222  0.556   0.222    0.0    7.0\n",
       "10    nan    nan     nan    nan    7.0\n",
       "11    1.0    0.0     0.0    0.0    7.0\n",
       "12    1.0    0.0     0.0    0.0    6.0\n",
       "13  0.667    0.0     0.0  0.333    6.0\n",
       "14    1.0    0.0     0.0    0.0    6.0\n",
       "15    1.0    0.0     0.0    0.0    6.0\n",
       "16  0.167  0.667   0.167    0.0    5.0\n",
       "17    0.5  0.333   0.167    0.0    3.0\n",
       "18    0.0    0.0     0.0    1.0    2.0\n",
       "19    1.0    0.0     0.0    0.0    2.0\n",
       "20    0.0    0.0     0.0    1.0    2.0\n",
       "21    0.0    0.0     1.0    0.0    1.0\n",
       "22    0.0    0.0     1.0    0.0    1.0\n",
       "23    0.0    0.0     0.0    1.0    1.0\n",
       "24    0.0    1.0     0.0    0.0    1.0\n",
       "25    0.0    1.0     0.0    0.0    1.0\n",
       "26    0.0    1.0     0.0    0.0    1.0\n",
       "27    0.0    1.0     0.0    0.0    1.0\n",
       "28    0.0    1.0     0.0    0.0    1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrapolation hold out distribution\n",
    "\n",
    "from modules.experiments import GroupKFoldSpecial\n",
    "import data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sphere':[], 'worm': [], 'vesicle': [], 'other':[], 'counts':[]})\n",
    "kf = GroupKFoldSpecial(len(set(data.comp_ids)), size=22)\n",
    "for train_indx, test_indx in kf.split(data.x1, data.y.replace(-1, 0), groups=data.comp_ids.array):\n",
    "    temp = pd.DataFrame(data.y.iloc[test_indx,].sum()/sum(data.y.iloc[test_indx,].sum())).T\n",
    "    temp['counts'] = int(len(test_indx))\n",
    "    df = pd.concat([df, temp], ignore_index=True)\n",
    "df = df.round(3)\n",
    "df = df.astype(str)\n",
    "df\n",
    "# df.sphere = df.apply(lambda x: round(x.sphere) if x.sphere == 0 or x.sphere == 1 else x.sphere, axis=1)\n",
    "# df.loc[1, 'sphere'] = 0.99\n",
    "# df\n",
    "# df.round(3)#(0.000000, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphere</th>\n",
       "      <th>worm</th>\n",
       "      <th>vesicle</th>\n",
       "      <th>other</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sphere   worm vesicle  other counts\n",
       "0   0.241  0.414   0.345    0.0   22.0\n",
       "1     1.0    0.0     0.0    0.0   16.0\n",
       "2   0.938    0.0     0.0  0.062   16.0\n",
       "3     0.5  0.312   0.188    0.0   15.0\n",
       "4   0.857    0.0     0.0  0.143   14.0\n",
       "5     1.0    0.0     0.0    0.0   11.0\n",
       "6     1.0    0.0     0.0    0.0    8.0\n",
       "7   0.875    0.0     0.0  0.125    8.0\n",
       "8     1.0    0.0     0.0    0.0    7.0\n",
       "9   0.222  0.556   0.222    0.0    7.0\n",
       "10    nan    nan     nan    nan    7.0\n",
       "11    1.0    0.0     0.0    0.0    7.0\n",
       "12    1.0    0.0     0.0    0.0    6.0\n",
       "13  0.667    0.0     0.0  0.333    6.0\n",
       "14    1.0    0.0     0.0    0.0    6.0\n",
       "15    1.0    0.0     0.0    0.0    6.0\n",
       "16  0.167  0.667   0.167    0.0    5.0\n",
       "17    0.5  0.333   0.167    0.0    3.0\n",
       "18    0.0    0.0     0.0    1.0    2.0\n",
       "19    1.0    0.0     0.0    0.0    2.0\n",
       "20    0.0    0.0     0.0    1.0    2.0\n",
       "21    0.0    0.0     1.0    0.0    1.0\n",
       "22    0.0    0.0     1.0    0.0    1.0\n",
       "23    0.0    0.0     0.0    1.0    1.0\n",
       "24    0.0    1.0     0.0    0.0    1.0\n",
       "25    0.0    1.0     0.0    0.0    1.0\n",
       "26    0.0    1.0     0.0    0.0    1.0\n",
       "27    0.0    1.0     0.0    0.0    1.0\n",
       "28    0.0    1.0     0.0    0.0    1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrapolation hold out distribution\n",
    "\n",
    "from modules.experiments import GroupKFoldSpecial\n",
    "import data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sphere':[], 'worm': [], 'vesicle': [], 'other':[], 'counts':[]})\n",
    "kf = GroupKFoldSpecial(len(set(data.comp_ids)), size=22)\n",
    "for train_indx, test_indx in kf.split(data.x1, data.y.replace(-1, 0), groups=data.comp_ids.array):\n",
    "    temp = pd.DataFrame(data.y.iloc[test_indx,].sum()/sum(data.y.iloc[test_indx,].sum())).T\n",
    "    temp['counts'] = int(len(test_indx))\n",
    "    df = pd.concat([df, temp], ignore_index=True)\n",
    "df = df.round(3)\n",
    "df = df.astype(str)\n",
    "df\n",
    "# df.sphere = df.apply(lambda x: round(x.sphere) if x.sphere == 0 or x.sphere == 1 else x.sphere, axis=1)\n",
    "# df.loc[1, 'sphere'] = 0.99\n",
    "# df\n",
    "# df.round(3)#(0.000000, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphere</th>\n",
       "      <th>worm</th>\n",
       "      <th>vesicle</th>\n",
       "      <th>other</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.241</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sphere   worm vesicle  other counts\n",
       "0     nan    nan     nan    nan    7.0\n",
       "1     1.0    0.0     0.0    0.0   16.0\n",
       "2     1.0    0.0     0.0    0.0   11.0\n",
       "3     1.0    0.0     0.0    0.0    8.0\n",
       "4     1.0    0.0     0.0    0.0    7.0\n",
       "5     1.0    0.0     0.0    0.0    7.0\n",
       "6     1.0    0.0     0.0    0.0    6.0\n",
       "7     1.0    0.0     0.0    0.0    6.0\n",
       "8     1.0    0.0     0.0    0.0    6.0\n",
       "9     1.0    0.0     0.0    0.0    2.0\n",
       "10    0.0    1.0     0.0    0.0    1.0\n",
       "11    0.0    1.0     0.0    0.0    1.0\n",
       "12    0.0    1.0     0.0    0.0    1.0\n",
       "13    0.0    1.0     0.0    0.0    1.0\n",
       "14    0.0    1.0     0.0    0.0    1.0\n",
       "15    0.0    0.0     1.0    0.0    1.0\n",
       "16    0.0    0.0     1.0    0.0    1.0\n",
       "17    0.0    0.0     0.0    1.0    1.0\n",
       "18    0.0    0.0     0.0    1.0    2.0\n",
       "19    0.0    0.0     0.0    1.0    2.0\n",
       "20  0.241  0.414   0.345    0.0   22.0\n",
       "21  0.938    0.0     0.0  0.062   16.0\n",
       "22    0.5  0.312   0.188    0.0   15.0\n",
       "23  0.857    0.0     0.0  0.143   14.0\n",
       "24  0.875    0.0     0.0  0.125    8.0\n",
       "25  0.222  0.556   0.222    0.0    7.0\n",
       "26  0.667    0.0     0.0  0.333    6.0\n",
       "27  0.167  0.667   0.167    0.0    5.0\n",
       "28    0.5  0.333   0.167    0.0    3.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reindex([10, 1, 5, 6, 8, 11, 12, 14, 15, 19, 24, 25, 26, 27, 28, 21, 22, 23, 18, 20, 0, 2, 3, 4, 7, 9, 13, 16, 17]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corona_GMA, core_HEMA has no morphology"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1304dd6425b372aa8285a68c11c3f25cfbbc0c3931e5f36be2c30c57a28c8b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
