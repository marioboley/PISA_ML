{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Average phases error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'inter_base']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full phase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
