{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    \"\"\"This function is for the actual size (cm) of plots\n",
    "    Input: \n",
    "        tuple: for example (12, 13) means 12cm, 13 cm\n",
    "    Output:\n",
    "        tuple: for python figsize\n",
    "    \"\"\"\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.074912</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.228333</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.403941</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>1.093641</td>\n",
       "      <td>0.498897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.069781</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.216404</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>1.252573</td>\n",
       "      <td>0.628597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.017693                0.003309   \n",
       "RuFit_pcc                 0.004879                0.002435   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.074912               0.032162          0.059179   \n",
       "RuFit_pcc                0.069781               0.028317          0.015262   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.011989         0.228333        0.092471   \n",
       "RuFit_pcc         0.008016         0.216404        0.078707   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.403941            0.040225            1.093641   \n",
       "RuFit_pcc             0.157948            0.045570            1.252573   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.498897  \n",
       "RuFit_pcc           0.628597  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.154716</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.377425</td>\n",
       "      <td>0.415537</td>\n",
       "      <td>0.414240</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>2.538467</td>\n",
       "      <td>3.494145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.189940</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.311302</td>\n",
       "      <td>0.410696</td>\n",
       "      <td>0.168864</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>2.922825</td>\n",
       "      <td>4.432923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.019174                0.002590   \n",
       "RuFit_pcc                 0.005574                0.002911   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.154716               0.183469          0.065718   \n",
       "RuFit_pcc                0.135766               0.189940          0.018276   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.009194         0.377425        0.415537   \n",
       "RuFit_pcc         0.010117         0.311302        0.410696   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.414240            0.035148            2.538467   \n",
       "RuFit_pcc             0.168864            0.063884            2.922825   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.494145  \n",
       "RuFit_pcc           4.432923  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1133.86x283.465 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True)\n",
    "fig.set_size_inches(cm2inch(40, 10))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_train_hamming loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_train_hamming loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_train_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Average phases error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss, unreal_extra_hamming_loss]\n",
    "avg_error_name = ['uninfo', 'inter_base', 'extra_base']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error, unreal_extra_full_info_error]\n",
    "inter_error_name = ['uninfo', 'inter_base', 'extra_base']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss, real_extra_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'inter_base', 'extra_base']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full phase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
