{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.647140</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>1.263058</td>\n",
       "      <td>0.476161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.036842                0.003132   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.088377               0.033908          0.122612   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.010827         0.270439        0.105647   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.647140            0.038226            1.263058   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.476161  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.139766</td>\n",
       "      <td>0.172878</td>\n",
       "      <td>0.133714</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.364181</td>\n",
       "      <td>0.423148</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.052019</td>\n",
       "      <td>2.506141</td>\n",
       "      <td>3.413426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.040134                0.003514   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.139766               0.172878          0.133714   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.011004         0.364181        0.423148   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.671861            0.052019            2.506141   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.413426  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6554775150876018 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7401933665227551\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.556380</td>\n",
       "      <td>0.043451</td>\n",
       "      <td>0.588246</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>2.251545</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>2.359290</td>\n",
       "      <td>0.414337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.105647</td>\n",
       "      <td>0.647140</td>\n",
       "      <td>0.038226</td>\n",
       "      <td>1.263058</td>\n",
       "      <td>0.476161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.207544</td>\n",
       "      <td>0.090273</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>1.047064</td>\n",
       "      <td>0.429802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.199298</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.243237</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>1.069053</td>\n",
       "      <td>0.685669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.202688                0.010509   \n",
       "GAM_pcc                   0.036842                0.003132   \n",
       "RuFit_pcc                 0.013761                0.002088   \n",
       "RF_pcc                    0.000015                0.000080   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.215175               0.055519          0.556380   \n",
       "GAM_pcc                  0.088377               0.033908          0.122612   \n",
       "RuFit_pcc                0.066754               0.033378          0.044968   \n",
       "RF_pcc                   0.065461               0.026606          0.000058   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.043451         0.588246        0.146107   \n",
       "GAM_pcc           0.010827         0.270439        0.105647   \n",
       "RuFit_pcc         0.005734         0.207544        0.090273   \n",
       "RF_pcc            0.000319         0.199298        0.067024   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.251545            0.100844            2.359290   \n",
       "GAM_pcc               0.647140            0.038226            1.263058   \n",
       "RuFit_pcc             0.323129            0.010737            1.047064   \n",
       "RF_pcc                0.243237            0.003150            1.069053   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              0.414337  \n",
       "GAM_pcc             0.476161  \n",
       "RuFit_pcc           0.429802  \n",
       "RF_pcc              0.685669  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.204733</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.134576</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.616143</td>\n",
       "      <td>0.435963</td>\n",
       "      <td>2.277663</td>\n",
       "      <td>0.099304</td>\n",
       "      <td>2.644404</td>\n",
       "      <td>1.741969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.139766</td>\n",
       "      <td>0.172878</td>\n",
       "      <td>0.133714</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.364181</td>\n",
       "      <td>0.423148</td>\n",
       "      <td>0.671861</td>\n",
       "      <td>0.052019</td>\n",
       "      <td>2.506141</td>\n",
       "      <td>3.413426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.013480</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.108725</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>0.391676</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>1.939785</td>\n",
       "      <td>2.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.382492</td>\n",
       "      <td>0.238811</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.564812</td>\n",
       "      <td>1.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.204733                0.011155   \n",
       "GAM_pcc                   0.040134                0.003514   \n",
       "RuFit_pcc                 0.013480                0.001450   \n",
       "RF_pcc                    0.000305                0.000477   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.182432               0.134576          0.567365   \n",
       "GAM_pcc                  0.139766               0.172878          0.133714   \n",
       "RuFit_pcc                0.108725               0.143921          0.045264   \n",
       "RF_pcc                   0.108071               0.178174          0.000609   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.041419         0.616143        0.435963   \n",
       "GAM_pcc           0.011004         0.364181        0.423148   \n",
       "RuFit_pcc         0.004241         0.312950        0.391676   \n",
       "RF_pcc            0.000953         0.246090        0.382492   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.277663            0.099304            2.644404   \n",
       "GAM_pcc               0.671861            0.052019            2.506141   \n",
       "RuFit_pcc             0.319397            0.007212            1.939785   \n",
       "RF_pcc                0.238811            0.003490            1.564812   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.741969  \n",
       "GAM_pcc             3.413426  \n",
       "RuFit_pcc           2.700429  \n",
       "RF_pcc              1.846939  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Individual morphology error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.sharey(ax1) ########### here to share the y axis\n",
    "\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninformed', 'informed']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Log loss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from common import OUTPUTPATH\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'Performance_plot.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
