{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.207029</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.217193</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>0.571414</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.586579</td>\n",
       "      <td>0.142673</td>\n",
       "      <td>2.287592</td>\n",
       "      <td>0.068544</td>\n",
       "      <td>2.408361</td>\n",
       "      <td>0.415231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>0.036325</td>\n",
       "      <td>0.122728</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.113918</td>\n",
       "      <td>0.657340</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>1.289729</td>\n",
       "      <td>0.474532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.071864</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.216228</td>\n",
       "      <td>0.090593</td>\n",
       "      <td>0.320184</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>1.015118</td>\n",
       "      <td>0.441967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.067566</td>\n",
       "      <td>0.028430</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.207807</td>\n",
       "      <td>0.072806</td>\n",
       "      <td>0.245469</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>1.152941</td>\n",
       "      <td>0.806021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_hamming loss  std_train_hamming loss  \\\n",
       "LR                      0.207029                0.007364   \n",
       "GAM                     0.036958                0.003932   \n",
       "RuleFit                 0.013077                0.001704   \n",
       "RF                      0.000015                0.000080   \n",
       "\n",
       "         mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "LR                     0.217193               0.053799          0.571414   \n",
       "GAM                    0.091776               0.036325          0.122728   \n",
       "RuleFit                0.071864               0.031709          0.042579   \n",
       "RF                     0.067566               0.028430          0.000058   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \\\n",
       "LR              0.028748         0.586579        0.142673   \n",
       "GAM             0.012920         0.278947        0.113918   \n",
       "RuleFit         0.004480         0.216228        0.090593   \n",
       "RF              0.000319         0.207807        0.072806   \n",
       "\n",
       "         mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "LR                  2.287592            0.068544            2.408361   \n",
       "GAM                 0.657340            0.052355            1.289729   \n",
       "RuleFit             0.320184            0.017854            1.015118   \n",
       "RF                  0.245469            0.003132            1.152941   \n",
       "\n",
       "         std_test_log loss  \n",
       "LR                0.415231  \n",
       "GAM               0.474532  \n",
       "RuleFit           0.441967  \n",
       "RF                0.806021  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.205310</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.193837</td>\n",
       "      <td>0.164797</td>\n",
       "      <td>0.568321</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>0.580874</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>2.279832</td>\n",
       "      <td>0.090288</td>\n",
       "      <td>2.692989</td>\n",
       "      <td>1.879043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.040741</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.146785</td>\n",
       "      <td>0.181733</td>\n",
       "      <td>0.135459</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.363659</td>\n",
       "      <td>0.420920</td>\n",
       "      <td>0.698547</td>\n",
       "      <td>0.048496</td>\n",
       "      <td>2.461090</td>\n",
       "      <td>3.041846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.155976</td>\n",
       "      <td>0.188312</td>\n",
       "      <td>0.041388</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.370475</td>\n",
       "      <td>0.424662</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>2.402128</td>\n",
       "      <td>3.151199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.116324</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.266713</td>\n",
       "      <td>0.389427</td>\n",
       "      <td>0.241264</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>1.589073</td>\n",
       "      <td>1.722327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_hamming loss  std_train_hamming loss  \\\n",
       "LR                      0.205310                0.010114   \n",
       "GAM                     0.040741                0.002913   \n",
       "RuleFit                 0.013010                0.001818   \n",
       "RF                      0.000294                0.000472   \n",
       "\n",
       "         mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "LR                     0.193837               0.164797          0.568321   \n",
       "GAM                    0.146785               0.181733          0.135459   \n",
       "RuleFit                0.155976               0.188312          0.041388   \n",
       "RF                     0.116324               0.180780          0.000588   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \\\n",
       "LR              0.038811         0.580874        0.447158   \n",
       "GAM             0.009794         0.363659        0.420920   \n",
       "RuleFit         0.004876         0.370475        0.424662   \n",
       "RF              0.000943         0.266713        0.389427   \n",
       "\n",
       "         mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "LR                  2.279832            0.090288            2.692989   \n",
       "GAM                 0.698547            0.048496            2.461090   \n",
       "RuleFit             0.323404            0.014918            2.402128   \n",
       "RF                  0.241264            0.003835            1.589073   \n",
       "\n",
       "         std_test_log loss  \n",
       "LR                1.879043  \n",
       "GAM               3.041846  \n",
       "RuleFit           3.151199  \n",
       "RF                1.722327  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2778716216216216 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.539959783214337\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7397973042571211\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.6603067710306796 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7397973042571211\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.207029</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.217193</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>0.571414</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.586579</td>\n",
       "      <td>0.142673</td>\n",
       "      <td>2.287592</td>\n",
       "      <td>0.068544</td>\n",
       "      <td>2.408361</td>\n",
       "      <td>0.415231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.091776</td>\n",
       "      <td>0.036325</td>\n",
       "      <td>0.122728</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.113918</td>\n",
       "      <td>0.657340</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>1.289729</td>\n",
       "      <td>0.474532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.071864</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.216228</td>\n",
       "      <td>0.090593</td>\n",
       "      <td>0.320184</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>1.015118</td>\n",
       "      <td>0.441967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.067566</td>\n",
       "      <td>0.028430</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.207807</td>\n",
       "      <td>0.072806</td>\n",
       "      <td>0.245469</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>1.152941</td>\n",
       "      <td>0.806021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_hamming loss  std_train_hamming loss  \\\n",
       "LR                      0.207029                0.007364   \n",
       "GAM                     0.036958                0.003932   \n",
       "RuleFit                 0.013077                0.001704   \n",
       "RF                      0.000015                0.000080   \n",
       "\n",
       "         mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "LR                     0.217193               0.053799          0.571414   \n",
       "GAM                    0.091776               0.036325          0.122728   \n",
       "RuleFit                0.071864               0.031709          0.042579   \n",
       "RF                     0.067566               0.028430          0.000058   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \\\n",
       "LR              0.028748         0.586579        0.142673   \n",
       "GAM             0.012920         0.278947        0.113918   \n",
       "RuleFit         0.004480         0.216228        0.090593   \n",
       "RF              0.000319         0.207807        0.072806   \n",
       "\n",
       "         mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "LR                  2.287592            0.068544            2.408361   \n",
       "GAM                 0.657340            0.052355            1.289729   \n",
       "RuleFit             0.320184            0.017854            1.015118   \n",
       "RF                  0.245469            0.003132            1.152941   \n",
       "\n",
       "         std_test_log loss  \n",
       "LR                0.415231  \n",
       "GAM               0.474532  \n",
       "RuleFit           0.441967  \n",
       "RF                0.806021  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.205310</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.193837</td>\n",
       "      <td>0.164797</td>\n",
       "      <td>0.568321</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>0.580874</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>2.279832</td>\n",
       "      <td>0.090288</td>\n",
       "      <td>2.692989</td>\n",
       "      <td>1.879043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.040741</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.146785</td>\n",
       "      <td>0.181733</td>\n",
       "      <td>0.135459</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.363659</td>\n",
       "      <td>0.420920</td>\n",
       "      <td>0.698547</td>\n",
       "      <td>0.048496</td>\n",
       "      <td>2.461090</td>\n",
       "      <td>3.041846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.155976</td>\n",
       "      <td>0.188312</td>\n",
       "      <td>0.041388</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.370475</td>\n",
       "      <td>0.424662</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>2.402128</td>\n",
       "      <td>3.151199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.116324</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.266713</td>\n",
       "      <td>0.389427</td>\n",
       "      <td>0.241264</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>1.589073</td>\n",
       "      <td>1.722327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_hamming loss  std_train_hamming loss  \\\n",
       "LR                      0.205310                0.010114   \n",
       "GAM                     0.040741                0.002913   \n",
       "RuleFit                 0.013010                0.001818   \n",
       "RF                      0.000294                0.000472   \n",
       "\n",
       "         mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "LR                     0.193837               0.164797          0.568321   \n",
       "GAM                    0.146785               0.181733          0.135459   \n",
       "RuleFit                0.155976               0.188312          0.041388   \n",
       "RF                     0.116324               0.180780          0.000588   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \\\n",
       "LR              0.038811         0.580874        0.447158   \n",
       "GAM             0.009794         0.363659        0.420920   \n",
       "RuleFit         0.004876         0.370475        0.424662   \n",
       "RF              0.000943         0.266713        0.389427   \n",
       "\n",
       "         mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "LR                  2.279832            0.090288            2.692989   \n",
       "GAM                 0.698547            0.048496            2.461090   \n",
       "RuleFit             0.323404            0.014918            2.402128   \n",
       "RF                  0.241264            0.003835            1.589073   \n",
       "\n",
       "         std_test_log loss  \n",
       "LR                1.879043  \n",
       "GAM               3.041846  \n",
       "RuleFit           3.151199  \n",
       "RF                1.722327  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Individual morphology error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.sharey(ax1) ########### here to share the y axis\n",
    "\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninformed', 'informed']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Log loss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'latest_overall_performance.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphere</th>\n",
       "      <th>worm</th>\n",
       "      <th>vesicle</th>\n",
       "      <th>other</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sphere   worm vesicle  other counts\n",
       "0   0.333  0.364   0.303    0.0   22.0\n",
       "1     1.0    0.0     0.0    0.0   16.0\n",
       "2   0.938    0.0     0.0  0.062   16.0\n",
       "3     0.5  0.312   0.188    0.0   15.0\n",
       "4   0.857    0.0     0.0  0.143   14.0\n",
       "5     1.0    0.0     0.0    0.0   11.0\n",
       "6     1.0    0.0     0.0    0.0    8.0\n",
       "7   0.875    0.0     0.0  0.125    8.0\n",
       "8     1.0    0.0     0.0    0.0    7.0\n",
       "9   0.222  0.556   0.222    0.0    7.0\n",
       "10    nan    nan     nan    nan    7.0\n",
       "11    1.0    0.0     0.0    0.0    7.0\n",
       "12    1.0    0.0     0.0    0.0    6.0\n",
       "13  0.667    0.0     0.0  0.333    6.0\n",
       "14    1.0    0.0     0.0    0.0    6.0\n",
       "15    1.0    0.0     0.0    0.0    6.0\n",
       "16  0.167  0.667   0.167    0.0    5.0\n",
       "17    0.5  0.333   0.167    0.0    3.0\n",
       "18    0.0    0.0     0.0    1.0    2.0\n",
       "19    1.0    0.0     0.0    0.0    2.0\n",
       "20    0.0    0.0     0.0    1.0    2.0\n",
       "21    0.0    0.0     1.0    0.0    1.0\n",
       "22    0.0    0.0     1.0    0.0    1.0\n",
       "23    0.0    0.0     0.0    1.0    1.0\n",
       "24    0.0    1.0     0.0    0.0    1.0\n",
       "25    0.0    1.0     0.0    0.0    1.0\n",
       "26    0.0    1.0     0.0    0.0    1.0\n",
       "27    0.0    1.0     0.0    0.0    1.0\n",
       "28    0.0    1.0     0.0    0.0    1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrapolation hold out distribution\n",
    "\n",
    "from modules.experiments import GroupKFoldSpecial\n",
    "import data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sphere':[], 'worm': [], 'vesicle': [], 'other':[], 'counts':[]})\n",
    "kf = GroupKFoldSpecial(len(set(data.comp_ids)), size=22)\n",
    "for train_indx, test_indx in kf.split(data.x1, data.y.replace(-1, 0), groups=data.comp_ids.array):\n",
    "    temp = pd.DataFrame(data.y.iloc[test_indx,].sum()/sum(data.y.iloc[test_indx,].sum())).T\n",
    "    temp['counts'] = int(len(test_indx))\n",
    "    df = pd.concat([df, temp], ignore_index=True)\n",
    "df = df.round(3)\n",
    "df = df.astype(str)\n",
    "df\n",
    "# df.sphere = df.apply(lambda x: round(x.sphere) if x.sphere == 0 or x.sphere == 1 else x.sphere, axis=1)\n",
    "# df.loc[1, 'sphere'] = 0.99\n",
    "# df\n",
    "# df.round(3)#(0.000000, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphere</th>\n",
       "      <th>worm</th>\n",
       "      <th>vesicle</th>\n",
       "      <th>other</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sphere   worm vesicle  other counts\n",
       "0   0.333  0.364   0.303    0.0   22.0\n",
       "1     1.0    0.0     0.0    0.0   16.0\n",
       "2   0.938    0.0     0.0  0.062   16.0\n",
       "3     0.5  0.312   0.188    0.0   15.0\n",
       "4   0.857    0.0     0.0  0.143   14.0\n",
       "5     1.0    0.0     0.0    0.0   11.0\n",
       "6     1.0    0.0     0.0    0.0    8.0\n",
       "7   0.875    0.0     0.0  0.125    8.0\n",
       "8     1.0    0.0     0.0    0.0    7.0\n",
       "9   0.222  0.556   0.222    0.0    7.0\n",
       "10    nan    nan     nan    nan    7.0\n",
       "11    1.0    0.0     0.0    0.0    7.0\n",
       "12    1.0    0.0     0.0    0.0    6.0\n",
       "13  0.667    0.0     0.0  0.333    6.0\n",
       "14    1.0    0.0     0.0    0.0    6.0\n",
       "15    1.0    0.0     0.0    0.0    6.0\n",
       "16  0.167  0.667   0.167    0.0    5.0\n",
       "17    0.5  0.333   0.167    0.0    3.0\n",
       "18    0.0    0.0     0.0    1.0    2.0\n",
       "19    1.0    0.0     0.0    0.0    2.0\n",
       "20    0.0    0.0     0.0    1.0    2.0\n",
       "21    0.0    0.0     1.0    0.0    1.0\n",
       "22    0.0    0.0     1.0    0.0    1.0\n",
       "23    0.0    0.0     0.0    1.0    1.0\n",
       "24    0.0    1.0     0.0    0.0    1.0\n",
       "25    0.0    1.0     0.0    0.0    1.0\n",
       "26    0.0    1.0     0.0    0.0    1.0\n",
       "27    0.0    1.0     0.0    0.0    1.0\n",
       "28    0.0    1.0     0.0    0.0    1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrapolation hold out distribution\n",
    "\n",
    "from modules.experiments import GroupKFoldSpecial\n",
    "import data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'sphere':[], 'worm': [], 'vesicle': [], 'other':[], 'counts':[]})\n",
    "kf = GroupKFoldSpecial(len(set(data.comp_ids)), size=22)\n",
    "for train_indx, test_indx in kf.split(data.x1, data.y.replace(-1, 0), groups=data.comp_ids.array):\n",
    "    temp = pd.DataFrame(data.y.iloc[test_indx,].sum()/sum(data.y.iloc[test_indx,].sum())).T\n",
    "    temp['counts'] = int(len(test_indx))\n",
    "    df = pd.concat([df, temp], ignore_index=True)\n",
    "df = df.round(3)\n",
    "df = df.astype(str)\n",
    "df\n",
    "# df.sphere = df.apply(lambda x: round(x.sphere) if x.sphere == 0 or x.sphere == 1 else x.sphere, axis=1)\n",
    "# df.loc[1, 'sphere'] = 0.99\n",
    "# df\n",
    "# df.round(3)#(0.000000, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sphere</th>\n",
       "      <th>worm</th>\n",
       "      <th>vesicle</th>\n",
       "      <th>other</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sphere   worm vesicle  other counts\n",
       "0     nan    nan     nan    nan    7.0\n",
       "1     1.0    0.0     0.0    0.0   16.0\n",
       "2     1.0    0.0     0.0    0.0   11.0\n",
       "3     1.0    0.0     0.0    0.0    8.0\n",
       "4     1.0    0.0     0.0    0.0    7.0\n",
       "5     1.0    0.0     0.0    0.0    7.0\n",
       "6     1.0    0.0     0.0    0.0    6.0\n",
       "7     1.0    0.0     0.0    0.0    6.0\n",
       "8     1.0    0.0     0.0    0.0    6.0\n",
       "9     1.0    0.0     0.0    0.0    2.0\n",
       "10    0.0    1.0     0.0    0.0    1.0\n",
       "11    0.0    1.0     0.0    0.0    1.0\n",
       "12    0.0    1.0     0.0    0.0    1.0\n",
       "13    0.0    1.0     0.0    0.0    1.0\n",
       "14    0.0    1.0     0.0    0.0    1.0\n",
       "15    0.0    0.0     1.0    0.0    1.0\n",
       "16    0.0    0.0     1.0    0.0    1.0\n",
       "17    0.0    0.0     0.0    1.0    1.0\n",
       "18    0.0    0.0     0.0    1.0    2.0\n",
       "19    0.0    0.0     0.0    1.0    2.0\n",
       "20  0.333  0.364   0.303    0.0   22.0\n",
       "21  0.938    0.0     0.0  0.062   16.0\n",
       "22    0.5  0.312   0.188    0.0   15.0\n",
       "23  0.857    0.0     0.0  0.143   14.0\n",
       "24  0.875    0.0     0.0  0.125    8.0\n",
       "25  0.222  0.556   0.222    0.0    7.0\n",
       "26  0.667    0.0     0.0  0.333    6.0\n",
       "27  0.167  0.667   0.167    0.0    5.0\n",
       "28    0.5  0.333   0.167    0.0    3.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reindex([10, 1, 5, 6, 8, 11, 12, 14, 15, 19, 24, 25, 26, 27, 28, 21, 22, 23, 18, 20, 0, 2, 3, 4, 7, 9, 13, 16, 17]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corona_GMA, core_HEMA has no morphology"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pisa_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd6b87b1d9db1ce915ee764793ba7ec2dd8e8c821299e2856d765be01bc13f44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
