{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for extrapolation version for full phase prediction in MileStone1.\n",
    "1. setups: corona_GluMA==1 & core_HPMA == 1 as our test data\n",
    "2. Use 30 K-Fold CV to run the model. No test data will be included in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data1 as data\n",
    "# import random\n",
    "from common import *\n",
    "from rules import *\n",
    "from realkd.patch import RuleFit\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full phase prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from multilabel import BinaryRelevanceClassifier, ProbabilisticClassifierChain\n",
    "from gam import LogisticGAM\n",
    "\n",
    "STATE = np.random.RandomState(seed=1000)\n",
    "\n",
    "lr = LogisticRegressionCV(penalty='l1', solver='saga', random_state=STATE)\n",
    "lr_ind = BinaryRelevanceClassifier(lr)\n",
    "lr_chain = ClassifierChain(lr, order=[0, 1, 2])\n",
    "lr_pcc = ProbabilisticClassifierChain(lr) \n",
    "\n",
    "# gams not fixed, remove this part.\n",
    "# gam_ind = BinaryRelevanceClassifier(LogisticGAM(lam=20.0, max_iter=250))\n",
    "# gam_chain = ClassifierChain(LogisticGAM(lam=20.0, max_iter=250))\n",
    "# gam_pcc = ProbabilisticClassifierChain(LogisticGAM(lam=20.0, max_iter=250)) \n",
    "\n",
    "rf = RandomForestClassifier(random_state=STATE, min_samples_leaf=1, n_estimators=100)\n",
    "rf_ind = BinaryRelevanceClassifier(rf)\n",
    "rf_chain = ClassifierChain(rf, order=[0, 2, 1])\n",
    "rf_pcc = ProbabilisticClassifierChain(rf)\n",
    "\n",
    "# Rulefit\n",
    "rufit_pcc = RuleFitWrapper()\n",
    "\n",
    "full_estimators = [lr_ind, lr_pcc, rf_ind, rf_pcc, rufit_pcc]\n",
    "full_names = ['LR_ind', 'LR_pcc', 'RF_ind', 'RF_pcc', 'rufit_pcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with 30 repetitions\n",
      "======================================\n",
      "***"
     ]
    }
   ],
   "source": [
    "from common import Experiment, LogLikelihoodEvaluator\n",
    "from sklearn.model_selection import KFold\n",
    "GluMA_HPMA = data.x[(data.x.corona_GluMA==1) & (data.x.core_HPMA == 1)].index.tolist()\n",
    "extrapolation = Experiment(full_estimators, \n",
    "                    full_names,\n",
    "                    KFold(30, shuffle=True, random_state=STATE),\n",
    "                    data.x1, data.y.replace(-1.0, 0.0),\n",
    "                    groups=data.comp_ids.array, \n",
    "                    evaluators=['accuracy', LogLikelihoodEvaluator(2, neg=True)],\n",
    "                    verbose=True, extrapolation_index = GluMA_HPMA).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following code under \"2.6 GHz 6-Core Intel Core i7\" runs ~5 hours. You can simply use saved result to re-run the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('corona_GluMA_core_HPMA.pkl', 'wb') as f:   \n",
    "    pickle.dump(extrapolation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# cur_save=open('./' + 'extra_30folder_SEL' + '.p', 'rb')\n",
    "# extrapolation = pickle.load(cur_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)\n",
    "    \n",
    "df = extrapolation.summary()\n",
    "df['mean_train_error'] = 1- df['mean_train_accuracy']\n",
    "df['std_train_error'] = df['std_train_accuracy']\n",
    "df['mean_test_error'] = 1- df['mean_test_accuracy']\n",
    "df['std_test_error'] = df['std_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrapolation.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Baseline\n",
    "\n",
    "* __Logloss__   \n",
    "For a single sample with true label $y \\in \\{0,1\\}$ and a probability estimate $p=P(y=1)$, the log loss is:\n",
    "  \n",
    "$$L = -(y\\log(p) + (1-y)\\log(1-p))$$.\n",
    "\n",
    "* __Error Rate__\n",
    "For a sample of $n$ observations, the probability of $k$ unique observation is $\\{p_1, p_2, \\dots, p_k\\}$. The error rate is:\n",
    "\n",
    "$$\n",
    "E_{rr} = 1 - argmax \\{p_i: p_i \\in \\{p_1, \\dots, p_k\\}\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base line\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True) \n",
    "prob = cnt/sum(cnt)\n",
    "info_logloss = sum(-1*prob * np.log2(prob))\n",
    "print('Informed logloss: ', info_logloss)\n",
    "\n",
    "uniprob = np.array([1/16 for _ in range(16)])\n",
    "uninfo_logloss =  sum(-1*uniprob * np.log2(uniprob))\n",
    "print('Uninformed logloss: ', uninfo_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary('log loss', summ=extrapolation.summary(), baseline=[info_logloss, uninfo_logloss], names=['Informed', 'Uninformed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate base line\n",
    "uniq, cnts = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnts/sum(cnts)\n",
    "informed_error = 1- max(prob)\n",
    "print('Informed Error: ', informed_error)\n",
    "\n",
    "uninformed_error = sum(uniprob * (1-uniprob))\n",
    "print('Uninformed Error: ', uninformed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_summary('error', summ=df, baseline=[informed_error, uninformed_error], names=['Informed', 'Uninformed']) # below plot is the error rate (1- accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rules\n",
    "\n",
    "After $30$ Folder CV, we have $30$ RuleFit estimators. We refit these estimators with whole dataset and select one having minimum log-loss and number of rules.\n",
    "\n",
    "This is for full-phase, the chain rules first estimate __sphere__ and then treat __sphere__ as a predictor to estimate __worm__. The prediction order is __sphere, worm, vesicle__, and, __other__.\n",
    "\n",
    "The output rules with coefficient of this notebook are in \"Rules/Full_Phase/Interpolation/\". The index of the csv names follow the prediction order as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_test, y_pred):\n",
    "    y_test = y_test.astype(np.float16)\n",
    "    y_pred = y_pred.astype(np.float16)\n",
    "    if len(y_test.shape) == 1:\n",
    "        N = y_test.shape[0]\n",
    "        loss = 0\n",
    "        for i in range(N):\n",
    "            loss -= ((y_test[i]*np.log(y_pred[i]))+((1.0-y_test[i])*np.log(1.0-y_pred[i])))\n",
    "            loss = loss/N\n",
    "    else:\n",
    "        N,M = y_test.shape\n",
    "        a=[]\n",
    "        for m in range(M):\n",
    "            loss=0\n",
    "            for i in range(N):\n",
    "                subloss = ((y_test[i,m]*np.log(y_pred[i,m]))+((1.0-y_test[i,m])*np.log(1.0-y_pred[i,m])))\n",
    "                if np.isnan(subloss):\n",
    "                    continue\n",
    "                loss -= subloss\n",
    "            loss = loss/N\n",
    "            a.append(round(loss,8))\n",
    "        loss = np.mean(a)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best RuleFit\n",
    "lst = []\n",
    "for each in extrapolation.fitted_['rufit_pcc']:\n",
    "    pred = each.predict_proba(data.x)\n",
    "    res = log_loss(data.y.values, pred)\n",
    "    lst.append((res, each))\n",
    "lst.sort()\n",
    "best_rf = lst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = best_rf.get_rules(data.x, data.y)\n",
    "indx = -1\n",
    "for key, values in dic.items():\n",
    "    indx += 1\n",
    "    name = 'Rules/Full_Phase/corona_GluMA_core_HPMA/'+ str(indx) + \"_\" + key + '.csv'\n",
    "    values.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
