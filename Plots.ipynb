{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path is a list of absolute path strings\n",
    "sys.path.append('./Script')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import data1 as data\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data & format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrafull = pd.read_csv('extra_full_performance.csv')\n",
    "df_extra_average = pd.read_csv('extra_average_performance.csv')\n",
    "df_inter_average = pd.read_csv('inter_average_performance.csv')\n",
    "df_interfull = pd.read_csv('inter_full_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrafull['mean_train_error'] = 1-df_extrafull['mean_train_accuracy']\n",
    "df_extrafull['std_train_error'] = df_extrafull['std_train_accuracy']\n",
    "df_extrafull['mean_test_error'] = 1-df_extrafull['mean_test_accuracy']\n",
    "df_extrafull['std_test_error'] = df_extrafull['std_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrafull.set_index('Unnamed: 0', inplace=True)\n",
    "df_extrafull.index.name = None\n",
    "df_extra_average.set_index('Unnamed: 0', inplace=True)\n",
    "df_extra_average.index.name = None\n",
    "df_inter_average.set_index('Unnamed: 0', inplace=True)\n",
    "df_inter_average.index.name = None\n",
    "df_interfull.set_index('Unnamed: 0', inplace=True)\n",
    "df_interfull.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_size</th>\n",
       "      <th>std_train_size</th>\n",
       "      <th>mean_test_size</th>\n",
       "      <th>std_test_size</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.377717</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.446446</td>\n",
       "      <td>0.438791</td>\n",
       "      <td>2.911227</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>3.590427</td>\n",
       "      <td>3.078563</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.553554</td>\n",
       "      <td>0.438791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.638607</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.646817</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>1.054390</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>3.114656</td>\n",
       "      <td>2.228330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361393</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.958876</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.614941</td>\n",
       "      <td>0.429592</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>2.346265</td>\n",
       "      <td>2.671447</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.385059</td>\n",
       "      <td>0.429592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.759012</td>\n",
       "      <td>0.380918</td>\n",
       "      <td>0.242205</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>2.069523</td>\n",
       "      <td>4.054021</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>0.380918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.377717            0.011388            0.446446   \n",
       "Gam               0.638607            0.002073            0.646817   \n",
       "Rufit             0.958876            0.005074            0.614941   \n",
       "Rf                0.999573            0.000754            0.759012   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.438791             2.911227            0.013010   \n",
       "Gam             0.001785             1.054390            0.030500   \n",
       "Rufit           0.429592             0.367581            0.008444   \n",
       "Rf              0.380918             0.242205            0.004092   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_size  std_train_size  \\\n",
       "LR               3.590427           3.078563       586.214286        4.863752   \n",
       "Gam              3.114656           2.228330              NaN             NaN   \n",
       "Rufit            2.346265           2.671447       586.214286        4.863752   \n",
       "Rf               2.069523           4.054021       586.214286        4.863752   \n",
       "\n",
       "       mean_test_size  std_test_size  mean_train_error  std_train_error  \\\n",
       "LR           5.785714       4.863752          0.622283         0.011388   \n",
       "Gam               NaN            NaN          0.361393         0.002073   \n",
       "Rufit        5.785714       4.863752          0.041124         0.005074   \n",
       "Rf           5.785714       4.863752          0.000427         0.000754   \n",
       "\n",
       "       mean_test_error  std_test_error  \n",
       "LR            0.553554        0.438791  \n",
       "Gam           0.353183        0.001785  \n",
       "Rufit         0.385059        0.429592  \n",
       "Rf            0.240988        0.380918  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extrafull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_size</th>\n",
       "      <th>std_train_size</th>\n",
       "      <th>mean_test_size</th>\n",
       "      <th>std_test_size</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.377717</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.446446</td>\n",
       "      <td>0.438791</td>\n",
       "      <td>2.911227</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>3.590427</td>\n",
       "      <td>3.078563</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.553554</td>\n",
       "      <td>0.438791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.638607</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.646817</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>1.054390</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>3.114656</td>\n",
       "      <td>2.228330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361393</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.958876</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.614941</td>\n",
       "      <td>0.429592</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>2.346265</td>\n",
       "      <td>2.671447</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.385059</td>\n",
       "      <td>0.429592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.759012</td>\n",
       "      <td>0.380918</td>\n",
       "      <td>0.242205</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>2.069523</td>\n",
       "      <td>4.054021</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>0.380918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.377717            0.011388            0.446446   \n",
       "GAM                 0.638607            0.002073            0.646817   \n",
       "RuleFit             0.958876            0.005074            0.614941   \n",
       "RF                  0.999573            0.000754            0.759012   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.438791             2.911227            0.013010   \n",
       "GAM               0.001785             1.054390            0.030500   \n",
       "RuleFit           0.429592             0.367581            0.008444   \n",
       "RF                0.380918             0.242205            0.004092   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_size  \\\n",
       "LR                 3.590427           3.078563       586.214286   \n",
       "GAM                3.114656           2.228330              NaN   \n",
       "RuleFit            2.346265           2.671447       586.214286   \n",
       "RF                 2.069523           4.054021       586.214286   \n",
       "\n",
       "         std_train_size  mean_test_size  std_test_size  mean_train_error  \\\n",
       "LR             4.863752        5.785714       4.863752          0.622283   \n",
       "GAM                 NaN             NaN            NaN          0.361393   \n",
       "RuleFit        4.863752        5.785714       4.863752          0.041124   \n",
       "RF             4.863752        5.785714       4.863752          0.000427   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.011388         0.553554        0.438791  \n",
       "GAM             0.002073         0.353183        0.001785  \n",
       "RuleFit         0.005074         0.385059        0.429592  \n",
       "RF              0.000754         0.240988        0.380918  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extrafull.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_extrafull # full phase extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.711198</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.742590</td>\n",
       "      <td>0.362704</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>1.024929</td>\n",
       "      <td>0.288802</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.362704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.885808</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.883329</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.263598</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.778664</td>\n",
       "      <td>0.508616</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.116671</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.989188</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.832062</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.085698</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.657738</td>\n",
       "      <td>0.988463</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>0.272435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876031</td>\n",
       "      <td>0.237429</td>\n",
       "      <td>0.064246</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.678348</td>\n",
       "      <td>1.960990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.237429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.711198            0.004448            0.742590   \n",
       "Gam               0.885808            0.002564            0.883329   \n",
       "Rufit             0.989188            0.002794            0.832062   \n",
       "Rf                1.000000            0.000000            0.876031   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.362704             0.727807            0.004611   \n",
       "Gam             0.001686             0.263598            0.008742   \n",
       "Rufit           0.272435             0.085698            0.005195   \n",
       "Rf              0.237429             0.064246            0.001849   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               0.897607           1.024929          0.288802   \n",
       "Gam              0.778664           0.508616          0.114192   \n",
       "Rufit            0.657738           0.988463          0.010812   \n",
       "Rf               0.678348           1.960990          0.000000   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.004448         0.257410        0.362704  \n",
       "Gam           0.002564         0.116671        0.001686  \n",
       "Rufit         0.002794         0.167938        0.272435  \n",
       "Rf            0.000000         0.123969        0.237429  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.711198</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.742590</td>\n",
       "      <td>0.362704</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>1.024929</td>\n",
       "      <td>0.288802</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.362704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.885808</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.883329</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.263598</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.778664</td>\n",
       "      <td>0.508616</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.116671</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.989188</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.832062</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.085698</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.657738</td>\n",
       "      <td>0.988463</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>0.272435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876031</td>\n",
       "      <td>0.237429</td>\n",
       "      <td>0.064246</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.678348</td>\n",
       "      <td>1.960990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.237429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.711198            0.004448            0.742590   \n",
       "GAM                 0.885808            0.002564            0.883329   \n",
       "RuleFit             0.989188            0.002794            0.832062   \n",
       "RF                  1.000000            0.000000            0.876031   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.362704             0.727807            0.004611   \n",
       "GAM               0.001686             0.263598            0.008742   \n",
       "RuleFit           0.272435             0.085698            0.005195   \n",
       "RF                0.237429             0.064246            0.001849   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR                 0.897607           1.024929          0.288802   \n",
       "GAM                0.778664           0.508616          0.114192   \n",
       "RuleFit            0.657738           0.988463          0.010812   \n",
       "RF                 0.678348           1.960990          0.000000   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.004448         0.257410        0.362704  \n",
       "GAM             0.002564         0.116671        0.001686  \n",
       "RuleFit         0.002794         0.167938        0.272435  \n",
       "RF              0.000000         0.123969        0.237429  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra_average.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_extra_average # average phases extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.382689</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>2.908712</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>2.929920</td>\n",
       "      <td>0.345263</td>\n",
       "      <td>0.617311</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.149020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.642335</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.581140</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>1.049974</td>\n",
       "      <td>0.034620</td>\n",
       "      <td>1.699951</td>\n",
       "      <td>1.359898</td>\n",
       "      <td>0.357665</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.418860</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.954916</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.785439</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.374219</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>1.039242</td>\n",
       "      <td>0.431893</td>\n",
       "      <td>0.045084</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.214561</td>\n",
       "      <td>0.090540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999185</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.800789</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.245952</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>1.163131</td>\n",
       "      <td>0.806772</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.199211</td>\n",
       "      <td>0.066668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.382689            0.011744            0.378509   \n",
       "Gam               0.642335            0.001623            0.581140   \n",
       "Rufit             0.954916            0.005991            0.785439   \n",
       "Rf                0.999185            0.001356            0.800789   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.149020             2.908712            0.011742   \n",
       "Gam             0.000786             1.049974            0.034620   \n",
       "Rufit           0.090540             0.374219            0.011522   \n",
       "Rf              0.066668             0.245952            0.004644   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               2.929920           0.345263          0.617311   \n",
       "Gam              1.699951           1.359898          0.357665   \n",
       "Rufit            1.039242           0.431893          0.045084   \n",
       "Rf               1.163131           0.806772          0.000815   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.011744         0.621491        0.149020  \n",
       "Gam           0.001623         0.418860        0.000786  \n",
       "Rufit         0.005991         0.214561        0.090540  \n",
       "Rf            0.001356         0.199211        0.066668  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.382689</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>2.908712</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>2.929920</td>\n",
       "      <td>0.345263</td>\n",
       "      <td>0.617311</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.149020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.642335</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.581140</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>1.049974</td>\n",
       "      <td>0.034620</td>\n",
       "      <td>1.699951</td>\n",
       "      <td>1.359898</td>\n",
       "      <td>0.357665</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.418860</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.954916</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.785439</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.374219</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>1.039242</td>\n",
       "      <td>0.431893</td>\n",
       "      <td>0.045084</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.214561</td>\n",
       "      <td>0.090540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999185</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.800789</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.245952</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>1.163131</td>\n",
       "      <td>0.806772</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.199211</td>\n",
       "      <td>0.066668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.382689            0.011744            0.378509   \n",
       "GAM                 0.642335            0.001623            0.581140   \n",
       "RuleFit             0.954916            0.005991            0.785439   \n",
       "RF                  0.999185            0.001356            0.800789   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.149020             2.908712            0.011742   \n",
       "GAM               0.000786             1.049974            0.034620   \n",
       "RuleFit           0.090540             0.374219            0.011522   \n",
       "RF                0.066668             0.245952            0.004644   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR                 2.929920           0.345263          0.617311   \n",
       "GAM                1.699951           1.359898          0.357665   \n",
       "RuleFit            1.039242           0.431893          0.045084   \n",
       "RF                 1.163131           0.806772          0.000815   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.011744         0.621491        0.149020  \n",
       "GAM             0.001623         0.418860        0.000786  \n",
       "RuleFit         0.005991         0.214561        0.090540  \n",
       "RF              0.001356         0.199211        0.066668  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interfull.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_interfull # full phase interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.713231</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.712061</td>\n",
       "      <td>0.092212</td>\n",
       "      <td>0.727174</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.286769</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.287939</td>\n",
       "      <td>0.092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.887055</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.262494</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>0.424988</td>\n",
       "      <td>0.337170</td>\n",
       "      <td>0.112945</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.134868</td>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.923553</td>\n",
       "      <td>0.058483</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.279032</td>\n",
       "      <td>0.207822</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.076447</td>\n",
       "      <td>0.058483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.932851</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.336166</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.067149</td>\n",
       "      <td>0.054240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.713231            0.004747            0.712061   \n",
       "Gam               0.887055            0.002369            0.865132   \n",
       "Rufit             0.989501            0.002760            0.923553   \n",
       "Rf                0.999898            0.000188            0.932851   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.092212             0.727174            0.004368   \n",
       "Gam             0.001617             0.262494            0.013987   \n",
       "Rufit           0.058483             0.085185            0.004568   \n",
       "Rf              0.054240             0.064982            0.001980   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               0.732412           0.128536          0.286769   \n",
       "Gam              0.424988           0.337170          0.112945   \n",
       "Rufit            0.279032           0.207822          0.010499   \n",
       "Rf               0.286925           0.336166          0.000102   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.004747         0.287939        0.092212  \n",
       "Gam           0.002369         0.134868        0.001617  \n",
       "Rufit         0.002760         0.076447        0.058483  \n",
       "Rf            0.000188         0.067149        0.054240  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.713231</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.712061</td>\n",
       "      <td>0.092212</td>\n",
       "      <td>0.727174</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.286769</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.287939</td>\n",
       "      <td>0.092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.887055</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.262494</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>0.424988</td>\n",
       "      <td>0.337170</td>\n",
       "      <td>0.112945</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.134868</td>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.923553</td>\n",
       "      <td>0.058483</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.279032</td>\n",
       "      <td>0.207822</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.076447</td>\n",
       "      <td>0.058483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.932851</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.336166</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.067149</td>\n",
       "      <td>0.054240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.713231            0.004747            0.712061   \n",
       "GAM                 0.887055            0.002369            0.865132   \n",
       "RuleFit             0.989501            0.002760            0.923553   \n",
       "RF                  0.999898            0.000188            0.932851   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.092212             0.727174            0.004368   \n",
       "GAM               0.001617             0.262494            0.013987   \n",
       "RuleFit           0.058483             0.085185            0.004568   \n",
       "RF                0.054240             0.064982            0.001980   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR                 0.732412           0.128536          0.286769   \n",
       "GAM                0.424988           0.337170          0.112945   \n",
       "RuleFit            0.279032           0.207822          0.010499   \n",
       "RF                 0.286925           0.336166          0.000102   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.004747         0.287939        0.092212  \n",
       "GAM             0.002369         0.134868        0.001617  \n",
       "RuleFit         0.002760         0.076447        0.058483  \n",
       "RF              0.000188         0.067149        0.054240  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter_average.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_inter_average # average phase interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the base line\n",
    "__Notice__:\n",
    "We think only for the uninformed baseline, interpolation and extrapolation are the same.\n",
    "\n",
    "1. Informed baseline: \n",
    "    * based on the most frequent observations\n",
    "2. Uninformed baseline: \n",
    "    * uninform guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpolation Error baseline__\n",
    "1. Informed full sphase:\n",
    "    \n",
    "2. Informed average sphase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>23, 43, 61, 157, 243, 253, 296, 336, 346, 375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>60, 65, 79, 133, 167, 180, 220, 254, 272, 285,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...</td>\n",
       "      <td>1, 37, 42, 45, 52, 113, 127, 177, 229, 364, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>14, 28, 36, 40, 70, 93, 114, 116, 153, 165, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...</td>\n",
       "      <td>4, 55, 57, 132, 136, 150, 247, 249, 264, 265, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num                                              train  \\\n",
       "0    1  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "1    2  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "2    3  0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...   \n",
       "3    4  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "4    5  0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...   \n",
       "\n",
       "                                                test  \n",
       "0  23, 43, 61, 157, 243, 253, 296, 336, 346, 375,...  \n",
       "1  60, 65, 79, 133, 167, 180, 220, 254, 272, 285,...  \n",
       "2  1, 37, 42, 45, 52, 113, 127, 177, 229, 364, 38...  \n",
       "3  14, 28, 36, 40, 70, 93, 114, 116, 153, 165, 18...  \n",
       "4  4, 55, 57, 132, 136, 150, 247, 249, 264, 265, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_index = pd.read_csv('interpolation_full_index.csv')\n",
    "inter_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_error(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_individual_error(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Inform error:  0.5907894736842105\n"
     ]
    }
   ],
   "source": [
    "# real interpolation full\n",
    "real_inter_full_info_error = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    \n",
    "    real_inter_full_info_error.append(get_full_error(_train, _test))\n",
    "real_inter_full_info_error = np.mean(real_inter_full_info_error)\n",
    "print(\"real Inform error: \", real_inter_full_info_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162\n",
      "Real inform error:0.5907894736842105 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{}\\nReal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, real_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__interpolation average error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Real inform error:0.2795175438596491 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation average\n",
    "unreal_inter_avg_info_error = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_avg_info_error.append(error)\n",
    "\n",
    "real_inter_avg_info_error = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    \n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_inter_avg_info_error.append(get_individual_error(_train, _test, each.name))\n",
    "real_inter_avg_info_error = np.mean(real_inter_avg_info_error)  \n",
    "unreal_inter_avg_info_error = np.mean(unreal_inter_avg_info_error)\n",
    "inter_avg_uninfo_error = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nReal inform error:{} \\nUninform error:{}'.format(unreal_inter_avg_info_error, real_inter_avg_info_error, inter_avg_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation Error baseline__\n",
    "1. Full sphase Informed: \n",
    "    \n",
    "2. Average sphase Informed: \n",
    "    \n",
    "3. Uninformed:\n",
    "    * Same with interpolation, random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>555, 556, 557, 558, 559, 560, 561, 562, 563, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>292, 293, 294, 456, 457, 458, 459, 460, 461, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>311, 312, 313, 314, 315, 316, 317, 318, 319, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>97, 98, 99, 100, 101, 102, 103, 104, 105, 106,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>221, 222, 223, 224, 225, 226, 227, 228, 229, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>281, 282, 283, 284, 285, 286, 287, 288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>50, 51, 52, 53, 54, 55, 56, 57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>59, 60, 61, 62, 63, 64, 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1...</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>186, 187, 188, 189, 190, 191, 192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>320, 321, 322, 323, 324, 325, 326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>450, 451, 452, 453, 454, 479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>333, 334, 335, 336, 337, 338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>193, 194, 195, 196, 197, 198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>339, 340, 341, 342, 343, 344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>572, 573, 574, 575, 576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 1...</td>\n",
       "      <td>6, 7, 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>18, 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>15, 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>17, 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num                                              train  \\\n",
       "0     1  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "1     2  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "2     3  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "3     4  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "4     5  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "5     6  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "6     7  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "7     8  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "8     9  6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1...   \n",
       "9    10  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "10   11  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "11   12  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "12   13  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "13   14  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "14   15  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "15   16  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "16   17  0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 1...   \n",
       "17   18  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "18   19  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "19   20  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "20   21  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "21   22  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "22   23  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "23   24  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "24   25  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, ...   \n",
       "25   26  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, ...   \n",
       "26   27  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, ...   \n",
       "27   28  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, ...   \n",
       "\n",
       "                                                 test  \n",
       "0   555, 556, 557, 558, 559, 560, 561, 562, 563, 5...  \n",
       "1   292, 293, 294, 456, 457, 458, 459, 460, 461, 4...  \n",
       "2   311, 312, 313, 314, 315, 316, 317, 318, 319, 3...  \n",
       "3   97, 98, 99, 100, 101, 102, 103, 104, 105, 106,...  \n",
       "4   221, 222, 223, 224, 225, 226, 227, 228, 229, 2...  \n",
       "5              281, 282, 283, 284, 285, 286, 287, 288  \n",
       "6                      50, 51, 52, 53, 54, 55, 56, 57  \n",
       "7                          59, 60, 61, 62, 63, 64, 65  \n",
       "8                                 0, 1, 2, 3, 4, 5, 9  \n",
       "9                   186, 187, 188, 189, 190, 191, 192  \n",
       "10                  320, 321, 322, 323, 324, 325, 326  \n",
       "11                       450, 451, 452, 453, 454, 479  \n",
       "12                       333, 334, 335, 336, 337, 338  \n",
       "13                       193, 194, 195, 196, 197, 198  \n",
       "14                       339, 340, 341, 342, 343, 344  \n",
       "15                            572, 573, 574, 575, 576  \n",
       "16                                            6, 7, 8  \n",
       "17                                             18, 21  \n",
       "18                                             15, 19  \n",
       "19                                             17, 20  \n",
       "20                                                 49  \n",
       "21                                                 58  \n",
       "22                                                 16  \n",
       "23                                                 14  \n",
       "24                                                 13  \n",
       "25                                                 12  \n",
       "26                                                 11  \n",
       "27                                                 10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_index = pd.read_csv('Extrapolation_index.csv')\n",
    "extra_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation full error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Inform error:  0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# real interpolation full\n",
    "real_extra_full_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    real_extra_full_info_error.append(get_full_error(_train, _test))\n",
    "real_extra_full_info_error = np.mean(real_extra_full_info_error)\n",
    "print(\"real Inform error: \", real_extra_full_info_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n",
      "Real inform error:0.5233630952380952 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full sphase\n",
    "unreal_extra_full_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "#     _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    unreal_extra_full_info_error.append(get_full_error(data.y.index.tolist(), _test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "\n",
    "\n",
    "extra_full_uninfo_error = 1-0.5**4\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}\\nReal inform error:{} \\nUninform error:{}'.format(unreal_extra_full_info_error, real_extra_full_info_error, extra_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation Average Error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095 \n",
      "Real inform error:0.2485863095238095 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# extrapolation average\n",
    "unreal_extra_avg_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_avg_info_error.append(get_individual_error(data.y.index.tolist(), _test, each.name))\n",
    "unreal_extra_avg_info_error = np.mean(unreal_extra_avg_info_error)\n",
    "        \n",
    "real_extra_avg_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_extra_avg_info_error.append(get_individual_error(_train, _test, each.name))\n",
    "real_extra_avg_info_error = np.mean(real_extra_avg_info_error)  \n",
    "\n",
    "unreal_inter_avg_info_error = np.mean(unreal_inter_avg_info_error)\n",
    "extra_avg_uninfo_error = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nReal inform error:{} \\nUninform error:{}'.format(unreal_extra_avg_info_error, real_extra_avg_info_error, extra_avg_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative loglikelihood baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpolation negative loglikelihood baseline__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, we have the implement of the p(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_individual_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Inform error:  2.5287817512815858\n"
     ]
    }
   ],
   "source": [
    "real_inter_full_info_loss = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    \n",
    "    real_inter_full_info_loss.append(get_full_logs(_train, _test))\n",
    "real_inter_full_info_loss = np.mean(real_inter_full_info_loss)\n",
    "print(\"real Inform error: \", real_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase logloss base line:\n",
      "Unreal_Inform error:2.5225679165070907\n",
      "Real_Inform error:2.5287817512815858 \n",
      "Uninform error:4.0\n"
     ]
    }
   ],
   "source": [
    "# interpolation full sphase informed\n",
    "\n",
    "inter_full_uninfo_loss = -math.log2(0.5**4)\n",
    "print('Interpolation full sphase logloss base line:\\nUnreal_Inform error:{}\\nReal_Inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_loss, real_inter_full_info_loss, inter_full_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n",
      "Real Inform logloss:0.7434276646050642\n",
      "Uninform logloss:1.0\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "\n",
    "\n",
    "# real\n",
    "real_inter_avg_info_loss = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_inter_avg_info_loss.append(get_individual_logs(_train, _test, each.name))\n",
    "real_inter_avg_info_loss = np.mean(real_inter_avg_info_loss)\n",
    "\n",
    "\n",
    "inter_avg_uninfo_loss = -math.log2(0.5) # uninformed\n",
    "print('Interpolation average sphase logloss base line:\\nUnreal Inform logloss:{}\\nReal Inform logloss:{}\\nUninform logloss:{}'.format(unreal_inter_avg_info_loss, real_inter_avg_info_loss, inter_avg_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation negative loglikelihood baseline__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation Full__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Extra Inform error:  2.6554775150876035\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = 0\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    real_extra_full_info_loss += get_full_logs(_train, _test)/extra_index.shape[0]\n",
    "\n",
    "print(\"real Extra Inform error: \", real_extra_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unreal Extra Inform error:  2.5831816190915395\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_full_info_loss = 0\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    unreal_extra_full_info_loss += get_full_logs(data.x.index.tolist(), _test)/extra_index.shape[0]\n",
    "\n",
    "print(\"Unreal Extra Inform error: \", unreal_extra_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal Inform logloss:2.5831816190915395\n",
      "Real Inform logloss:2.6554775150876035 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "print('Extrapolation full sphase error base line:\\nUnreal Inform logloss:{}\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(unreal_extra_full_info_loss, real_extra_full_info_loss, extra_full_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation average__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extrapolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n",
      "Real Inform logloss:0.8156726613658424\n",
      "Uninform logloss:1.0\n"
     ]
    }
   ],
   "source": [
    "# extrapolation average sphase informed\n",
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "\n",
    "\n",
    "# real\n",
    "real_extra_avg_info_loss = []\n",
    "\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_extra_avg_info_loss.append(get_individual_logs(_train, _test, each.name))\n",
    "real_extra_avg_info_loss = np.mean(real_extra_avg_info_loss)\n",
    "real_extra_avg_info_loss\n",
    "\n",
    "\n",
    "extra_avg_uninfo_loss = -math.log2(0.5) # uninformed\n",
    "print('extrapolation average sphase logloss base line:\\nUnreal Inform logloss:{}\\nReal Inform logloss:{}\\nUninform logloss:{}'.format(unreal_extra_avg_info_loss, real_extra_avg_info_loss, extra_avg_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame({\n",
    "    'Inter_avg_error': [unreal_inter_avg_info_error, real_inter_avg_info_error, inter_avg_uninfo_error],\n",
    "    'Inter_Full_error':[unreal_inter_full_info_error, real_inter_full_info_error, inter_full_uninfo_error],\n",
    "    \n",
    "    'Extra_avg_error': [unreal_extra_avg_info_error, real_extra_avg_info_error, extra_avg_uninfo_error],\n",
    "    'Extra_Full_error':[unreal_extra_full_info_error, real_extra_full_info_error, extra_full_uninfo_error],\n",
    "    \n",
    "    'Inter_avg_log loss': [unreal_inter_avg_info_loss, real_inter_avg_info_loss, inter_avg_uninfo_loss],\n",
    "    'Inter_Full_log loss':[unreal_inter_full_info_loss, real_inter_full_info_loss, inter_full_uninfo_loss],\n",
    "    \n",
    "    'Extra_avg_log loss': [unreal_extra_avg_info_loss, real_extra_avg_info_loss, extra_avg_uninfo_loss],\n",
    "    'Extra_Full_log loss':[unreal_extra_full_info_loss, real_extra_full_info_loss, extra_full_uninfo_loss]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inter_avg_error</th>\n",
       "      <th>Inter_Full_error</th>\n",
       "      <th>Extra_avg_error</th>\n",
       "      <th>Extra_Full_error</th>\n",
       "      <th>Inter_avg_log loss</th>\n",
       "      <th>Inter_Full_log loss</th>\n",
       "      <th>Extra_avg_log loss</th>\n",
       "      <th>Extra_Full_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unreal</th>\n",
       "      <td>0.279561</td>\n",
       "      <td>0.591216</td>\n",
       "      <td>0.248586</td>\n",
       "      <td>0.523363</td>\n",
       "      <td>0.740193</td>\n",
       "      <td>2.522568</td>\n",
       "      <td>0.740193</td>\n",
       "      <td>2.583182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.590789</td>\n",
       "      <td>0.248586</td>\n",
       "      <td>0.523363</td>\n",
       "      <td>0.743428</td>\n",
       "      <td>2.528782</td>\n",
       "      <td>0.815673</td>\n",
       "      <td>2.655478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uninformed</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Inter_avg_error  Inter_Full_error  Extra_avg_error  \\\n",
       "Unreal             0.279561          0.591216         0.248586   \n",
       "Real               0.279518          0.590789         0.248586   \n",
       "Uninformed         0.500000          0.937500         0.500000   \n",
       "\n",
       "            Extra_Full_error  Inter_avg_log loss  Inter_Full_log loss  \\\n",
       "Unreal              0.523363            0.740193             2.522568   \n",
       "Real                0.523363            0.743428             2.528782   \n",
       "Uninformed          0.937500            1.000000             4.000000   \n",
       "\n",
       "            Extra_avg_log loss  Extra_Full_log loss  \n",
       "Unreal                0.740193             2.583182  \n",
       "Real                  0.815673             2.655478  \n",
       "Uninformed            1.000000             4.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.index = ['Unreal', 'Real', 'Uninformed']\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    \"\"\"This function is for the actual size (cm) of plots\n",
    "    Input: \n",
    "        tuple: for example (12, 13) means 12cm, 13 cm\n",
    "    Output:\n",
    "        tuple: for python figsize\n",
    "    \"\"\"\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2834.65x1700.79 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, ((ax2, ax1), (ax4, ax3)) = plt.subplots(2,2, sharey=False, sharex=True)\n",
    "fig.set_size_inches(cm2inch(100, 60))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 25\n",
    "ind = np.arange(len(df_extrafull))\n",
    "ax1.bar(ind-width, df_interfull[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=df_interfull[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, df_interfull[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=df_interfull[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, df_extrafull[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=df_extrafull[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, real_inter_full_info_error, real_extra_full_info_error]\n",
    "inter_error_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax1.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax1.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax2.bar(ind-width, df_inter_average[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=df_inter_average[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, df_inter_average[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=df_inter_average[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, df_extra_average[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=df_extra_average[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "\n",
    "ax2.set_title('Individual phase average error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax2.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_avg_uninfo_error, real_inter_avg_info_error, real_extra_avg_info_error]\n",
    "avg_error_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax2.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax2.legend(fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, df_interfull[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=df_interfull[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, df_interfull[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=df_interfull[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, df_extrafull[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=df_extrafull[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [inter_full_uninfo_loss, real_inter_full_info_loss, real_extra_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full sphase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "\n",
    "ax4.bar(ind-width, df_inter_average[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=df_inter_average[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax4.bar(ind, df_inter_average[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=df_inter_average[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax4.bar(ind+width, df_extra_average[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=df_extra_average[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "\n",
    "avg_loss_base = [inter_avg_uninfo_loss, real_inter_avg_info_loss, real_extra_avg_info_loss]\n",
    "avg_loss_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(avg_loss_base)):\n",
    "    ax4.axhline(y=avg_loss_base[i], color=colors[i], linestyle='-', label=avg_loss_name[i])\n",
    "\n",
    "ax4.set_title('Individual sphase average logloss', fontsize=fontsize)\n",
    "ax4.set_xticks(ind)\n",
    "ax4.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax4.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
