{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path is a list of absolute path strings\n",
    "sys.path.append('./Script')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import data1 as data\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data & format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrafull = pd.read_csv('extra_full_performance.csv')\n",
    "df_extra_average = pd.read_csv('extra_average_performance.csv')\n",
    "df_inter_average = pd.read_csv('inter_average_performance.csv')\n",
    "df_interfull = pd.read_csv('inter_full_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrafull['mean_train_error'] = 1-df_extrafull['mean_train_accuracy']\n",
    "df_extrafull['std_train_error'] = df_extrafull['std_train_accuracy']\n",
    "df_extrafull['mean_test_error'] = 1-df_extrafull['mean_test_accuracy']\n",
    "df_extrafull['std_test_error'] = df_extrafull['std_test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrafull.set_index('Unnamed: 0', inplace=True)\n",
    "df_extrafull.index.name = None\n",
    "df_extra_average.set_index('Unnamed: 0', inplace=True)\n",
    "df_extra_average.index.name = None\n",
    "df_inter_average.set_index('Unnamed: 0', inplace=True)\n",
    "df_inter_average.index.name = None\n",
    "df_interfull.set_index('Unnamed: 0', inplace=True)\n",
    "df_interfull.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_size</th>\n",
       "      <th>std_train_size</th>\n",
       "      <th>mean_test_size</th>\n",
       "      <th>std_test_size</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.377717</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.446446</td>\n",
       "      <td>0.438791</td>\n",
       "      <td>2.911227</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>3.590427</td>\n",
       "      <td>3.078563</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.553554</td>\n",
       "      <td>0.438791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.638607</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>0.646817</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>1.054390</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>3.114656</td>\n",
       "      <td>4.480667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361393</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.344654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.958876</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.614941</td>\n",
       "      <td>0.429592</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>2.346265</td>\n",
       "      <td>2.671447</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.385059</td>\n",
       "      <td>0.429592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.759012</td>\n",
       "      <td>0.380918</td>\n",
       "      <td>0.242205</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>2.069523</td>\n",
       "      <td>4.054021</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>0.380918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.377717            0.011388            0.446446   \n",
       "Gam               0.638607            0.344654            0.646817   \n",
       "Rufit             0.958876            0.005074            0.614941   \n",
       "Rf                0.999573            0.000754            0.759012   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.438791             2.911227            0.013010   \n",
       "Gam             0.344654             1.054390            0.010034   \n",
       "Rufit           0.429592             0.367581            0.008444   \n",
       "Rf              0.380918             0.242205            0.004092   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_size  std_train_size  \\\n",
       "LR               3.590427           3.078563       586.214286        4.863752   \n",
       "Gam              3.114656           4.480667              NaN             NaN   \n",
       "Rufit            2.346265           2.671447       586.214286        4.863752   \n",
       "Rf               2.069523           4.054021       586.214286        4.863752   \n",
       "\n",
       "       mean_test_size  std_test_size  mean_train_error  std_train_error  \\\n",
       "LR           5.785714       4.863752          0.622283         0.011388   \n",
       "Gam               NaN            NaN          0.361393         0.344654   \n",
       "Rufit        5.785714       4.863752          0.041124         0.005074   \n",
       "Rf           5.785714       4.863752          0.000427         0.000754   \n",
       "\n",
       "       mean_test_error  std_test_error  \n",
       "LR            0.553554        0.438791  \n",
       "Gam           0.353183        0.344654  \n",
       "Rufit         0.385059        0.429592  \n",
       "Rf            0.240988        0.380918  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extrafull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_size</th>\n",
       "      <th>std_train_size</th>\n",
       "      <th>mean_test_size</th>\n",
       "      <th>std_test_size</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.377717</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.446446</td>\n",
       "      <td>0.438791</td>\n",
       "      <td>2.911227</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>3.590427</td>\n",
       "      <td>3.078563</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.553554</td>\n",
       "      <td>0.438791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.638607</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>0.646817</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>1.054390</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>3.114656</td>\n",
       "      <td>4.480667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361393</td>\n",
       "      <td>0.344654</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.344654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.958876</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.614941</td>\n",
       "      <td>0.429592</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.008444</td>\n",
       "      <td>2.346265</td>\n",
       "      <td>2.671447</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.385059</td>\n",
       "      <td>0.429592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.759012</td>\n",
       "      <td>0.380918</td>\n",
       "      <td>0.242205</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>2.069523</td>\n",
       "      <td>4.054021</td>\n",
       "      <td>586.214286</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>4.863752</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>0.380918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.377717            0.011388            0.446446   \n",
       "GAM                 0.638607            0.344654            0.646817   \n",
       "RuleFit             0.958876            0.005074            0.614941   \n",
       "RF                  0.999573            0.000754            0.759012   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.438791             2.911227            0.013010   \n",
       "GAM               0.344654             1.054390            0.010034   \n",
       "RuleFit           0.429592             0.367581            0.008444   \n",
       "RF                0.380918             0.242205            0.004092   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_size  \\\n",
       "LR                 3.590427           3.078563       586.214286   \n",
       "GAM                3.114656           4.480667              NaN   \n",
       "RuleFit            2.346265           2.671447       586.214286   \n",
       "RF                 2.069523           4.054021       586.214286   \n",
       "\n",
       "         std_train_size  mean_test_size  std_test_size  mean_train_error  \\\n",
       "LR             4.863752        5.785714       4.863752          0.622283   \n",
       "GAM                 NaN             NaN            NaN          0.361393   \n",
       "RuleFit        4.863752        5.785714       4.863752          0.041124   \n",
       "RF             4.863752        5.785714       4.863752          0.000427   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.011388         0.553554        0.438791  \n",
       "GAM             0.344654         0.353183        0.344654  \n",
       "RuleFit         0.005074         0.385059        0.429592  \n",
       "RF              0.000754         0.240988        0.380918  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extrafull.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_extrafull # full phase extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.711198</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.742590</td>\n",
       "      <td>0.362704</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>1.024929</td>\n",
       "      <td>0.288802</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.362704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.885808</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.883329</td>\n",
       "      <td>0.209107</td>\n",
       "      <td>0.263598</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.778664</td>\n",
       "      <td>1.786772</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.116671</td>\n",
       "      <td>0.209107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.989188</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.832062</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.085698</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.657738</td>\n",
       "      <td>0.988463</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>0.272435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876031</td>\n",
       "      <td>0.237429</td>\n",
       "      <td>0.064246</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.678348</td>\n",
       "      <td>1.960990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.237429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.711198            0.004448            0.742590   \n",
       "Gam               0.885808            0.003281            0.883329   \n",
       "Rufit             0.989188            0.002794            0.832062   \n",
       "Rf                1.000000            0.000000            0.876031   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.362704             0.727807            0.004611   \n",
       "Gam             0.209107             0.263598            0.004438   \n",
       "Rufit           0.272435             0.085698            0.005195   \n",
       "Rf              0.237429             0.064246            0.001849   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               0.897607           1.024929          0.288802   \n",
       "Gam              0.778664           1.786772          0.114192   \n",
       "Rufit            0.657738           0.988463          0.010812   \n",
       "Rf               0.678348           1.960990          0.000000   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.004448         0.257410        0.362704  \n",
       "Gam           0.003281         0.116671        0.209107  \n",
       "Rufit         0.002794         0.167938        0.272435  \n",
       "Rf            0.000000         0.123969        0.237429  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.711198</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.742590</td>\n",
       "      <td>0.362704</td>\n",
       "      <td>0.727807</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>1.024929</td>\n",
       "      <td>0.288802</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.362704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.885808</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.883329</td>\n",
       "      <td>0.209107</td>\n",
       "      <td>0.263598</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.778664</td>\n",
       "      <td>1.786772</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.116671</td>\n",
       "      <td>0.209107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.989188</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.832062</td>\n",
       "      <td>0.272435</td>\n",
       "      <td>0.085698</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.657738</td>\n",
       "      <td>0.988463</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.167938</td>\n",
       "      <td>0.272435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.876031</td>\n",
       "      <td>0.237429</td>\n",
       "      <td>0.064246</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.678348</td>\n",
       "      <td>1.960990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123969</td>\n",
       "      <td>0.237429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.711198            0.004448            0.742590   \n",
       "GAM                 0.885808            0.003281            0.883329   \n",
       "RuleFit             0.989188            0.002794            0.832062   \n",
       "RF                  1.000000            0.000000            0.876031   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.362704             0.727807            0.004611   \n",
       "GAM               0.209107             0.263598            0.004438   \n",
       "RuleFit           0.272435             0.085698            0.005195   \n",
       "RF                0.237429             0.064246            0.001849   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR                 0.897607           1.024929          0.288802   \n",
       "GAM                0.778664           1.786772          0.114192   \n",
       "RuleFit            0.657738           0.988463          0.010812   \n",
       "RF                 0.678348           1.960990          0.000000   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.004448         0.257410        0.362704  \n",
       "GAM             0.003281         0.116671        0.209107  \n",
       "RuleFit         0.002794         0.167938        0.272435  \n",
       "RF              0.000000         0.123969        0.237429  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extra_average.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_extra_average # average phases extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.382689</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>2.908712</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>2.929920</td>\n",
       "      <td>0.345263</td>\n",
       "      <td>0.617311</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.149020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.642045</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>1.759794</td>\n",
       "      <td>1.221905</td>\n",
       "      <td>0.357955</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.092838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.954916</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.785439</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.374219</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>1.039242</td>\n",
       "      <td>0.431893</td>\n",
       "      <td>0.045084</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.214561</td>\n",
       "      <td>0.090540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999185</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.800789</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.245952</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>1.163131</td>\n",
       "      <td>0.806772</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.199211</td>\n",
       "      <td>0.066668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.382689            0.011744            0.378509   \n",
       "Gam               0.642045            0.092838            0.585000   \n",
       "Rufit             0.954916            0.005991            0.785439   \n",
       "Rf                0.999185            0.001356            0.800789   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.149020             2.908712            0.011742   \n",
       "Gam             0.092838             1.049921            0.009802   \n",
       "Rufit           0.090540             0.374219            0.011522   \n",
       "Rf              0.066668             0.245952            0.004644   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               2.929920           0.345263          0.617311   \n",
       "Gam              1.759794           1.221905          0.357955   \n",
       "Rufit            1.039242           0.431893          0.045084   \n",
       "Rf               1.163131           0.806772          0.000815   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.011744         0.621491        0.149020  \n",
       "Gam           0.092838         0.415000        0.092838  \n",
       "Rufit         0.005991         0.214561        0.090540  \n",
       "Rf            0.001356         0.199211        0.066668  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.382689</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>2.908712</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>2.929920</td>\n",
       "      <td>0.345263</td>\n",
       "      <td>0.617311</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.149020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.642045</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>1.759794</td>\n",
       "      <td>1.221905</td>\n",
       "      <td>0.357955</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.092838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.954916</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.785439</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.374219</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>1.039242</td>\n",
       "      <td>0.431893</td>\n",
       "      <td>0.045084</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.214561</td>\n",
       "      <td>0.090540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999185</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.800789</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.245952</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>1.163131</td>\n",
       "      <td>0.806772</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.199211</td>\n",
       "      <td>0.066668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.382689            0.011744            0.378509   \n",
       "GAM                 0.642045            0.092838            0.585000   \n",
       "RuleFit             0.954916            0.005991            0.785439   \n",
       "RF                  0.999185            0.001356            0.800789   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.149020             2.908712            0.011742   \n",
       "GAM               0.092838             1.049921            0.009802   \n",
       "RuleFit           0.090540             0.374219            0.011522   \n",
       "RF                0.066668             0.245952            0.004644   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR                 2.929920           0.345263          0.617311   \n",
       "GAM                1.759794           1.221905          0.357955   \n",
       "RuleFit            1.039242           0.431893          0.045084   \n",
       "RF                 1.163131           0.806772          0.000815   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.011744         0.621491        0.149020  \n",
       "GAM             0.092838         0.415000        0.092838  \n",
       "RuleFit         0.005991         0.214561        0.090540  \n",
       "RF              0.001356         0.199211        0.066668  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interfull.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_interfull # full phase interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.713231</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.712061</td>\n",
       "      <td>0.092212</td>\n",
       "      <td>0.727174</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.286769</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.287939</td>\n",
       "      <td>0.092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.887070</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.865768</td>\n",
       "      <td>0.071723</td>\n",
       "      <td>0.262480</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.439949</td>\n",
       "      <td>0.403804</td>\n",
       "      <td>0.112930</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.134232</td>\n",
       "      <td>0.071723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.923553</td>\n",
       "      <td>0.058483</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.279032</td>\n",
       "      <td>0.207822</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.076447</td>\n",
       "      <td>0.058483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.932851</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.336166</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.067149</td>\n",
       "      <td>0.054240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.713231            0.004747            0.712061   \n",
       "Gam               0.887070            0.003435            0.865768   \n",
       "Rufit             0.989501            0.002760            0.923553   \n",
       "Rf                0.999898            0.000188            0.932851   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.092212             0.727174            0.004368   \n",
       "Gam             0.071723             0.262480            0.004823   \n",
       "Rufit           0.058483             0.085185            0.004568   \n",
       "Rf              0.054240             0.064982            0.001980   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               0.732412           0.128536          0.286769   \n",
       "Gam              0.439949           0.403804          0.112930   \n",
       "Rufit            0.279032           0.207822          0.010499   \n",
       "Rf               0.286925           0.336166          0.000102   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.004747         0.287939        0.092212  \n",
       "Gam           0.003435         0.134232        0.071723  \n",
       "Rufit         0.002760         0.076447        0.058483  \n",
       "Rf            0.000188         0.067149        0.054240  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.713231</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.712061</td>\n",
       "      <td>0.092212</td>\n",
       "      <td>0.727174</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.286769</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.287939</td>\n",
       "      <td>0.092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.887070</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.865768</td>\n",
       "      <td>0.071723</td>\n",
       "      <td>0.262480</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.439949</td>\n",
       "      <td>0.403804</td>\n",
       "      <td>0.112930</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.134232</td>\n",
       "      <td>0.071723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuleFit</th>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.923553</td>\n",
       "      <td>0.058483</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.279032</td>\n",
       "      <td>0.207822</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.076447</td>\n",
       "      <td>0.058483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.932851</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.336166</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.067149</td>\n",
       "      <td>0.054240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                  0.713231            0.004747            0.712061   \n",
       "GAM                 0.887070            0.003435            0.865768   \n",
       "RuleFit             0.989501            0.002760            0.923553   \n",
       "RF                  0.999898            0.000188            0.932851   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR                0.092212             0.727174            0.004368   \n",
       "GAM               0.071723             0.262480            0.004823   \n",
       "RuleFit           0.058483             0.085185            0.004568   \n",
       "RF                0.054240             0.064982            0.001980   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR                 0.732412           0.128536          0.286769   \n",
       "GAM                0.439949           0.403804          0.112930   \n",
       "RuleFit            0.279032           0.207822          0.010499   \n",
       "RF                 0.286925           0.336166          0.000102   \n",
       "\n",
       "         std_train_error  mean_test_error  std_test_error  \n",
       "LR              0.004747         0.287939        0.092212  \n",
       "GAM             0.003435         0.134232        0.071723  \n",
       "RuleFit         0.002760         0.076447        0.058483  \n",
       "RF              0.000188         0.067149        0.054240  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter_average.index = ['LR', 'GAM', 'RuleFit', 'RF']\n",
    "df_inter_average # average phase interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the base line\n",
    "__Notice__:\n",
    "We think only for the uninformed baseline, interpolation and extrapolation are the same.\n",
    "\n",
    "1. Informed baseline: \n",
    "    * based on the most frequent observations\n",
    "2. Uninformed baseline: \n",
    "    * uninform guessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpolation Error baseline__\n",
    "1. Informed full sphase:\n",
    "    \n",
    "2. Informed average sphase:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>23, 43, 61, 157, 243, 253, 296, 336, 346, 375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>60, 65, 79, 133, 167, 180, 220, 254, 272, 285,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...</td>\n",
       "      <td>1, 37, 42, 45, 52, 113, 127, 177, 229, 364, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>14, 28, 36, 40, 70, 93, 114, 116, 153, 165, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...</td>\n",
       "      <td>4, 55, 57, 132, 136, 150, 247, 249, 264, 265, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num                                              train  \\\n",
       "0    1  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "1    2  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "2    3  0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...   \n",
       "3    4  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "4    5  0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...   \n",
       "\n",
       "                                                test  \n",
       "0  23, 43, 61, 157, 243, 253, 296, 336, 346, 375,...  \n",
       "1  60, 65, 79, 133, 167, 180, 220, 254, 272, 285,...  \n",
       "2  1, 37, 42, 45, 52, 113, 127, 177, 229, 364, 38...  \n",
       "3  14, 28, 36, 40, 70, 93, 114, 116, 153, 165, 18...  \n",
       "4  4, 55, 57, 132, 136, 150, 247, 249, 264, 265, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_index = pd.read_csv('interpolation_full_index.csv')\n",
    "inter_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_error(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_individual_error(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Inform error:  0.5907894736842105\n"
     ]
    }
   ],
   "source": [
    "# real interpolation full\n",
    "real_inter_full_info_error = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    \n",
    "    real_inter_full_info_error.append(get_full_error(_train, _test))\n",
    "real_inter_full_info_error = np.mean(real_inter_full_info_error)\n",
    "print(\"real Inform error: \", real_inter_full_info_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5912162162162162\n",
      "Real inform error:0.5907894736842105 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{}\\nReal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, real_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__interpolation average error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.27956081081081074 \n",
      "Real inform error:0.2795175438596491 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation average\n",
    "unreal_inter_avg_info_error = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_avg_info_error.append(error)\n",
    "\n",
    "real_inter_avg_info_error = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    \n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_inter_avg_info_error.append(get_individual_error(_train, _test, each.name))\n",
    "real_inter_avg_info_error = np.mean(real_inter_avg_info_error)  \n",
    "unreal_inter_avg_info_error = np.mean(unreal_inter_avg_info_error)\n",
    "inter_avg_uninfo_error = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nReal inform error:{} \\nUninform error:{}'.format(unreal_inter_avg_info_error, real_inter_avg_info_error, inter_avg_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation Error baseline__\n",
    "1. Full sphase Informed: \n",
    "    \n",
    "2. Average sphase Informed: \n",
    "    \n",
    "3. Uninformed:\n",
    "    * Same with interpolation, random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>555, 556, 557, 558, 559, 560, 561, 562, 563, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>292, 293, 294, 456, 457, 458, 459, 460, 461, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>311, 312, 313, 314, 315, 316, 317, 318, 319, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>97, 98, 99, 100, 101, 102, 103, 104, 105, 106,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>221, 222, 223, 224, 225, 226, 227, 228, 229, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>281, 282, 283, 284, 285, 286, 287, 288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>50, 51, 52, 53, 54, 55, 56, 57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>59, 60, 61, 62, 63, 64, 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1...</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>186, 187, 188, 189, 190, 191, 192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>320, 321, 322, 323, 324, 325, 326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>450, 451, 452, 453, 454, 479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>333, 334, 335, 336, 337, 338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>193, 194, 195, 196, 197, 198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>339, 340, 341, 342, 343, 344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>572, 573, 574, 575, 576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 1...</td>\n",
       "      <td>6, 7, 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>18, 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>15, 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>17, 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num                                              train  \\\n",
       "0     1  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "1     2  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "2     3  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "3     4  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "4     5  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "5     6  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "6     7  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "7     8  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "8     9  6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1...   \n",
       "9    10  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "10   11  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "11   12  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "12   13  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "13   14  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "14   15  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "15   16  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "16   17  0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 1...   \n",
       "17   18  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "18   19  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "19   20  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "20   21  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "21   22  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "22   23  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "23   24  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, ...   \n",
       "24   25  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, ...   \n",
       "25   26  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, ...   \n",
       "26   27  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, ...   \n",
       "27   28  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, ...   \n",
       "\n",
       "                                                 test  \n",
       "0   555, 556, 557, 558, 559, 560, 561, 562, 563, 5...  \n",
       "1   292, 293, 294, 456, 457, 458, 459, 460, 461, 4...  \n",
       "2   311, 312, 313, 314, 315, 316, 317, 318, 319, 3...  \n",
       "3   97, 98, 99, 100, 101, 102, 103, 104, 105, 106,...  \n",
       "4   221, 222, 223, 224, 225, 226, 227, 228, 229, 2...  \n",
       "5              281, 282, 283, 284, 285, 286, 287, 288  \n",
       "6                      50, 51, 52, 53, 54, 55, 56, 57  \n",
       "7                          59, 60, 61, 62, 63, 64, 65  \n",
       "8                                 0, 1, 2, 3, 4, 5, 9  \n",
       "9                   186, 187, 188, 189, 190, 191, 192  \n",
       "10                  320, 321, 322, 323, 324, 325, 326  \n",
       "11                       450, 451, 452, 453, 454, 479  \n",
       "12                       333, 334, 335, 336, 337, 338  \n",
       "13                       193, 194, 195, 196, 197, 198  \n",
       "14                       339, 340, 341, 342, 343, 344  \n",
       "15                            572, 573, 574, 575, 576  \n",
       "16                                            6, 7, 8  \n",
       "17                                             18, 21  \n",
       "18                                             15, 19  \n",
       "19                                             17, 20  \n",
       "20                                                 49  \n",
       "21                                                 58  \n",
       "22                                                 16  \n",
       "23                                                 14  \n",
       "24                                                 13  \n",
       "25                                                 12  \n",
       "26                                                 11  \n",
       "27                                                 10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_index = pd.read_csv('Extrapolation_index.csv')\n",
    "extra_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation full error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Inform error:  0.5233630952380952\n"
     ]
    }
   ],
   "source": [
    "# real interpolation full\n",
    "real_extra_full_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    real_extra_full_info_error.append(get_full_error(_train, _test))\n",
    "real_extra_full_info_error = np.mean(real_extra_full_info_error)\n",
    "print(\"real Inform error: \", real_extra_full_info_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5233630952380952\n",
      "Real inform error:0.5233630952380952 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full sphase\n",
    "unreal_extra_full_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "#     _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    unreal_extra_full_info_error.append(get_full_error(data.y.index.tolist(), _test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "\n",
    "\n",
    "extra_full_uninfo_error = 1-0.5**4\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}\\nReal inform error:{} \\nUninform error:{}'.format(unreal_extra_full_info_error, real_extra_full_info_error, extra_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation Average Error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2485863095238095 \n",
      "Real inform error:0.2485863095238095 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# extrapolation average\n",
    "unreal_extra_avg_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_avg_info_error.append(get_individual_error(data.y.index.tolist(), _test, each.name))\n",
    "unreal_extra_avg_info_error = np.mean(unreal_extra_avg_info_error)\n",
    "        \n",
    "real_extra_avg_info_error = []\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_extra_avg_info_error.append(get_individual_error(_train, _test, each.name))\n",
    "real_extra_avg_info_error = np.mean(real_extra_avg_info_error)  \n",
    "\n",
    "unreal_inter_avg_info_error = np.mean(unreal_inter_avg_info_error)\n",
    "extra_avg_uninfo_error = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nReal inform error:{} \\nUninform error:{}'.format(unreal_extra_avg_info_error, real_extra_avg_info_error, extra_avg_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative loglikelihood baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpolation negative loglikelihood baseline__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, we have the implement of the p(a,b,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unreal Inform error:  2.5225679165070907\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_individual_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Inform error:  2.5287817512815858\n"
     ]
    }
   ],
   "source": [
    "real_inter_full_info_loss = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    \n",
    "    real_inter_full_info_loss.append(get_full_logs(_train, _test))\n",
    "real_inter_full_info_loss = np.mean(real_inter_full_info_loss)\n",
    "print(\"real Inform error: \", real_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase logloss base line:\n",
      "Unreal_Inform error:2.5225679165070907\n",
      "Real_Inform error:2.5287817512815858 \n",
      "Uninform error:4.0\n"
     ]
    }
   ],
   "source": [
    "# interpolation full sphase informed\n",
    "\n",
    "inter_full_uninfo_loss = -math.log2(0.5**4)\n",
    "print('Interpolation full sphase logloss base line:\\nUnreal_Inform error:{}\\nReal_Inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_loss, real_inter_full_info_loss, inter_full_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n",
      "Real Inform logloss:0.7434276646050642\n",
      "Uninform logloss:1.0\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "\n",
    "\n",
    "# real\n",
    "real_inter_avg_info_loss = []\n",
    "for indx, row in inter_index.iterrows():\n",
    "    _train = list(map(int, inter_index.train[indx].split(',')))\n",
    "    _test = list(map(int, inter_index.test[indx].split(',')))\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_inter_avg_info_loss.append(get_individual_logs(_train, _test, each.name))\n",
    "real_inter_avg_info_loss = np.mean(real_inter_avg_info_loss)\n",
    "\n",
    "\n",
    "inter_avg_uninfo_loss = -math.log2(0.5) # uninformed\n",
    "print('Interpolation average sphase logloss base line:\\nUnreal Inform logloss:{}\\nReal Inform logloss:{}\\nUninform logloss:{}'.format(unreal_inter_avg_info_loss, real_inter_avg_info_loss, inter_avg_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation negative loglikelihood baseline__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation Full__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real Extra Inform error:  2.6554775150876035\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = 0\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    real_extra_full_info_loss += get_full_logs(_train, _test)/extra_index.shape[0]\n",
    "\n",
    "print(\"real Extra Inform error: \", real_extra_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unreal Extra Inform error:  2.5831816190915395\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_full_info_loss = 0\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    \n",
    "    unreal_extra_full_info_loss += get_full_logs(data.x.index.tolist(), _test)/extra_index.shape[0]\n",
    "\n",
    "print(\"Unreal Extra Inform error: \", unreal_extra_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal Inform logloss:2.5831816190915395\n",
      "Real Inform logloss:2.6554775150876035 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "print('Extrapolation full sphase error base line:\\nUnreal Inform logloss:{}\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(unreal_extra_full_info_loss, real_extra_full_info_loss, extra_full_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extrapolation average__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extrapolation average sphase logloss base line:\n",
      "Unreal Inform logloss:0.7401933665227551\n",
      "Real Inform logloss:0.8156726613658424\n",
      "Uninform logloss:1.0\n"
     ]
    }
   ],
   "source": [
    "# extrapolation average sphase informed\n",
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "\n",
    "\n",
    "# real\n",
    "real_extra_avg_info_loss = []\n",
    "\n",
    "for indx, row in extra_index.iterrows():\n",
    "    _train = list(map(int, extra_index.train[indx].split(',')))\n",
    "    _test = list(map(int, extra_index.test[indx].split(',')))\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        real_extra_avg_info_loss.append(get_individual_logs(_train, _test, each.name))\n",
    "real_extra_avg_info_loss = np.mean(real_extra_avg_info_loss)\n",
    "real_extra_avg_info_loss\n",
    "\n",
    "\n",
    "extra_avg_uninfo_loss = -math.log2(0.5) # uninformed\n",
    "print('extrapolation average sphase logloss base line:\\nUnreal Inform logloss:{}\\nReal Inform logloss:{}\\nUninform logloss:{}'.format(unreal_extra_avg_info_loss, real_extra_avg_info_loss, extra_avg_uninfo_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame({\n",
    "    'Inter_avg_error': [unreal_inter_avg_info_error, real_inter_avg_info_error, inter_avg_uninfo_error],\n",
    "    'Inter_Full_error':[unreal_inter_full_info_error, real_inter_full_info_error, inter_full_uninfo_error],\n",
    "    \n",
    "    'Extra_avg_error': [unreal_extra_avg_info_error, real_extra_avg_info_error, extra_avg_uninfo_error],\n",
    "    'Extra_Full_error':[unreal_extra_full_info_error, real_extra_full_info_error, extra_full_uninfo_error],\n",
    "    \n",
    "    'Inter_avg_log loss': [unreal_inter_avg_info_loss, real_inter_avg_info_loss, inter_avg_uninfo_loss],\n",
    "    'Inter_Full_log loss':[unreal_inter_full_info_loss, real_inter_full_info_loss, inter_full_uninfo_loss],\n",
    "    \n",
    "    'Extra_avg_log loss': [unreal_extra_avg_info_loss, real_extra_avg_info_loss, extra_avg_uninfo_loss],\n",
    "    'Extra_Full_log loss':[unreal_extra_full_info_loss, real_extra_full_info_loss, extra_full_uninfo_loss]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inter_avg_error</th>\n",
       "      <th>Inter_Full_error</th>\n",
       "      <th>Extra_avg_error</th>\n",
       "      <th>Extra_Full_error</th>\n",
       "      <th>Inter_avg_log loss</th>\n",
       "      <th>Inter_Full_log loss</th>\n",
       "      <th>Extra_avg_log loss</th>\n",
       "      <th>Extra_Full_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unreal</th>\n",
       "      <td>0.279561</td>\n",
       "      <td>0.591216</td>\n",
       "      <td>0.248586</td>\n",
       "      <td>0.523363</td>\n",
       "      <td>0.740193</td>\n",
       "      <td>2.522568</td>\n",
       "      <td>0.740193</td>\n",
       "      <td>2.583182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.590789</td>\n",
       "      <td>0.248586</td>\n",
       "      <td>0.523363</td>\n",
       "      <td>0.743428</td>\n",
       "      <td>2.528782</td>\n",
       "      <td>0.815673</td>\n",
       "      <td>2.655478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uninformed</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Inter_avg_error  Inter_Full_error  Extra_avg_error  \\\n",
       "Unreal             0.279561          0.591216         0.248586   \n",
       "Real               0.279518          0.590789         0.248586   \n",
       "Uninformed         0.500000          0.937500         0.500000   \n",
       "\n",
       "            Extra_Full_error  Inter_avg_log loss  Inter_Full_log loss  \\\n",
       "Unreal              0.523363            0.740193             2.522568   \n",
       "Real                0.523363            0.743428             2.528782   \n",
       "Uninformed          0.937500            1.000000             4.000000   \n",
       "\n",
       "            Extra_avg_log loss  Extra_Full_log loss  \n",
       "Unreal                0.740193             2.583182  \n",
       "Real                  0.815673             2.655478  \n",
       "Uninformed            1.000000             4.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.index = ['Unreal', 'Real', 'Uninformed']\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm2inch(*tupl):\n",
    "    \"\"\"This function is for the actual size (cm) of plots\n",
    "    Input: \n",
    "        tuple: for example (12, 13) means 12cm, 13 cm\n",
    "    Output:\n",
    "        tuple: for python figsize\n",
    "    \"\"\"\n",
    "    inch = 2.54\n",
    "    if isinstance(tupl[0], tuple):\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1133.86x566.929 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, ((ax2, ax1), (ax4, ax3)) = plt.subplots(2,2, sharey=False, sharex=True)\n",
    "fig.set_size_inches(cm2inch(40, 20))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(df_extrafull))\n",
    "ax1.bar(ind-width, df_interfull[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=df_interfull[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, df_interfull[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=df_interfull[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, df_extrafull[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=df_extrafull[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, real_inter_full_info_error, real_extra_full_info_error]\n",
    "inter_error_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax1.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax1.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax2.bar(ind-width, df_inter_average[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=df_inter_average[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, df_inter_average[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=df_inter_average[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, df_extra_average[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=df_extra_average[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "\n",
    "ax2.set_title('Individual phase average error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax2.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_avg_uninfo_error, real_inter_avg_info_error, real_extra_avg_info_error]\n",
    "avg_error_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax2.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax2.legend(fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, df_interfull[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=df_interfull[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, df_interfull[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=df_interfull[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, df_extrafull[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=df_extrafull[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [inter_full_uninfo_loss, real_inter_full_info_loss, real_extra_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Full sphase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "\n",
    "ax4.bar(ind-width, df_inter_average[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=df_inter_average[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax4.bar(ind, df_inter_average[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=df_inter_average[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax4.bar(ind+width, df_extra_average[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=df_extra_average[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "\n",
    "avg_loss_base = [inter_avg_uninfo_loss, real_inter_avg_info_loss, real_extra_avg_info_loss]\n",
    "avg_loss_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "for i in range(len(avg_loss_base)):\n",
    "    ax4.axhline(y=avg_loss_base[i], color=colors[i], linestyle='-', label=avg_loss_name[i])\n",
    "\n",
    "ax4.set_title('Individual sphase average logloss', fontsize=fontsize)\n",
    "ax4.set_xticks(ind)\n",
    "ax4.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax4.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAEDCAYAAAAvJ7nlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABJqUlEQVR4nO3de3xU1dn3/89FQA6CWgQRRARbRS1i1AgiWIIWkWpFFG9FrNLDD/EAxT62oq0yqPctfeSxVFEprRhbT60HhCKtSEvEA8pBEKIUsJgqWhHpDRJOErh+f+xNHCYzyeQwM5nJ9/16zSv7sPbe1x7IlVmz1l7L3B0RERERERGRdGmS6QBERERERESkcVFFVERERERERNJKFVERERERERFJK1VERUREREREJK1UERUREREREZG0UkVURERERERE0koV0UbAzPaa2QozKzGzZ8ysVRqvHTGzm9N1vYbIzG7LdAwiucDM3Mz+ELXe1Mw2mdmccP0iMxtfD9cp3H/OJMt3NbOSul43m5nZxWZ2UqbjEMl2DTXPVXGeUjNrV9fzJHmtYjMrqOWxjf7zaEOkimjjsNPd8929B/AlMDrZA80sL3VhpZ+ZNa1qPdnjYvZV9x6pIipSP7YDPcysZbg+EPh4/053n+3ukzISWQMTm5eSyeUWSPi5oJpzXAyoIipSd8pz0mioItr4vAp8I/abMDObamYjw+VSM7vDzF4DLjOz88xskZm9Hbaoto49afgt1RQzeyNsee0VtfukcP96MxsbdcwLZrbMzN41s1HhtjwzKwrPscrMbgq3f93M/hqWf9XMTogTw8FmNsPMlpjZcjMbEm4fGcb9Z2BenPW2YSwrzexNM+sZHhcxs+lmNg/4fcy1Cs1sgZk9Cayq4n4mAS3DFuknwm1XmdnicNtvcq2yL5JifwEuCJeHA0/t3xH+bk8Nl2eZ2dXh8rVRv39x85mZnW9m/wjz3iXxLhyef1aYi9aY2YSo3Xlm9tvw93/e/g+RZvb/hTnpHTN7zsIeKWZ2WZjn3jGzheG2PDO7Nyy/0syuTRBH3BxiZmVmdqeZvQX0ibP+k/CaJWY2Ljymq5mtNrOHgLeBo2OuFfv3oNL9mNlZwEXAvWFMX08mZ4tIQpnMc9+Myi8rzey4ME/8w8weC7c9awf2rhsTXmvV/t91M+tlwWfC5eHP7onOH26v0WcjMxseXq/EzH4Ztf2HZrbWgs+dv93/XsUcm2/B572VZjbTzL4Wbh9rZu+F258Ot/UPY1oR3kubquKSGnJ3vXL8BZSFP5sCs4DrgEJgTlSZqcDIcLkU+Fm43A5YCBwcrt8C3BHnGsXAb8PlbwEl4XIEeANoHp5rM9As3Nc2/NkSKAEOB04HXo4672Hhz78Bx4XLvYG/x4nhf4Cr9h8HrAUOBkYCG6KuF7v+ADAhXD4HWBEV+zKgZZxrFRJ8a9ktalul+4l+/8PlE4E/R70HDwFXZ/r/iF56ZcMLKAN6As8CLYAV0bks/N2eGi53AN4Hzg5zQdtE+Sw810fAcYABf4rOj1HXHwn8O8xV+3/PC4CuQDmQH5b7U1QuOjzq+LuBMeHyKuCocPmw8Oco4BfhcnNgaXSOCbcnzCGAA/8VVbZinSC3rgpzYmvgXeDUMPZ9wJkJ3vNSwr8H1dxPETAsal+1OVsvvfSq/GoAee4BYES4fFCY67qG+aRvuH0GcHO4XBqVB64HfhcuHwI0DZe/DTxXxfmT+mxE8FmzAOgEfAi0J/hs+3eCXhmdwnjaAs0IGl/2v1eRqJhXAv3D5TuBKeHyJ0DzcPmw8Oefo+679f570qt+Xkl1S5Ss19LMVoTLrwKPAGdVc8wfw59nEnS3et3MIEgaixIc8xSAuy80s0PM7LBw+4vuvhvYbWafESTODcBYMxsaljmaIDmuAY41sweAFwlaLFuH8T4TxgDBh7RY5wEX2VfPALQAuoTLL7v7f6LKRq/3Ay4NY/+7mR1uZoeG+2a7+84E97vY3T+IWo93P5tjjjmX4APhkvBeWgKfJTi/iMRw95Vm1pWglWBuFeU2mtkdwAJgqLv/x8wuJH4+OwH4wN3XAZjZ4wSVwnhedvfNYbnnCfLHC+HxK8Iyywg+uEHQxe5ugi/HWgMvhdtfB4rM7E/A8+G284CeZjYsXD+UII9E55mqcshe4LmostHr/YCZ7r49KvazgdnAv9z9zQT3C1/9PajqfirUIGeLSBwZznOLgJ+bWWfgeXdfF57nI3d/PSzzODAWmByu789hy/iqpfVQ4LGwxdMJKoaJzl/Tz0ZnAMXuvim8lycIGkEAXtn/+c7MngGOjz4w/Hx3mLu/Em56DHgmXF4JPGFmLxDkdQhy9X3hNZ539w1VxCU1pIpo47DT3fOjN5hZOQd2zW4Rc8z2/UUJPngNT+I6nmB9d9S2vUBTMysk+Iasj7vvMLNioIW7/6+ZnQIMAm4A/gsYB2yJvYc4DLjU3dccsNGsd9T97Be9blTmccrFqtiX6H4SxPiYu99axXlFpGqzCT4AFRK0TiZyMsGXQZ3C9bj5zMzyqZy/Ekk2z+1/vqsIuNjd37Hg8YdCAHcfHeamC4AVYQxG0LJQqXIXHS6Jc8gud9+bYD1entuvqjwXu7+IOPcTownJ5WwRSSwjec7dn7SgO/8FwEtm9iNgfZxjo9f357+9fFW3uAtY4O5Dw0p1cRXnr+lno0T5rKo8l4wLCCq0FwG3m9k33X2Smb0IfAd408y+7e7/qON1JKRnRBuvfxE8u9k8/Hbo3ATl3gT6mtk3ACx4Huj4BGUvD8v0A7a6+9Yqrn8o8L9hpe0EgpZXLBh5rYm7PwfcDpzm7l8AH5jZZWEZCyursV4ieE7BwnKnVnH9aAuBEeExhcDn4TVrIu79hPaY2f5vAv8GDDOzI8LrtTWzY2p4LZHGbgZwp7uvSlTAgufUBxN0P73ZzLqROJ/9A+hmZl8PD6/qi7eB4e9tS4KuYK9XURagDfDvMAeMiIrv6+7+lrvfAXxO0IviJeC6/fnCzI43s4NjzlfbHLIQuDi854OBoQQ9ZGoq7v0A28J91CBni0hiGclzZnYssN7d7yeoDPcMd3Uxsz5Rx75WTfyH8tUgSyOrOX9N89pbQH8za2fBs6TDgVeAxeH2r1kwyOSlsQeGn03/18zODjd9D3jFgoHajnb3BcDPCHt9hLl6lbv/kuBxCT3vXo9UEW2k3P0jgucDVgJPAMsTlNtEkECeMrOVBAku0S/h/5rZG8A04IfVhPBXgpbRlQTfmu3vFnYUUGxBV+IiYP+3YyOAH5rZOwTPNg2Jc867CLp+rLRgKoW7qolhvwhQEMYyCbgmyeOiJbofgOlhTE+4+3vALwi6HK8EXgY61uJ6Io2Wu29w918n2m9mzYHfAj9w90+A/0Pwoe5z4uQzd99F0EXtRQsG8fhXFZd/DfgDwXNbz7n70mrCvZ3gQ9PLBB8E97vXwoE2CCqJ7wC/A94D3g63/4aYnku1zSHu/jZBTl0cxvM7d4+b92t5P08DP7VgMI+vk1zOFpEEMpjnLgdKws9hJ/DVYI2rgWvCc7YFHq7mFv4vcI+ZvQ5EDzxU6fw1zWvu/m+Cz4cLCHLn2+4+y90/Jhgv5C1gPkE+jdcocg1BDl4J5BM8J5oHPG5mqwg+E//K3bcA4ywcWA7YSTCQlNQTc0+2N5JIYmFX1JuT+FAmIpKVwq6oBe5+Y6ZjERFJl7Br7RwPpgFs0MystbuXhS2iM4EZ7j4z03FJfGoRFRERERGRXBAJW1tLCAZ6eyGj0UiV1CIqIiIiIiIiaaUWUREREREREUkrVURFREREREQkrVQRFRERERERkbRqWn2RhqVdu3betWvXTIchIhm2bNmyz929fabjqA/KayICymsiknuqymtZVxHt2rUrS5dqhhCRxs7MqprrMasor4kIKK+JSO6pKq+pa66IiIiIiIiklSqiIiIiIiIiklaqiIqIiIiIiEhaZd0zoiLpsmfPHjZs2MCuXbsyHUqj1qJFCzp37kyzZs0yHYqIiIiI1JOUVkTN7Hzg10Ae8Dt3nxSzvxCYBXwQbnre3e9MZUwiydqwYQNt2rSha9eumFmmw2mU3J3NmzezYcMGunXrlulwRERERKSepKwiamZ5wIPAQGADsMTMZrv7ezFFX3X3C1MVh0ht7dq1S5XQDDMzDj/8cDZt2pTpUERERESkHqXyGdFewPvuvt7dvwSeBoak8Hoi9U6V0MzTv4GIiIhI7kll19yjgI+i1jcAveOU62Nm7wCfADe7+7tVnnXNGigsrK8YRRKbMAGaZNd4XktXreL3s2Zx/y9+UWW5+3//ex5++mlOO+kknpg8OU3R1cGnn8J112U6itRRXhMREZFGJpWfsuM1Y3jM+tvAMe5+CvAA8ELcE5mNMrOlZrZ0z5499RulSA4pOPnkaiuhAA899RRzp0/PjkqoiIhImkUiEcys0isSiWQ6NJGckcoW0Q3A0VHrnQlaPSu4+xdRy3PN7CEza+fun8eUmw5MBygoKHCKi1MWtEiF1auhe/eMhlBaWsqFF15ISUkJAJMnT6asrIzi4mJ69+7NggUL2LJlC4888ghnn302xcXFTJ48mTlz5hCJRPjwww9Zv349H374IePGjWPs2LGMHj2a9Rs2cNG4cfzgBz/gmmuu4Qc/+AHr16+nVatWTJ8+nZ49e2b0vivZt49Kv/e51GW3e/fK9ycijU8u5bUsF4lEiEQiFIa9VYqVo0XqXSorokuA48ysG/AxcAVwZXQBMzsS2Ojubma9CFpoN6cwJpHaGTcOVqyo33Pm58OUKbU+vLy8nMWLFzN37lwmTpzI/PnzK5X5xz/+wYIFC9i2bRvdu3fnuuuuY9q0afz1r39lwYIFtGvXjjFjxnDqqafywgsv8Pe//52rr76aFfV9ryIiIiIiUVJWEXX3cjO7EXiJYPqWGe7+rpmNDvdPA4YB15lZObATuMLdY7vvikgcl1xyCQCnn346paWlcctccMEFNG/enObNm3PEEUewceNGOnfufECZ1157jeeeew6Ac845h82bN7N161YOPfTQlMYvIiIiIo1XSucRdfe5wNyYbdOilqcCU1MZg0i9qEPLZV00bdqUffv2Vazv2rWrYrl58+YA5OXlUV5eHvf4/WWqKhfvux+NVCsi0riE0+4tBT6OnVbPgj8Kvwa+A+wARrr72+mPUkRySXYNCSrSyHTo0IHPPvuMzZs3s3v3bubMmVPv1/jWt77FE088AQTPwLRr145DDjmk3q8jIiIN2o+B1Qn2DQaOC1+jgIfTFZSI5K6UtoiKSN00a9aMO+64g969e9OtWzdOOOGEer9GJBLh+9//Pj179qRVq1Y89thj9X4NERFpuMysM3AB8N/AT+IUGQL8Pnx86k0zO8zMOrr7vxOeNEempZqyf8yEHLgXkYZGFVGRBm7s2LGMHTs24f527dpVPCNaWFhYMcJf7BDz+0feBQ54prRt27bMmjWrvsIVEZHsMwX4GdAmwf54c8MfBRxQETWzUQQtpvSMejRERCQeVURFREREGikzuxD4zN2XmVlhomJxtlUaYCAXp9sbp+lbROqminFH9IyoiIiISOPVF7jIzEqBp4FzzOzxmDLVzg0vIlJTqoiKiIiINFLufqu7d3b3rgRzvv/d3a+KKTYbuNoCZwJbq3w+VEQkCaqIioiIiMgBzGz0/rnfCabiWw+8D/wWuD5jgUnKRSIRzKzSK3bsCZG60jOiIiIiIoK7FwPF4XL0vO8O3JCZqCTdIpEIkUikYvBDPR8rqaIWUREREREREUkrVURFREREREQkrVQRFZEKpaWl9OjRI+H+pUuXVjmnKcCWLVt46KGH6js0EREREckhqoiK5Kjy8vJ6P2dBQQH3339/lWVqUxF1d/bt21eX0EREREQki2iwIpEkjFu3jhVlZfV6zvzWrZly3HFVliktLeXCCy+kpKQEgMmTJ1NWVkZxcTG9e/dmwYIFbNmyhUceeYSzzz6boqIiXnzxRXbt2sX27dv585//zJgxY1i1ahXl5eVEIhGGDBlCaWkp3/ve99i+fTsAU6dO5ayzzqo25uLiYiZPnsycOXOIRCJ8+OGHrF+/ng8//JBx48YxduxYxo8fzz//+U/y8/MZOHAg9957L/feey9/+tOf2L17N0OHDmXixImUlpYyePBgBgwYwKJFi3jhhRc45phj6v7GioiIiEiDp4qoSJYqLy9n8eLFzJ07l4kTJzJ//nwAFi1axMqVK2nbti233XYb55xzDjNmzGDLli306tWLb3/72xxxxBG8/PLLtGjRgnXr1jF8+HCWLl1a4xj+8Y9/sGDBArZt20b37t257rrrmDRpEiUlJaxYsQKAefPmsW7dOhYvXoy7c9FFF7Fw4UK6dOnCmjVrePTRR9WVV0RERKSRUUVUJAnVtVxmwiWXXALA6aefTmlpacX2gQMH0rZtWyCoBM6ePZvJkycDsGvXLj788EM6derEjTfeyIoVK8jLy2Pt2rW1iuGCCy6gefPmNG/enCOOOIKNGzdWKjNv3jzmzZvHqaeeCkBZWRnr1q2jS5cuHHPMMZx55pm1uraIiIiIZC9VREUasKZNmx7w7OSuXbsqlps3bw5AXl7eAc+DHnzwwRXL7s5zzz1H9+7dDzhvJBKhQ4cOvPPOO+zbt48WLVrUKr79McSLIzqGW2+9lWuvvfaA7aWlpQfEKiIiIiKNhwYrEmnAOnTowGeffcbmzZvZvXs3c+bMqdHxgwYN4oEHHiCYixyWL18OwNatW+nYsSNNmjThD3/4A3v37q23mNu0acO2bdsOiGHGjBmUhc/Yfvzxx3z22Wf1dj0RERERyT5qERVpwJo1a8Ydd9xB79696datGyeccEKNjr/99tsZN24cPXv2xN3p2rUrc+bM4frrr+fSSy/lmWeeYcCAAfXaMnn44YfTt29fevToweDBg7n33ntZvXo1ffr0AaB169Y8/vjj5OXl1ds1RURERCS72P6WkmxRUFDgtRlURaSmVq9ezYknnpjpMIT4/xZmtszdCzIUUr1SXhMRUF5riAoLC4Fg1PjGpjHfu9SfqvKauuaKiIiIiIhIWqlrrohU8tJLL3HLLbccsK1bt27MnDkzQxGJiIiISC5RRVREKhk0aBCDBg3KdBgNkpmdD/wayAN+5+6TYvYfCjwOdCHIsZPd/dG0ByoiIiLSgKlrrohIkswsD3gQGAycBAw3s5Niit0AvOfupwCFwP8zs4PSGqiIiIhIA6cWURGR5PUC3nf39QBm9jQwBHgvqowDbczMgNbAf4DKE6yKiDQAZtYCWAg0J/hc+Ky7T4gpUwjMAj4INz3v7nemMcyUO/mxk+NuX//p+ir3A6y6ZlVKYhLJdaqIiogk7yjgo6j1DUDvmDJTgdnAJ0Ab4HJ335ee8EREamw3cI67l5lZM+A1M/uLu78ZU+5Vd78wA/GJSI5S11wRkeRZnG2xc2ANAlYAnYB8YKqZHVLpRGajzGypmS3dtGlTfccpIpIUD5SFq83CV3bN7SciWUkVURGpUFpaSo8ePertfMXFxbzxxhv1dr4GYANwdNR6Z4KWz2jfJ+i25u7+PkFXthNiT+Tu0929wN0L2rdvn7KARUSqY2Z5ZrYC+Ax42d3filOsj5m9Y2Z/MbNvpjdCEclFqoiK5Kjy8sw/llhVRbQhxFcLS4DjzKxbOADRFQTdcKN9CJwLYGYdgO7A+rRGKSJSA+6+193zCb5c62Vmsd9Ivg0cEw7C9gDwQrzzqKeHiNSEnhEVScK6cesoW1FWfcEaaJ3fmuOmHFdlmdLSUi688EJKSkoAmDx5MmVlZRQXF9O7d28WLFjAli1beOSRRzj77LMpKirixRdfZNeuXWzfvp0///nPjBkzhlWrVlFeXk4kEmHIkCGUlpbyve99j+3btwMwdepUzjrrrGpj3rt3L+PHj6e4uJjdu3dzww03cO2113LfffdRUlLCjBkzWLVqFcOHD+dPf/oT06ZNIy8vj8cff5wHHniARx55hLZt27J8+XJOO+00Lr/8csaNG8fOnTtp2bIljz76KN27d6/7m5si7l5uZjcCLxFM3zLD3d81s9Hh/mnAXUCRma0i6Mp7i7t/nrGgRUSS5O5bzKwYOB8oidr+RdTyXDN7yMzaxeY2d58OTAcoKChQ914RqZIqoiJZqry8nMWLFzN37lwmTpzI/PnzAVi0aBErV66kbdu23HbbbZxzzjnMmDGDLVu20KtXL7797W9zxBFH8PLLL9OiRQvWrVvH8OHDWbp0abXXfOSRRzj00ENZsmQJu3fvpm/fvpx33nmMGzeOwsJCZs6cyX//93/zm9/8hpNOOonRo0fTunVrbr755orj165dy/z588nLy+OLL75g4cKFNG3alPnz53Pbbbfx3HPPpfR9qyt3nwvMjdk2LWr5E+C8dMclIlIbZtYe2BNWQlsC3wZ+GVPmSGCju7uZ9SLoUbc5/dGKSC5RRVQkCdW1XGbCJZdcAsDpp59OaWlpxfaBAwfStm1bAObNm8fs2bOZPHkyALt27eLDDz+kU6dO3HjjjaxYsYK8vDzWrl2b1DXnzZvHypUrefbZZwHYunUr69ato1u3bhQVFdGzZ0+uvfZa+vbtm/Acl112GXl5eRXHX3PNNaxbtw4zY8+ePTV+H0REpE46Ao+F8yQ3Af7k7nNienoMA64zs3JgJ3CFu6vFU0TqRBVRkQasadOm7Nv31cwfu3btqlhu3rw5AHl5eQc8b3nwwQdXLLs7zz33XKXurpFIhA4dOvDOO++wb98+WrRokVQ87s4DDzzAoEGDKu1bt24drVu35pNPYsfuOVB0fLfffjsDBgxg5syZlJaWUlhYmFQcIiJSP9x9JXBqnO3RPT2mEkxNJSJSb1I6WJGZnW9ma8zsfTMbX0W5M8xsr5kNS2U8ItmmQ4cOfPbZZ2zevJndu3czZ86cGh0/aNAgHnjgAfZ/cb18+XIgaIns2LEjTZo04Q9/+AN79+5N+nwPP/xwRcvl2rVr2b59O1u3buXHP/4xCxcuZPPmzRUtpm3atGHbtm0Jz7d161aOOuooAIqKimp0byIiIiKSvVJWEQ27eDwIDAZOAoab2UkJyv2SYPAPEYnSrFkz7rjjDnr37s2FF17ICSdUmgWkSrfffjt79uyhZ8+e9OjRg9tvvx2A66+/nscee4wzzzyTtWvXHtBKWZUf/ehHnHTSSZx22mn06NGDa6+9lvLycm666Sauv/56jj/+eB555BHGjx/PZ599xne/+11mzpxJfn4+r776aqXz/exnP+PWW2+lb9++SVeGRURERCT7Waq6+JtZHyDi7oPC9VsB3P2emHLjgD3AGcAcd3+2qvMWFBR4MoOqiNTV6tWrOfHEEzMdhhD/38LMlrl7QYZCqlfKayICymuZdPJjJ8fdvv6eYPatY289NuGxq65ZlZKYMm3/4zLFxcUZjUOyW1V5LZVdc48CPopa3xBuiw7sKGAoMA0RERERERFpFFI5WJHF2Rbb/DqFYI69vWbxiocnMhsFjALo0qVLfcUnIgm89NJL3HLLLQds69atGzNnzsxQRCIiIiKSS1JZEd0AHB213hmIHU6zAHg6rIS2A75jZuXu/kJ0IU2QLJJegwYNijsyroiIiIhIfUhlRXQJcJyZdQM+Bq4Arowu4O7d9i+bWRHBM6IvpDAmERERERERybCUVUTdvdzMbiQYDTcPmOHu78ZMkCwiIiIiIiKNTCpbRHH3ucDcmG1xK6DuPjKVsYiIiIiIiEjDkMpRc0VEREREREQqSWmLqEgu6Tr+xXo9X+mkC6otc9ZZZ/HGG29UWWbKlCmMGjWKVq1a1TmmoqIizjvvPDp16lSj46ZNm0arVq24+uqr6xyDiIiIiOQ+tYiKNGDVVUIhqIju2LGjRufdu3dv3O1FRUV88kns4NZVHwMwevRoVUJFREREJGmqiIo0YK1btwaguLiYwsJChg0bxgknnMCIESNwd+6//34++eQTBgwYwIABAwCYN28effr04bTTTuOyyy6jrKwMgK5du3LnnXfSr18/nnnmmUrXevbZZ1m6dCkjRowgPz+fnTt3Vjrmt7/9LWeccQannHIKl156aUUFOBKJMHnyZAAKCwu55ZZb6NWrF8cffzyvvvpqOt4qEREREckiqoiKZInly5czZcoU3nvvPdavX8/rr7/O2LFj6dSpEwsWLGDBggV8/vnn3H333cyfP5+3336bgoIC7rvvvopztGjRgtdee40rrrii0vmHDRtGQUEBTzzxBCtWrKBly5aVjrnkkktYsmQJ77zzDieeeCKPPPJI3FjLy8tZvHgxU6ZMYeLEial5Q0REREQka+kZUZEs0atXLzp37gxAfn4+paWl9OvX74Ayb775Ju+99x59+/YF4Msvv6RPnz4V+y+//PIaXzf6mJKSEn7xi1+wZcsWysrKGDRoUNxjLrnkEgBOP/10SktLa3xNERERSb2THzs54b71n66vtsyqa1bVe0zSeKgiKpIlmjdvXrGcl5dHeXl5pTLuzsCBA3nqqafinuPggw+u8XWjjxk5ciQvvPACp5xyCkVFRRQXF1cZa6I4RURERKRxU9dckSzXpk0btm3bBsCZZ57J66+/zvvvvw/Ajh07WLt2ba3OFc+2bdvo2LEje/bs4Yknnqhb4CIiknFm1sLMFpvZO2b2rplVep7CAveb2ftmttLMTstErCKSW9QiKpKkZKZbyYRRo0YxePBgOnbsyIIFCygqKmL48OHs3r0bgLvvvpvjjz8+qXONHDmS0aNH07JlSxYtWlRp/1133UXv3r055phjOPnkk6ustIqISFbYDZzj7mVm1gx4zcz+4u5vRpUZDBwXvnoDD4c/RURqzdw90zHUSEFBgS9dujTTYUgjsHr1ak488cRMhyHE/7cws2XuXpChkOqV8pqIQObzmpm1Al4DrnP3t6K2/wYodvenwvU1QKG7/zvRubItr8U+B7lx5kY2zdpUqVz7Ie3pMLTDAduy+TnJKp8RvSd4RvTYW49NWCab713So6q8phZRERERkUbMzPKAZcA3gAejK6Gho4CPotY3hNsSVkSzXYehHSpVOEWkfukZUZFG6IYbbiA/P/+A16OPPprpsEREJAPcfa+75wOdgV5m1iOmiMU7LHaDmY0ys6VmtnTTpsqtiekWiUQws0qvSCSS6dBEBLWIijRKDz74YKZDEBGRBsbdt5hZMXA+UBK1awNwdNR6Z+CTOMdPB6ZD0DU3dZEmJxKJEIlEKCwsBEg40ruIZIZaREVEREQaKTNrb2aHhcstgW8D/4gpNhu4Ohw990xga1XPh4qIJEMtoiIiIiKNV0fgsfA50SbAn9x9jpmNBnD3acBc4DvA+8AO4PuZCjahyKGJ95Vur75Mty71G4+IVEsVUREREZFGyt1XAqfG2T4tatmBG1IZR9fxL1ba9umT49n9UUml7c2P7sGRV046YFtpi5SFJiIpooqoiIiIiDQ4sZVNEcktqoiKJKuqLj21Ot/WaoucddZZvPHGG1WWmTJlCqNGjaJVq1Z1DqmoqIjzzjuPTp061fjY4uJiDjroIM4666w6xyHpF4lEmDhxYqXtEyZM0AiTIpKVIsW7mPjKlxXrNvELACb0P4hIoZpQRTJNFVGRBqy6SigEFdGrrrqqRhXRvXv3kpeXV2l7UVERPXr0qHVFtHXr1qqIZimNLikiuSZS2EIVTpEGTKPmijRgrVu3BoJKQWFhIcOGDeOEE05gxIgRuDv3338/n3zyCQMGDGDAgAEAzJs3jz59+nDaaadx2WWXUVZWBkDXrl2588476devH88880ylaz377LMsXbqUESNGkJ+fz86dO1m2bBn9+/fn9NNPZ9CgQfz738Egiffffz8nnXQSPXv25IorrqC0tJRp06bxq1/9ivz8fF599dU0vUMiIiIi9UNzz6aXKqIiWWL58uVMmTKF9957j/Xr1/P6668zduxYOnXqxIIFC1iwYAGff/45d999N/Pnz+ftt9+moKCA++67r+IcLVq04LXXXuOKK66odP5hw4ZRUFDAE088wYoVK2jatCljxozh2WefZdmyZfzgBz/g5z//OQCTJk1i+fLlrFy5kmnTptG1a1dGjx7NTTfdxIoVKzj77LPT9r5I5ukPt4iI5IJIJIK7079/f/r374+74+45//csU3/H1TVXJEv06tWLzp07A5Cfn09paSn9+vU7oMybb77Je++9R9++fQH48ssv6dOnT8X+yy+/POnrrVmzhpKSEgYOHAgE3Xk7duwIQM+ePRkxYgQXX3wxF198cV1uS3KAuvWKiIhkr0z9HVdFVCRLNG/evGI5Ly+P8vLySmXcnYEDB/LUU0/FPcfBBx+c9PXcnW9+85ssWrSo0r4XX3yRhQsXMnv2bO666y7efffdpM8rIiIiIqKKqEiWa9OmDdu2baNdu3aceeaZ3HDDDbz//vt84xvfYMeOHWzYsIHjjz++RucC6N69O5s2bWLRokX06dOHPXv2sHbtWk488UQ++ugjBgwYQL9+/XjyyScpKyujTZs2fPHFF6m8ValCjUa9rcvE70mM9iwiIiJSHVVERZLVQD+Ajxo1isGDB9OxY0cWLFhAUVERw4cPZ/fu3QDcfffdSVdER44cyejRo2nZsiWLFi3i2WefZezYsWzdupXy8nLGjRvH8ccfz1VXXcXWrVtxd2666SYOO+wwvvvd7zJs2DBmzZrFAw88kLPPiZrZ+cCvgTzgd+5eaaI7MysEpgDNgM/dvX99xhBv4vctr62NW3bK/LUU7TqwvCZ+FxERkUxTRVSkAds/4m1hYWFFv32AqVOnViyPGTOGMWPGVKyfc845LFmypNK5SktLq73epZdeyqWXXlqxnp+fz8KFCyuVe+211yptO/7441m5cmW118hmZpYHPAgMBDYAS8xstru/F1XmMOAh4Hx3/9DMjkhHbIf1G8Fh/Uak41IiIiIidaZRc9NMo0uKZLVewPvuvt7dvwSeBobElLkSeN7dPwRw98/SHKOIiIhIg6eKaJo11mGhpWG54YYbyM/PP+D16KOPZjqsbHAU8FHU+oZwW7Tjga+ZWbGZLTOzq+OdyMxGmdlSM1u6adOmFIUrIiIi0jAl3TXXzA529+2pDEZE0uPBBx/MdAgNQi3ymsXZ5jHrTYHTgXOBlsAiM3vT3Q94iNPdpwPTAdqcdJIXLl+edBCf9qrbQ56FTe5OuG/F+H1BmSMTfE9ZRZwrRo4Mjq3BvYiIiEjjVG2LqJmdZWbvAavD9VPM7KGURyYikiJ1yGsbgKOj1jsDn8Qp81d33+7unwMLgVPqIeyUKt2yj1dK97J1l7N1l/NK6V5eKd1L6ZZ9mQ5NREREclAyLaK/AgYBswHc/R0z+1ZKoxIRSa3a5rUlwHFm1g34GLiC4JnQaLOAqWbWFDgI6B1eL6HurVpRfOqpSQff9Y+VR82tieIWv0i+8JaY9YsTjx5deNNNwfnTNBG2SK6J1+UiW+1Ys4Plhcn3jhi/vm49PZZX0dMjGWNb1P76yx/N3l4gYz8dm3Dfzg93AtDynpYJy2TzvVdl5IqRADX6P5wL0n3fSXXNdfePzA5Ij3tTE46ISHrUJq+5e7mZ3Qi8RDB9ywx3f9fMRof7p7n7ajP7K7AS2EcwxUtJ/d+BiIiISPZKpiL6kZmdBbiZHQSMJezOVp3q5tszsyHAXQQf1sqBce5eeV4IkQbg5MdOrtfzrbpmVb2dq7S0lDfeeIMrr4xtnKu5LVu28OSTT3L99dfX6vgpU6YwatQoWrVqVedYUqjWec3d5wJzY7ZNi1m/F7i3nmIVEUkZMzsa+D1wJMHnsenu/uuYMoUEvT0+CDc97+53VnXeVt1bcWpx8j09hsaZH7kmSmvS0yOOq7t1qfWx9fn3PN2ufizueHoArL9nPQDH3npswjLZfO9VuamwcfbwScl9V9HVI5mK6GiCyuRRBM8+zQOq/YSazHx7wN+A2e7uZtYT+BNwQhIxiUiU0tJSnnzyybgV0fLycpo2TX7K4C1btvDQQw/VqSJ61VVXNfSKaK3ymohIDioH/o+7v21mbYBlZvZyzOc1gFfd/cJkT7pmx44aDVyWykHYkrG+Dl1zs3mAtvUdEnfN3fWTnWGZxF1zs/neq9JYB99L930nM31Ld3cf4e4d3P0Id78KODGJ46qdb8/dy9x9/4iTB1N59MkGR/OASjo9/vjj9OrVi/z8fK699lreeustevbsya5du9i+fTvf/OY3KSkpYfz48bz66qvk5+fzq1/9iqKiIi677DK++93vct5551FWVsa5557Laaedxsknn8ysWbMSXnP8+PH885//JD8/n5/+9KcA3HvvvZxxxhn07NmTCRMmALB9+3YuuOACTjnlFHr06MEf//hH7r//fj755BMGDBjAgAED0vIe1VJt85qISE5x93+7+9vh8jaC3iGx01KJiNS7ZJpJHgBOS2JbrHjz7fWOLWRmQ4F7gCOAC5KIJ6MikQiRSITCwkKg8TXZS/qsXr2aP/7xj7z++us0a9aM66+/njVr1nDRRRfxi1/8gp07d3LVVVfRo0cPJk2axOTJk5kzZw4ARUVFLFq0iJUrV9K2bVvKy8uZOXMmhxxyCJ9//jlnnnkmF110ETHPSAIwadIkSkpKWLFiBQDz5s1j3bp1LF68GHfnoosuYuHChWzatIlOnTrx4otBd6qtW7dy6KGHct9997FgwQLatWuXtveqFmqb10REcpaZdQVOBd6Ks7uPmb1DMFL4ze7+bpzjRwGjALp06dJwB2GL4+Q6dM0tPj97u6eeXFXX3Puq75qbzfdelcY6+F4q7ruqQdgSVkTNrA9wFtDezH4StesQgmc+a3PdSi2e7j4TmBmOWHkX8O04sRyQ2EQag7/97W8sW7aMM844A4CdO3dyxBFHcMcdd3DGGWfQokUL7r///oTHDxw4kLZt2wLg7tx2220sXLiQJk2a8PHHH7Nx40aOPPLIauOYN28e8+bN49TwA0VZWRnr1q3j7LPP5uabb+aWW27hwgsv5Oyzz66Hu06teshrIiJZwcyaAK3d/Ysky7cGniMYryP2mLeBY9y9zMy+A7wAHBd7juj5kQsKChp8LzcRyayqWkQPAlqHZdpEbf8CGJbEuZOZb6+Cuy80s6+bWbtw7r3ofUps0ui4O9dccw333HPPAds//fRTysrK2LNnD7t27eLggw+Oe3z09ieeeIJNmzaxbNkymjVrRteuXdm1a1fScdx6661ce+21lfYtW7aMuXPncuutt3Leeedxxx131OAOM6Kuea3Rq2rQrvWfrq+2TK4ObCHSEJjZkwTPwO8FlgGHmtl94QBqVR3XjKAS+oS7Px+7P7pi6u5zzeyheJ/XRERqImFF1N1fAV4xsyJ3/1ctzl3tfHtm9g3gn+FgRacRfEjcXItrieScc889lyFDhnDTTTdxxBFH8J///Idt27YxZswY7rrrLj744ANuueUWpk6dSps2bdi2bVvCc23dupUjjjiCZs2asWDBAv71r8S/0rHnGjRoELfffjsjRoygdevWfPzxxzRr1ozy8nLatm3LVVddRevWrSkqKjrg+IbYNbce8pqISEN2krt/YWYjCEb3voWgQpqwImrBMxqPAKvd/b4EZY4ENoaf13oRjDGiz2siUifJPCO6w8zuBb4JVAwp5u7nVHVQMvPtAZcCV5vZHmAncHnU4EUiDUq6W3JOOukk7r77bs477zz27dtHs2bNGDJkCE2bNuXKK69k7969nHXWWfz973/n7LPPpmnTppxyyimMHDmSr33taweca8SIEXz3u9+loKCA/Px8Tjgh8eDUhx9+OH379qVHjx4MHjyYe++9l9WrV9OnTx8AWrduzeOPP87777/PT3/6U5o0aUKzZs14+OGHARg1ahSDBw+mY8eOLFiwIHVvUN3UKq+JiDRwzcLWzYuBqe6+x8yq+1zVF/gesMrMVoTbbgO6QMXntWHAdWZWTvB57Qp9XhORukqmIvoE8EfgQoLuHtcAm5I5eXXz7bn7L4FfJhtsRkQOjb+9dHvV+wEiW+s/HmlULr/8ci6//PK4+/Ly8njrra/Gk/jb3/52wP6R4RDcAO3atWPRokVJX/fJJ588YP3HP/4xP/7xjw/Y9vWvf51BgwZVOnbMmDGMGTMm6WtlSK3zmohIA/YboBR4B1hoZscQPHqQUDh/e1XjieDuU4Gp9RSjiAiQXEX0cHd/xMx+HNWt7ZVUB1ZfusaZIPnTJ8ez+6OSStubH92DI6+cdMC20rpNayUiDVNW5zURkXjc/X4gehS7f5lZg55LS0Qar2QqonvCn/82swsIBhzqnLqQUi+2sinSGG3evJlzzz230va//e1vHH744RmIKK1yLq+JiJjZj4FHgW3A7wimYhkPzMtkXCIi8SRTEb3bzA4F/g/BPHuHADelNKoqrNmxg8Lly5Mu/2mvujVpFja5O+72FeP3BfuPbJL44CriXBF2m6zJvUh6TWjShCY7dmQ6jNRp2ZI/vvFGpc2fA583sPv+9Msvua5+f1caVF7bsWYHywuTv7/x6+uW15YnyGvJGNsi8bV3frgTgJb3tEx87UeV80RS6Afu/mszGwS0B75PUDFVRVQkhkaBz7wqK6Jmlgcc5+5zgK2AundIo+EEU5cEAwpKprh75QmI60B5TURy2P4/WN8BHnX3d0x/xESkgaqyIurue83sIuBXaYqnWt1btaL41FOTLt/1j5WfEa2J4ha/iLu9sCgYrKh4ZPw5HAG4OPFgRYU3BY0vxcXFtY5NUuuDDz6gzc6dHH744aqMZoi7s3nzZpofcgjF3bodsK+2/yINMa+16t6KU4uTz2tD4zz7XhOlCfJaMq7u1iXhvvX3BN8gH3vrsQnL6BtkkSrU/U/NMjObB3QDbjWzNsC+Op9VGpWNMzeyadZX4/eVjAzGVWk/pD0dhnbIVFiSg5LpmvuGmU0lGGFy+/6N7v52yqISaQA6d+7Mhg0b2LRJg6lmUosWLejcud4f31ReE5Fc9EMgH1jv7jvM7HCC7rkiSeswtIMqnJIWyVREzwp/3hm1zYFGOd9epHgXE1/5smLdJgajok/ofxCRQg2xm0uaNWtGt5hWOMkZymsiknPcfZ+ZdQauDHvyvOLuf85wWCIicVVbEXV3PT8VJVLYQhVOkSynvCYiucjMJgFnEMyVDDDWzM5y91szGJaISFzJtIiKiIiISMP3HSDf3fcBmNljwHJAFVERaXCqmHtERERERLLMYVHLh2YqCBGR6lQ3fUsT4Ex3rzzZoIhIFlJeE5Ecdg+w3MwWEIzB+y3UGioiDVSVLaJh147/l6ZYRERSTnlNRHKVuz8FnAk8H776uPvTmY1KRCS+ZJ4RnWdmlwLPu3t9ziuf805+7OSE+9Z/ur7aMppvTyRllNdEJGeY2WkxmzaEPzuZWSdNTSUiDVEyFdGfAAcDe81sJ0FXD3f3Q1IamYhI6iiviUguqaqXh6amEpEGKZnpW9qkI5Bk7Vizg+WFy5MuP3593aZaWd7k7lofO7ZF4mvv/HAnAC3vaZn42o8mf58ikryGltey3caZG9k0a1PFesnIEgDaD2mvSdFF0kBTUolINkpq+hYzu4jggXeAYnefk7qQRERST3mt/nQY2kEVTpEGwMwuibN5K7DK3T9LcMzRwO+BI4F9wHR3/3VMGQN+TTA9zA5gpLr7imSvRI8GpvvRwWoronEmR/6xmfVz9/H1FkUNtOreilOLT026/NDxL9bpeqUtflHrY6/u1iXhvvX3BP/Qx956bMIyekZUpApWh0MbWF4TyUaRSISJEydW2j5hwgQikUj6AxKAHwJ9gAXheiHwJnC8md3p7n+Ic0w58H/c/W0zawMsM7OX3f29qDKDgePCV2/g4fCniEitJdMimmhyZH1gE5FspbwmUkeRSIRIJEJhYSEAxcXFGY1HgKBF80R33whgZh34qtK4EKhUEXX3fwP/Dpe3mdlq4CgguiI6BPh9OLjbm2Z2mJl1DI8VEamVKqdviXJY1LImRxaRXHBY1LLymojkgq77K6Ghz4Dj3f0/wJ7qDjazrsCpwFsxu44CPopa3xBuExGptWQqov9DMDlyUdhqsCzcJiKSrZTXRCQXvWpmc8zsGjO7BpgNLDSzg4EtVR1oZq2B54Bx7v5F7O44h1Sa+srMRpnZUjNbumnTpjiHSDpEIhHMrNJLXealoamya66ZNSHo5nEmwfNUBtzi7p+mITYRkXqnvCYiOewG4BKgH0Fuewx4LuxSm3BkXTNrRlAJfcLdn49TZANwdNR6Z+CT2ELuPh2YDlBQUKA5mjNE3eYlW1RZEXX3fWZ2o7v/ieBbNRGRrKa8JiK5yt3dzF4DviRosVwcVkITCkfEfQRY7e73JSg2G7jRzJ4meN50q54PFZG6SqZr7stmdrOZHW1mbfe/Uh6ZiEjqKK+JSM4xs/8CFgPDgP8C3jKzYdUc1hf4HnCOma0IX98xs9FmNjosMxdYD7wP/Ba4PjV3ICKNSTKj5v4g/HlD1DYHEs87IiLSsCmvCaApSCTn/Bw4Y/+coWbWHpgPPJvoAHd/jWomxApbVW+oqoyISE0l84zoeHf/Y5riERFJKeU1iaZnqSTHNNlfCQ1tJvkZEkRE0qrK5BTOsadvwEQkZyiviUgO+6uZvWRmI81sJPAiQbdaEZEGR8+IikhjVOu8Zmbnm9kaM3vfzMZXUe4MM9ubxPNZksU0TYI0JO7+U4JRa3sCpwDT3f2WzEYlkj02ztxIycgSdqzZwY41OygZWULJyBI2ztxY/cFSY3pGVEQao1rlNTPLAx4EBhJMZ7DEzGa7+3txyv0SeKneIpa6ixyaeF/p9urLRLZW3qSuvdLAuPtzBFOxiEgNdRjagQ5DO2Q6jEaj2hZRd+8W56VKqEiS1GLS8NQhr/UC3nf39e7+JfA0MCROuTEEHwQ/i7NPRKRemdk2M/sizmubmX2R6fhEROJJWBE1s59FLV8Ws+9/UhmUSC6JRCK4O/3796d///64O+6uimgG1ENeOwr4KGp9Q7gt+jxHAUOBabWPVEQkee7ext0PifNq4+6HZDo+EZF4quqaewXwf8PlW4FnovadD9yWqqBERFKkrnkt3hQHsZPFTwFucfe9wTzxCU5kNgoYBdClS5dqLiupEinexcRXvqxYt4lB49GE/gcRKWyRqbBERJKX6JGCZB456Ka/P5I5VVVELcFyvHURkWxQ17y2ATg6ar0z8ElMmQLg6bAS2g74jpmVu/sL0YXcfTrBoCIUFBTEVmYlTSKFLVThFBERyYCqnhH1BMvx1uOqbnRJMxthZivD1xtmdkoy5xURqaW65rUlwHFm1s3MDiJoYZ19wEmC5027untXgknkr4+thIqIiIg0dlW1iJ4SPuBuQMuoh90NqPbr4yRHl/wA6O/u/2tmgwlaB3rX4j5ERJJRp7zm7uVmdiPBaLh5wAx3f9fMRof79Vyo5KSTHzs54b71n66vssyqa1alJCYREcluCSui7p5Xx3NXjC4JYGb7R5esqIi6+xtR5d8k6OYmIpIS9ZDXcPe5xEwQn6gC6u4j63o9ERERkVxU7fQtdVDt6JIxfgj8Jd4OMxtlZkvNbOmmTZvqMUQREcl2miJJREQk+6SyIprM6JJBQbMBBBXRW+Ltd/fp7l7g7gXt27evxxBFRCTbaYokERGR7FPVM6J1lczokphZT+B3wGB335zCeERERERERKQBSGWLaLWjS5pZF+B54HvuvjaFsYiIiIiIiEgDkbIW0SRHl7wDOBx4KJxzr9zdC1IVU0OwceZGNs366jnXkpElALQf0p4OQztkKiwRkazQdfyLCfd9un5zlWVKNV2oiIhIg5HKrrnVji7p7j8CfpTKGBqaDkM7qMIpIpKF6jKFCWgaE2m4zGwGcCHwmbv3iLO/EJhFMO0ewPPufmfaAhSRnJTSiqiIiIiINHhFwFTg91WUedXdL0xPOFIXkeJdTHzly4p1mxhMmT2h/0FECtU1RBoOVURFREREGjF3X2hmXTMdh9SPSGELVTglK6giKiIiWW3La0+w9fWnKtb/9cug0ebQvsM5rN+ITIUlkmv6mNk7BDMg3Ozu78YWMLNRwCiALl26pDk8Eck2qoiKiEhWO6zfCFU4RVLrbeAYdy8zs+8ALwDHxRZy9+nAdICCgoK4c8eLiOyXyulbRERERCTLufsX7l4WLs8FmplZuwyHJSJZThVREREREUnIzI60cJ49M+tF8Plxc2ajEpFsp665IiIiIo2YmT0FFALtzGwDMAFoBhXT7g0DrjOzcmAncIW7q+utiNSJKqIi9SzRPIKaZ1BERBoidx9ezf6pBNO7iIjUG3XNFZGUiUQimFmlVyQSyXRoIiK1orwmIlI/1CIqIikTiUSIRCIUFhYCUFxcnNF4RKT+bJy5kU2zNlWsl4wsAaD9kPZ0GNohU2GlnPKaiEj9UEVUREREaqzD0A45XeEUEZHUUtdcERERERGRLFaXxwY2ztxIycgSdqzZwY41OygZWULJyBI2ztyY0pjVIioiIiIiIpLF6vLYQKZ6uKhFVNJGAzyISK7J1LfIIiIi2U4topI2GuBBRHKNnpMUERGpHbWIioiIiIiISFqpIipJU9daERERERGpD+qaK0lT11oREREREakPahEVERERERGRtFKLqIiIiIiISLaIHJp4X+n26st061K/8dSSWkRFREREREQkrdQiKvHV9ZuWyNb6jUdEREREpAqRSISJEydW2j5hwgQNrtkAqSIqIiIiIiJZTwNrZhdVREVERETiOPmxkxPuW//p+mrLrLpmVb3HlApmNgO4EPjM3XvE2W/Ar4HvADuAke7+dnqjFJFco4qoiIiISONWBEwFfp9g/2DguPDVG3g4/Cn1oOv4Fytt+/TJ8ez+qKTS9uZH9+DIKycdsK20RcpCE0kpVURFpF40lpYDEZFc4+4LzaxrFUWGAL93dwfeNLPDzKyju/87PRE2PrGVTYkjR0aObcw0aq4kLVK8C5v4Ba/8ay+v/GsvNvELbOIXRIp3ZTo0ERGpoUgkgplVemlAD4njKOCjqPUN4TYRaSCy8XO6WkQlaZHCFkQK1f9DRCQXaFAPqQGLs80rFTIbBYwC6NJFrU0i6ZSNn9NVEZWUUDfNr2ycuZFNszZVrJeMDJ75aD+kPR2GdshUWCIiIsnaABwdtd4Z+CS2kLtPB6YDFBQUVKqoiohEU0VUJMU6DO2gCmcOMbPzCUaPzAN+5+6TYvaPAG4JV8uA69z9nfRGKRJDz1JJ3cwGbjSzpwkGKdqq50OlIYoU72LiK19WrNvELwCY0P+grGstbAxUEc1hsaOwaQQ2kboxszzgQWAgQQvBEjOb7e7vRRX7AOjv7v9rZoMJWgc0uqRIA6JJ7w9kZk8BhUA7M9sATACaAbj7NGAuwdQt7xNM3/L9zEQqUrVs7J7amKW0IppEy8EJwKPAacDP3X1yKuNp7DQCm0id9QLed/f1AGHrwBCgoiLq7m9ElX+ToAubiDQgej72QO4+vJr9DtyQpnBEpJFIWUU0yZaD/wBjgYtTFYeISD2KN3JkVa2dPwT+Em+HBvUQSZO6dEtWl2QRkZRJ5fQtFS0H7v4lsL/loIK7f+buS4A9KYxDRKS+JDVyJICZDSCoiN4Sb7+7T3f3AncvaN++fT2GKJKcbBzqX0REckcqu+bWtOVARKShS2rkSDPrCfwOGOzum9MUm0iN6FkqERHJpFRWRJNuOaj2ROrCJiINwxLgODPrBnwMXAFcGV3AzLoAzwPfc/e16Q9RRKqjkTVFRDIvlRXRpFoOkqF5qUSkIXD3cjO7EXiJYBC2Ge7+rpmNDvdPA+4ADgceMjOAcncvyFTMIlKZWoNFRDIvlRXRalsORESyjbvPJZjKIHrbtKjlHwE/SndcIiIiItkkZRXRZFoOzOxIYClwCLDPzMYBJ7n7F6mKS0RERERERDIrpfOIJtFy8CmaY09ERESyxMaZG9k0a1PFesnIEgDaD2lPh6EdMhWWiEjWSWlFVCRXRCIRJk6cWGn7hAkTiEQi6Q9IREQyosPQDqpwiojUA1VERZIQiUSIRCIUFhYCUFxcnNF4RERERESyWZNMByAiIiIiIiKNi1pERSRl9CyViIiIiMSjiqikjSol2aeuz8bqWSoRERERiUcVUUmbrKmURA5NvK90e/VlunWp33gySM/GioiIiEgq6BlRERERERERSStVREVERERERCSt1DVXRL6SqMtxI+uSLCLSmJjZ+cCvgTzgd+4+KWZ/ITAL+CDc9Ly735nOGEUk96giKpKESPEuJr7yZcW6TfwCgAn9DyJS2CJTYYmIiNSJmeUBDwIDgQ3AEjOb7e7vxRR91d0vTHuAIpKzVBEVSUKksIUqnCIikot6Ae+7+3oAM3saGALEVkRFROqVnhEVERERabyOAj6KWt8QbovVx8zeMbO/mNk3453IzEaZ2VIzW7pp06Z4RUREKqhFVEQSUpdkEZGcZ3G2ecz628Ax7l5mZt8BXgCOq3SQ+3RgOkBBQUHsOUREDqCKqIgkpC7JIiI5bwNwdNR6Z+CT6ALu/kXU8lwze8jM2rn752mKUURykLrmioiIiDReS4DjzKybmR0EXAHMji5gZkeamYXLvQg+P25Oe6QiklPUIioiIiLSSLl7uZndCLxEMH3LDHd/18xGh/unAcOA68ysHNgJXOHu6norInWiiqiIiIhII+buc4G5MdumRS1PBaamOy4RyW2qiIqIiIiISNp1Hf/iAetbXnuCra8/VancoX2Hc1i/EQdsK9UQFllPz4iKiIiIiIhIWqlFVEREREREMu6wfiMqtXxK7lKLqIiIiIiIiKSVKqIiIiIiIiKSVqqIioiIiIiISFqpIioiIiIiIiJppcGKRERERERE0iR22hqAT58cz+6PSiptb350D468ctIB23Jl6hpVREVERERERDIotrLZGKgiKiIi0sDp23MREck1qoiKiIhkocb47bmIiOQODVYkIiIiIiIiaaWKqIiIiIiIiKSVKqIiIiIiIiKSVqqISqMQiUQws0qvSCSS6dBERERERBqdlA5WZGbnA78G8oDfufukmP0W7v8OsAMY6e5vpzImyX3xRpfc8trauGWnzF9L0a4Dy2t0SamK8pqI5BrlNRHJhJRVRM0sD3gQGAhsAJaY2Wx3fy+q2GDguPDVG3g4/ClSrw7rN4LD+o3IdBiS5ZTXRCTXKK+JSKaksmtuL+B9d1/v7l8CTwNDYsoMAX7vgTeBw8ysYwpjEhGpC+U1Eck1ymsikhGprIgeBXwUtb4h3FbTMiIiDYXymojkGuU1EcmIVD4janG2eS3KYGajgFHhapmZraljbEmLF2CUdsDniXeX1O3aI6u5egolcWXde0K1v/cU3Xd3oHWc7WVATX6XGtq/+TF1umDtNIa8BlX+W+t3u9bXb6T33sDzGjSs/+/Ka7WUg//Hk79+1buV1xLSvdfq2vWY11JZEd0AHB213hn4pBZlcPfpwPT6DrCuzGypuxdkOo5M0L03vntvrPcdI+fzGjTef+vGet+ge2+s9x5SXsthjfW+QfeeDfeeyq65S4DjzKybmR0EXAHMjikzG7jaAmcCW9393ymMSUSkLpTXRCTXKK+JSEakrEXU3cvN7EbgJYLhwGe4+7tmNjrcPw2YSzAU+PsEw4F/P1XxiIjUlfKaiOQa5TURyZSUziPq7nMJklf0tmlRyw7ckMoYUqxBdj9JE91749NY7/sAjSCvQeP9t26s9w2690ZNeS2nNdb7Bt17g2dBbhERERERERFJj1Q+IyoiIiIiIiJSiSqiSTKzsjjbImb2sZmtMLP3zGx4JmKrT2bWwcyeNLP1ZrbMzBaZ2dCo/b8O77lJ1LaRZuZmdm7UtqHhtmHpvofqmNne8N+sxMz+bGaHVVO+0MzmJFFma3jeFWY238wKzOz+qP1n1eNtpFSi98jMuprZzqj7XBEObiFZSHmtYr/yWuIyymuSdRpDblNei1teeS3L8poqonX3K3fPB4YAvzGzZhmOp9bMzIAXgIXufqy7n04wel7ncH8TYCjBpNbfijl8FRCd1K8A3kl1zLW0093z3b0H8B/q77mXV8Pz5rv7t919qbuPDfcVAlmT2Kj6Pfpn1H3mu/uXGYpRUkd5LaC8prwmuSUncpvyWp0przUQqojWE3dfRzCS3NcyHUsdnAN8GTNAwb/c/YFwdQDBDLgPc2ASA3gV6GVmzcysNfANYEXqQ66zRcBRAGZWbGYF4XI7MyuNLWxmB5vZDDNbYmbLzWxIohPv/2bOzLoCo4Gbwm+kzk7JnaROxXskjYvymvJanLLKa5L1ciC3Ka8pr8WTdXktpaPmNiZmdhqwzt0/y3QsdfBN4O0q9g8HngJmAf9jZs3cfU+4z4H5wCDgUII5x7qlMNY6M7M84FzgkRoc9nPg7+7+g7D7w2Izmx/uO9vMVoTLzwCvA7h7qZlNA8rcfXK9BJ8mCd6jr0fd5+vunu0jKUoCymvKayivSQ7KgdymvFY95bUsyGtqEa27m8xsDfAWEMlwLPXKzB40s3fCb5MOIphD7AV3/4Lgfs+LOeRpgi4eVxAkwIaqZfiLuRloC7xcg2PPA8aHxxcDLYAu4b7orh7/XX/hZkRV71F0V48Gl9SkXiivfUV5TXlNckdO5jbltbiU17Igr6kiWne/cvfuwOXA782sRaYDqoN3gdP2r4T/ac8F2gPnE3xztirsAtGPmO4e7r4Y6AG0c/e1aYq5NnaGz4gcAxzEV/3py/nqdyLRv6MBl0b9Yndx99UpjTYzEr1H0jgor31VXnktdyivSa7kNuU15bX9sjqvqSJaT9z9eWApcE2mY6mDvwMtzOy6qG2twp/DgR+5e1d370rQjeM8M2sVc45bgdtSHmk9cPetwFjg5nDAglLg9HB3otHjXgLGhAMFYGanJnm5bUCb2kebGXHeI2lElNcqKK/Fp7wmWSkHcpvymvLaAbI1r6kimrxWZrYh6vWTOGXuBH5iUUNlZxN3d+BioL+ZfWBmi4HHgAkEzxK8GFV2O/Aa8N2Yc/zF3RekLeg6cvflBKPFXQFMBq4zszeAdgkOuQtoBqw0s5JwPRl/BoZm48PvMe+R5BblNeU1UF6T3JPTuU15TXktnmzMaxb8XxYRERERERFJj6z7FkhERERERESymyqiIiIiIiIiklaqiIqIiIiIiEhaqSIqIiIiIiIiaaWKqIiIiIiIiKSVKqIiIiIiIiKSVqqIioiIiIiISFqpIioiIiIiIiJp9f8Day3zfrc+ENEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1133.86x283.465 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax2, ax1, ax3) = plt.subplots(1, 3, sharey=False, sharex=True)\n",
    "fig.set_size_inches(cm2inch(40, 10))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(df_extrafull))\n",
    "ax1.bar(ind-width, df_interfull[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=df_interfull[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, df_interfull[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=df_interfull[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, df_extrafull[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=df_extrafull[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error, unreal_extra_full_info_error]\n",
    "inter_error_name = ['uninfo', 'unreal_inter', 'unreal_extra']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax1.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax1.set_title('Mixed phase error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "\n",
    "ax2.bar(ind-width, df_inter_average[f'mean_train_error'], width=width, label='inter_train', \n",
    "        yerr=df_inter_average[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, df_inter_average[f'mean_test_error'], width=width, label='inter_test',\n",
    "        yerr=df_inter_average[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, df_extra_average[f'mean_test_error'], width=width, label='extra_test',\n",
    "        yerr=df_extra_average[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "\n",
    "ax2.set_title('Pure phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax2.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_avg_uninfo_error, unreal_inter_avg_info_error, unreal_extra_avg_info_error]\n",
    "avg_error_name = ['uninfo', 'unreal_inter', 'unreal_extra']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax2.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax2.legend(fontsize=fontsize)\n",
    "\n",
    "ax3.bar(ind-width, df_interfull[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "        yerr=df_interfull[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, df_interfull[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "        yerr=df_interfull[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, df_extrafull[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "        yerr=df_extrafull[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [inter_full_uninfo_loss, unreal_inter_full_info_loss, unreal_extra_full_info_loss]\n",
    "full_loss_name = ['uninfo', 'unreal_inter', 'unreal_extra']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Mixed sphase logloss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "\n",
    "# ax4.bar(ind-width, df_inter_average[f'mean_train_log loss'], width=width, label='inter_train', \n",
    "#         yerr=df_inter_average[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "# ax4.bar(ind, df_inter_average[f'mean_test_log loss'], width=width, label='inter_test',\n",
    "#         yerr=df_inter_average[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "# ax4.bar(ind+width, df_extra_average[f'mean_test_log loss'], width=width, label='extra_test',\n",
    "#         yerr=df_extra_average[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "\n",
    "# avg_loss_base = [inter_avg_uninfo_loss, real_inter_avg_info_loss, real_extra_avg_info_loss]\n",
    "# avg_loss_name = ['uninfo', 'real_inter', 'real_extra']\n",
    "# for i in range(len(avg_loss_base)):\n",
    "#     ax4.axhline(y=avg_loss_base[i], color=colors[i], linestyle='-', label=avg_loss_name[i])\n",
    "\n",
    "# ax4.set_title('Individual sphase average logloss', fontsize=fontsize)\n",
    "# ax4.set_xticks(ind)\n",
    "# ax4.set_xticklabels(df_extrafull.index, fontsize=fontsize)\n",
    "# ax4.set_ylabel('logloss', fontsize=fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
