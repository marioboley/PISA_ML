{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook considers:\n",
    "1. __data.x2__ in data.py. It contains 69 features (initiator exclusive). \n",
    "2. From the result, we can find there is no difference with manual selected 23 features. We don't generate features in this notebook but we get rules for 23 features.\n",
    "3. In this notebook, we compare the prediction order (sphere, worm, vesicle, other) with (vesicle, worm, sphere, other). There is no difference between select variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data1 as data\n",
    "import random\n",
    "from common import *\n",
    "from rules import *\n",
    "from realkd.patch import RuleFit\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full phase prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from multilabel import BinaryRelevanceClassifier, ProbabilisticClassifierChain\n",
    "from gam import LogisticGAM\n",
    "\n",
    "STATE = np.random.RandomState(seed=1000)\n",
    "\n",
    "lr = LogisticRegressionCV(penalty='l1', solver='saga', random_state=STATE)\n",
    "lr_ind = BinaryRelevanceClassifier(lr)\n",
    "lr_chain = ClassifierChain(lr, order=[0, 2, 1, 3])\n",
    "lr_pcc = ProbabilisticClassifierChain(lr) \n",
    "\n",
    "# gams not fixed, remove this part.\n",
    "# gam_ind = BinaryRelevanceClassifier(LogisticGAM(lam=20.0, max_iter=250))\n",
    "# gam_chain = ClassifierChain(LogisticGAM(lam=20.0, max_iter=250))\n",
    "# gam_pcc = ProbabilisticClassifierChain(LogisticGAM(lam=20.0, max_iter=250)) \n",
    "\n",
    "rf = RandomForestClassifier(random_state=STATE, min_samples_leaf=1, n_estimators=100)\n",
    "rf_ind = BinaryRelevanceClassifier(rf)\n",
    "rf_chain = ClassifierChain(rf, order=[0, 2, 1, 3])\n",
    "rf_pcc = ProbabilisticClassifierChain(rf)\n",
    "\n",
    "# Rulefit\n",
    "rufit_pcc = RuleFitWrapper(mode='chain')\n",
    "\n",
    "full_estimators = [lr_ind, lr_pcc, lr_chain, rf_ind, rf_pcc, rf_chain, rufit_pcc]\n",
    "full_names = ['LR_ind', 'LR_pcc', 'LR_chain', 'RanF_ind', 'RanF_pcc', 'Ranf_chain', 'Rufit_pcc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following code under \"2.6 GHz 6-Core Intel Core i7\" runs ~5 hours. You can simply use saved result to re-run the result. (See below instructions)\n",
    "\n",
    "```\n",
    "import pickle\n",
    "cur_save=open('./' + 'interpolation_30folder' + '.p', 'rb')\n",
    "interpolation = pickle.load(cur_save)\n",
    "```\n",
    "After running these three-line code, you can ignore the following __interpolation__ code and re-run the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the individual prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Prediction Order is: ['sphere', 'worm', 'vesicle', 'other']\n",
      "Num of predictors:,  23\n",
      "Running experiment with 30 repetitions\n",
      "======================================\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "from common import Experiment, LogLikelihoodEvaluator\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"Current Prediction Order is:\", data.y.columns.tolist())\n",
    "print('Num of predictors:, ', data.x1.shape[1])\n",
    "interpolation = Experiment(full_estimators, \n",
    "                    full_names,\n",
    "                    KFold(30, shuffle=True, random_state=STATE),\n",
    "                    data.x1, data.y.replace(-1.0, 0.0),\n",
    "                    groups=data.comp_ids.array, \n",
    "                    evaluators=['accuracy', LogLikelihoodEvaluator(2, neg=True)],\n",
    "                    verbose=True).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('interpolation_select_swvo.pkl', 'wb') as f:   \n",
    "#     pickle.dump(interpolation, f)\n",
    "\n",
    "import pickle\n",
    "cur_save=open('./' + 'interpolation_select_swvo' + '.pkl', 'rb')\n",
    "interpolation = pickle.load(cur_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rules\n",
    "def loss(y_test, y_pred):\n",
    "    y_test = y_test.astype(np.float16)\n",
    "    y_pred = y_pred.astype(np.float16)\n",
    "    if len(y_test.shape) == 1:\n",
    "        N = y_test.shape[0]\n",
    "        loss = 0\n",
    "        for i in range(N):\n",
    "            loss -= ((y_test[i]*np.log(y_pred[i]))+((1.0-y_test[i])*np.log(1.0-y_pred[i])))\n",
    "            loss = loss/N\n",
    "    else:\n",
    "        N,M = y_test.shape\n",
    "        a=[]\n",
    "        for m in range(M):\n",
    "            loss=0\n",
    "            for i in range(N):\n",
    "                subloss = ((y_test[i,m]*np.log(y_pred[i,m]))+((1.0-y_test[i,m])*np.log(1.0-y_pred[i,m])))\n",
    "                if np.isnan(subloss):\n",
    "                    continue\n",
    "                loss -= subloss\n",
    "            loss = loss/N\n",
    "            a.append(round(loss,8))\n",
    "        loss = np.mean(a)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best RuleFit\n",
    "lst = []\n",
    "for each in interpolation.fitted_['Rufit_pcc']:\n",
    "    pred = each.predict_proba(data.x)\n",
    "    res = log_loss(data.y.values, pred)\n",
    "    lst.append((res, each))\n",
    "lst.sort()\n",
    "best_rf = lst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = best_rf.get_rules(data.x, data.y)\n",
    "indx = -1\n",
    "for key, values in dic.items():\n",
    "    indx += 1\n",
    "    name = 'Rules/Full_Phase/Interpolation/'+ str(indx) + \"_sel_swvo_\" + key + '.csv'\n",
    "    values.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
