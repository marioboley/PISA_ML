{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to find project root directory by chaning to parent directory\n",
      "all good\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('common.py'):\n",
    "    print('trying to find project root directory by chaning to parent directory')\n",
    "    os.chdir('..')\n",
    "if os.path.exists('common.py'):\n",
    "    print('all good')\n",
    "else:\n",
    "    print('could not find project root directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import data\n",
    "from common import OUTPUTPATH\n",
    "from modules.experiments import KFold, GroupKFoldSpecial\n",
    "STATE = np.random.RandomState(seed=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr</th>\n",
       "      <td>0.183269</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.201535</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>0.474907</td>\n",
       "      <td>0.028398</td>\n",
       "      <td>0.513421</td>\n",
       "      <td>0.131641</td>\n",
       "      <td>2.073205</td>\n",
       "      <td>0.085173</td>\n",
       "      <td>2.159589</td>\n",
       "      <td>0.388495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM</th>\n",
       "      <td>0.038438</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.043192</td>\n",
       "      <td>0.127604</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.264649</td>\n",
       "      <td>0.121913</td>\n",
       "      <td>0.631576</td>\n",
       "      <td>0.040820</td>\n",
       "      <td>1.278009</td>\n",
       "      <td>0.602032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit</th>\n",
       "      <td>0.010961</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>0.037165</td>\n",
       "      <td>0.035087</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.182281</td>\n",
       "      <td>0.093626</td>\n",
       "      <td>0.267426</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>0.989179</td>\n",
       "      <td>0.660852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.060439</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.192632</td>\n",
       "      <td>0.098014</td>\n",
       "      <td>0.237679</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>1.038604</td>\n",
       "      <td>0.709325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr                    0.183269                0.007191   \n",
       "GAM                   0.038438                0.003724   \n",
       "RuFit                 0.010961                0.002383   \n",
       "RF                    0.000227                0.000390   \n",
       "\n",
       "       mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr                   0.201535               0.049730          0.474907   \n",
       "GAM                  0.085000               0.043192          0.127604   \n",
       "RuFit                0.063092               0.037165          0.035087   \n",
       "RF                   0.060439               0.035364          0.000483   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  mean_train_log loss  \\\n",
       "Lr            0.028398         0.513421        0.131641             2.073205   \n",
       "GAM           0.012400         0.264649        0.121913             0.631576   \n",
       "RuFit         0.007635         0.182281        0.093626             0.267426   \n",
       "RF            0.000815         0.192632        0.098014             0.237679   \n",
       "\n",
       "       std_train_log loss  mean_test_log loss  std_test_log loss  \n",
       "Lr               0.085173            2.159589           0.388495  \n",
       "GAM              0.040820            1.278009           0.602032  \n",
       "RuFit            0.028055            0.989179           0.660852  \n",
       "RF               0.004404            1.038604           0.709325  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation = pd.read_csv(os.path.join(OUTPUTPATH, 'no_assemble_interpolation.csv'))\n",
    "interpolation = interpolation.set_index('Unnamed: 0')\n",
    "interpolation.index.name = None\n",
    "interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_hamming loss</th>\n",
       "      <th>std_train_hamming loss</th>\n",
       "      <th>mean_test_hamming loss</th>\n",
       "      <th>std_test_hamming loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lr_pcc</th>\n",
       "      <td>0.183836</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.178331</td>\n",
       "      <td>0.479947</td>\n",
       "      <td>0.029754</td>\n",
       "      <td>0.499150</td>\n",
       "      <td>0.454198</td>\n",
       "      <td>2.088094</td>\n",
       "      <td>0.096015</td>\n",
       "      <td>2.670335</td>\n",
       "      <td>1.991078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM_pcc</th>\n",
       "      <td>0.039552</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.134332</td>\n",
       "      <td>0.174609</td>\n",
       "      <td>0.130201</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.327829</td>\n",
       "      <td>0.397306</td>\n",
       "      <td>0.625013</td>\n",
       "      <td>0.044157</td>\n",
       "      <td>2.668734</td>\n",
       "      <td>3.636575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuFit_pcc</th>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.162652</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.353297</td>\n",
       "      <td>0.414054</td>\n",
       "      <td>0.263414</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>2.316536</td>\n",
       "      <td>3.425546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_pcc</th>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.112563</td>\n",
       "      <td>0.184935</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.236691</td>\n",
       "      <td>0.367998</td>\n",
       "      <td>0.233382</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>1.504354</td>\n",
       "      <td>1.727774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_hamming loss  std_train_hamming loss  \\\n",
       "Lr_pcc                    0.183836                0.008626   \n",
       "GAM_pcc                   0.039552                0.002979   \n",
       "RuFit_pcc                 0.010858                0.002180   \n",
       "RF_pcc                    0.000094                0.000277   \n",
       "\n",
       "           mean_test_hamming loss  std_test_hamming loss  mean_train_error  \\\n",
       "Lr_pcc                   0.183400               0.178331          0.479947   \n",
       "GAM_pcc                  0.134332               0.174609          0.130201   \n",
       "RuFit_pcc                0.162652               0.202399          0.034836   \n",
       "RF_pcc                   0.112563               0.184935          0.000188   \n",
       "\n",
       "           std_train_error  mean_test_error  std_test_error  \\\n",
       "Lr_pcc            0.029754         0.499150        0.454198   \n",
       "GAM_pcc           0.009977         0.327829        0.397306   \n",
       "RuFit_pcc         0.005773         0.353297        0.414054   \n",
       "RF_pcc            0.000553         0.236691        0.367998   \n",
       "\n",
       "           mean_train_log loss  std_train_log loss  mean_test_log loss  \\\n",
       "Lr_pcc                2.088094            0.096015            2.670335   \n",
       "GAM_pcc               0.625013            0.044157            2.668734   \n",
       "RuFit_pcc             0.263414            0.022423            2.316536   \n",
       "RF_pcc                0.233382            0.003507            1.504354   \n",
       "\n",
       "           std_test_log loss  \n",
       "Lr_pcc              1.991078  \n",
       "GAM_pcc             3.636575  \n",
       "RuFit_pcc           3.425546  \n",
       "RF_pcc              1.727774  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrapolation = pd.read_csv(os.path.join(OUTPUTPATH, 'no_assemble_extrapolation.csv'))\n",
    "extrapolation = extrapolation.set_index('Unnamed: 0')\n",
    "extrapolation.index.name = None\n",
    "extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_summary(metric, summ, num_reps=30, baseline=None, names=None, colors = list(mcolors.BASE_COLORS.keys())):\n",
    "    width = 0.35\n",
    "    ind = np.arange(len(summ))\n",
    "    plt.bar(ind-width/2, summ[f'mean_train_{metric}'], width=width, label='train', \n",
    "            yerr=summ[f'std_train_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    plt.bar(ind+width/2, summ[f'mean_test_{metric}'], width=width, label='test',\n",
    "            yerr=summ[f'std_test_{metric}']/num_reps**0.5, capsize=3.0)\n",
    "    if baseline:\n",
    "        for i in range(len(baseline)):\n",
    "            plt.axhline(y=baseline[i], color=colors[i], linestyle='-', label=names[i])\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.xticks(ind, summ.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_loss(_train, _test):\n",
    "    \"\"\"This is calculate realistic full phase error\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if (test_uniq[i] == _select).all():\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)\n",
    "\n",
    "def get_hamming_loss(_train, _test, name):\n",
    "    \"\"\"This is calculate realistic hamming loss\n",
    "    \"\"\"\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    _select = train_uniq[list(train_cnt).index(max(train_cnt))]\n",
    "\n",
    "    acc_cnt = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        if test_uniq[i] == _select:\n",
    "            acc_cnt += test_cnt[i]\n",
    "    return 1-acc_cnt/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full sphase error base line:\n",
      "Unreal inform error:0.5761821366024518 \n",
      "Uninform error:0.9375\n"
     ]
    }
   ],
   "source": [
    "# interpolation full phase\n",
    "uniq, cnts = np.unique(data.y.values, return_counts=True, axis=0)\n",
    "unreal_inter_full_info_error = 1 - max(cnts)/sum(cnts)\n",
    "inter_full_uninfo_error = 1 - (1/2)**4\n",
    "print('Interpolation full sphase error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_full_info_error, inter_full_uninfo_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is interpolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.2806479859894921 \n",
      "Uninform error:0.5\n"
     ]
    }
   ],
   "source": [
    "# interpolation hamming loss\n",
    "unreal_inter_hamming_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    error = 1 - max(cnt)/sum(cnt)\n",
    "    unreal_inter_hamming_loss.append(error)\n",
    "unreal_inter_hamming_loss = np.mean(unreal_inter_hamming_loss)\n",
    "inter_uninfo_hamming_loss = np.mean([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{} \\nUninform error:{}'.format(unreal_inter_hamming_loss, inter_uninfo_hamming_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed full phase loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Unreal inform error:0.5026709401709402\n"
     ]
    }
   ],
   "source": [
    "# extrapolation full phase loss\n",
    "unreal_extra_full_info_error = []\n",
    "cnt =0\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    unreal_extra_full_info_error.append(get_full_loss(train, test))\n",
    "unreal_extra_full_info_error = np.mean(unreal_extra_full_info_error)\n",
    "unreal_extra_full_info_error\n",
    "print('Extrapolation full sphase error base line:\\nUnreal inform error:{}'.format(unreal_extra_full_info_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extrapolation unreal and uniformed hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average sphases error base line:\n",
      "Unreal inform error:0.24853395061728398\n"
     ]
    }
   ],
   "source": [
    "# extrapolation hamming loss\n",
    "unreal_extra_hamming_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "        unreal_extra_hamming_loss.append(get_hamming_loss(data.y.index.tolist(), test, each.name))\n",
    "unreal_extra_hamming_loss = np.mean(unreal_extra_hamming_loss)\n",
    "print('Interpolation average sphases error base line:\\nUnreal inform error:{}'.format(unreal_extra_hamming_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def neglikehood(p, y):\n",
    "    result = (-math.log2(p)*y - (1-y)*math.log2(1-p))\n",
    "    return (result)\n",
    "\n",
    "def get_full_logs(_train, _test):\n",
    "    train_uniq, train_cnt = np.unique(data.y[data.y.index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = [list(each) for each in train_uniq]\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[data.y.index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = [list(each) for each in test_uniq]\n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)\n",
    "\n",
    "def get_hamming_logs(_train, _test, name):\n",
    "    train_uniq, train_cnt = np.unique(data.y[name][data.y[name].index.isin(_train)].values, return_counts=True, axis=0)\n",
    "    train_uniq = train_uniq.tolist()\n",
    "    train_prob = train_cnt/sum(train_cnt)\n",
    "    \n",
    "    test_uniq, test_cnt = np.unique(data.y[name][data.y[name].index.isin(_test)], return_counts=True, axis=0)\n",
    "    test_uniq = test_uniq.tolist()\n",
    "    \n",
    "    logs = 0\n",
    "    for i in range(len(test_uniq)):\n",
    "        try:\n",
    "            indx = train_uniq.index(test_uniq[i])\n",
    "            logs += -1* test_cnt[i] * math.log2(train_prob[indx])\n",
    "        except:\n",
    "            pass\n",
    "    return logs/sum(test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation full phase logloss base line:\n",
      " Unreal Inform error:  2.3860728197730245\n"
     ]
    }
   ],
   "source": [
    "# unrealistic interpolation\n",
    "uniq, cnt = np.unique(data.y.values, axis=0, return_counts=True)\n",
    "prob = cnt/sum(cnt)\n",
    "\n",
    "unreal_inter_full_info_loss = 0\n",
    "for each in cnt:\n",
    "    unreal_inter_full_info_loss += -each * math.log2(each/sum(cnt))\n",
    "unreal_inter_full_info_loss = unreal_inter_full_info_loss/sum(cnt)\n",
    "print(\"Interpolation full phase logloss base line:\\n Unreal Inform error: \", unreal_inter_full_info_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation average morphology logloss base line:\n",
      "Unreal Inform logloss:0.7462898274008147\n"
     ]
    }
   ],
   "source": [
    "# interpolation average sphase informed\n",
    "unreal_inter_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_inter_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_inter_avg_info_loss = np.mean(unreal_inter_avg_info_loss)\n",
    "print('Interpolation average morphology logloss base line:\\nUnreal Inform logloss:{}'.format(unreal_inter_avg_info_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation full sphase error base line:\n",
      "Real Inform logloss:2.4879044454190025 \n",
      "Uninform logloss:4.0\n"
     ]
    }
   ],
   "source": [
    "real_extra_full_info_loss = []\n",
    "for train, test in GroupKFoldSpecial(len(set(data.comp_ids)), size=20).split(data.x1, data.y, data.comp_ids):\n",
    "    real_extra_full_info_loss.append(get_full_logs(train, test))\n",
    "real_extra_full_info_loss = np.mean(real_extra_full_info_loss)\n",
    "\n",
    "extra_full_uninfo_loss = -math.log2(0.5**4)\n",
    "\n",
    "print('Extrapolation full sphase error base line:\\nReal Inform logloss:{} \\nUninform logloss:{}'.format(real_extra_full_info_loss, extra_full_uninfo_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrapolation average sphase error base line:\n",
      "Real Inform logloss:0.7462898274008147\n"
     ]
    }
   ],
   "source": [
    "unreal_extra_avg_info_loss = []\n",
    "for each in [data.sphere, data.vesicle, data.worm, data.other]:\n",
    "    uniq, cnt = np.unique(each, return_counts=True)\n",
    "    prob = max(cnt)/sum(cnt) if uniq[list(cnt).index(max(cnt))] else 1- max(cnt)/sum(cnt)\n",
    "    \n",
    "    for indx in range(len(each)):\n",
    "        unreal_extra_avg_info_loss.append(neglikehood(prob, each[indx]))\n",
    "unreal_extra_avg_info_loss = np.mean(unreal_extra_avg_info_loss)\n",
    "print('Extrapolation average sphase error base line:\\nReal Inform logloss:{}'.format(unreal_extra_avg_info_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'c', 'm', 'y', 'b']\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, sharex=True, figsize=(20, 5))\n",
    "\n",
    "width = 0.25\n",
    "fontsize = 10\n",
    "ind = np.arange(len(interpolation))\n",
    "\n",
    "ax1.bar(ind-width, interpolation[f'mean_train_hamming loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind, interpolation[f'mean_test_hamming loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_hamming loss']/30**0.5, capsize=3.0)\n",
    "ax1.bar(ind+width, extrapolation[f'mean_test_hamming loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_hamming loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "ax1.set_title('Individual morphology error rate', fontsize=fontsize)\n",
    "ax1.set_xticks(ind)\n",
    "ax1.set_ylabel('Error rate', fontsize=fontsize)\n",
    "ax1.set_xticklabels(interpolation.index, fontsize=fontsize)\n",
    "\n",
    "# add base line\n",
    "avg_error_base = [inter_uninfo_hamming_loss, unreal_inter_hamming_loss]\n",
    "avg_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(avg_error_base)):\n",
    "    ax1.axhline(y=avg_error_base[i], color=colors[i], linestyle='-', label=avg_error_name[i])\n",
    "\n",
    "ax1.legend(fontsize=fontsize)\n",
    "ax1.sharey(ax2) ########### here to share the y axis\n",
    "\n",
    "ax2.bar(ind-width, interpolation[f'mean_train_error'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind, interpolation[f'mean_test_error'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_error']/30**0.5, capsize=3.0)\n",
    "ax2.bar(ind+width, extrapolation[f'mean_test_error'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_error']/28**0.5, capsize=3.0)\n",
    "\n",
    "# add base line\n",
    "inter_error_base = [inter_full_uninfo_error, unreal_inter_full_info_error]\n",
    "inter_error_name = ['uninformed', 'informed']\n",
    "for i in range(len(inter_error_base)):\n",
    "    ax2.axhline(y=inter_error_base[i], color=colors[i], linestyle='-', label=inter_error_name[i])\n",
    "\n",
    "ax2.set_title('Full phase error rate', fontsize=fontsize)\n",
    "ax2.set_xticks(ind)\n",
    "ax2.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax2.sharey(ax1) ########### here to share the y axis\n",
    "\n",
    "\n",
    "ax3.bar(ind-width, interpolation[f'mean_train_log loss'], width=width, label='training', \n",
    "        yerr=interpolation[f'std_train_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind, interpolation[f'mean_test_log loss'], width=width, label='interpolation',\n",
    "        yerr=interpolation[f'std_test_log loss']/30**0.5, capsize=3.0)\n",
    "ax3.bar(ind+width, extrapolation[f'mean_test_log loss'], width=width, label='extrapolation',\n",
    "        yerr=extrapolation[f'std_test_log loss']/28**0.5, capsize=3.0)\n",
    "\n",
    "full_loss_base = [4, unreal_inter_full_info_loss]\n",
    "full_loss_name = ['uninformed', 'informed']\n",
    "for i in range(len(full_loss_base)):\n",
    "    ax3.axhline(y=full_loss_base[i], color=colors[i], linestyle='-', label=full_loss_name[i])\n",
    "\n",
    "ax3.set_title('Log loss', fontsize=fontsize)\n",
    "ax3.set_xticks(ind)\n",
    "ax3.set_xticklabels(extrapolation.index, fontsize=fontsize)\n",
    "ax3.set_ylabel('logloss', fontsize=fontsize)\n",
    "plt.savefig(os.path.join(OUTPUTPATH, 'no_assemble_overall_performance.pdf'), bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corona_GMA, core_HEMA has no morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
