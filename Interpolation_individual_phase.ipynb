{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook considers: Interpolation\n",
    "\n",
    "1. __data.x1__ in data.py. It contains 23 features (initiator exclusive). \n",
    "2. From the result, we can find there is no difference with manual selected 23 features. We don't generate features in this notebook but we get rules for 23 features.\n",
    "3. In this notebook, we compare the prediction order (sphere, worm, vesicle, other) with (vesicle, worm, sphere, other). There is no difference between select variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path is a list of absolute path strings\n",
    "sys.path.append('./Script')\n",
    "\n",
    "import data1 as data\n",
    "import random\n",
    "from common import *\n",
    "from rules import *\n",
    "from realkd.patch import RuleFit\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolorss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from multilabel import BinaryRelevanceClassifier, ProbabilisticClassifierChain\n",
    "\n",
    "STATE = np.random.RandomState(seed=1000)\n",
    "\n",
    "lr = LogisticRegressionCV(penalty='l1', solver='saga', random_state=STATE)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=STATE, min_samples_leaf=1, n_estimators=100)\n",
    "\n",
    "# Rulefit\n",
    "rufit = RuleFitWrapper()\n",
    "\n",
    "indi_estimators = [lr, rf, rufit]\n",
    "indi_names = ['LR', 'Rf', 'Rufit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of predictors:,  23\n",
      "Target:  sphere\n",
      "Running experiment with 30 repetitions\n",
      "======================================\n",
      "******************************\n",
      "\n",
      "Target:  worm\n",
      "Running experiment with 30 repetitions\n",
      "======================================\n",
      "******************************\n",
      "\n",
      "Target:  vesicle\n",
      "Running experiment with 30 repetitions\n",
      "======================================\n",
      "******************************\n",
      "\n",
      "Target:  other\n",
      "Running experiment with 30 repetitions\n",
      "======================================\n",
      "******************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from common import Experiment, LogLikelihoodEvaluator\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "inter_no_comp = {}\n",
    "\n",
    "print('Num of predictors:, ', data.x1.shape[1])\n",
    "for y in [data.sphere, data.worm, data.vesicle, data.other]:\n",
    "    print('Target: ',y.name)\n",
    "    experiment = Experiment(indi_estimators, \n",
    "                        indi_names,\n",
    "                        KFold(30, shuffle=True, random_state=STATE),\n",
    "                        data.x1, y.replace(-1, 0),\n",
    "                        groups=data.comp_ids.array, \n",
    "                        evaluators=['accuracy', LogLikelihoodEvaluator(base=2)],\n",
    "                        verbose=True, file_name='interpolation_indi')\n",
    "    inter_no_comp[y.name] = experiment.run()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('interpolation_indi_phase.pkl', 'wb') as f:   \n",
    "#     pickle.dump(inter_no_comp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_no_comp_df = {}\n",
    "for key in inter_no_comp:\n",
    "    df = inter_no_comp[key].summary()\n",
    "    df['mean_train_error'] = 1- df['mean_train_accuracy']\n",
    "    df['std_train_error'] = df['std_train_accuracy']\n",
    "    df['mean_test_error'] = 1- df['mean_test_accuracy']\n",
    "    df['std_test_error'] = df['std_test_accuracy']\n",
    "    inter_no_comp_df[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_columns = {\"mean_train_log likelihood\": 'mean_train_log loss', \n",
    "                  'std_train_log likelihood': 'std_train_log loss',\n",
    "                  'mean_test_log likelihood': 'mean_test_log loss',\n",
    "                  'std_test_log likelihood': 'std_test_log loss'} # chang log likelihood to log loss\n",
    "\n",
    "for each in inter_no_comp_df:\n",
    "    inter_no_comp_df[each] = inter_no_comp_df[each].rename(change_columns, axis=1)\n",
    "    inter_no_comp_df[each]['mean_train_log loss'] = -1*inter_no_comp_df[each]['mean_train_log loss']\n",
    "    inter_no_comp_df[each]['mean_test_log loss'] = -1*inter_no_comp_df[each]['mean_test_log loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>joint</th>\n",
       "      <td>0.642335</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.581140</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>1.049974</td>\n",
       "      <td>0.034620</td>\n",
       "      <td>1.699951</td>\n",
       "      <td>1.359898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sphere</th>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.844386</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.350696</td>\n",
       "      <td>0.029128</td>\n",
       "      <td>0.409624</td>\n",
       "      <td>0.069212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vesicle</th>\n",
       "      <td>0.882548</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.857368</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.262162</td>\n",
       "      <td>0.013190</td>\n",
       "      <td>0.316949</td>\n",
       "      <td>0.038933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worm</th>\n",
       "      <td>0.816908</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.787719</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.445646</td>\n",
       "      <td>0.010360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.986697</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.971053</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.035516</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.527731</td>\n",
       "      <td>1.230176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "joint               0.642335            0.001623            0.581140   \n",
       "sphere              0.862069            0.003167            0.844386   \n",
       "vesicle             0.882548            0.002433            0.857368   \n",
       "worm                0.816908            0.002272            0.787719   \n",
       "other               0.986697            0.001604            0.971053   \n",
       "\n",
       "         std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "joint             0.000786             1.049974            0.034620   \n",
       "sphere            0.002025             0.350696            0.029128   \n",
       "vesicle           0.001625             0.262162            0.013190   \n",
       "worm              0.001638             0.401600            0.004016   \n",
       "other             0.001181             0.035516            0.009613   \n",
       "\n",
       "         mean_test_log loss  std_test_log loss  \n",
       "joint              1.699951           1.359898  \n",
       "sphere             0.409624           0.069212  \n",
       "vesicle            0.316949           0.038933  \n",
       "worm               0.445646           0.010360  \n",
       "other              0.527731           1.230176  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gam = pd.read_csv('inter_GAM_result.csv')\n",
    "df_gam = df_gam.rename(columns = {'mean_train_logloss': 'mean_train_log loss',\n",
    "                        'std_train_logloss': 'std_train_log loss',\n",
    "                        'mean_test_logloss': 'mean_test_log loss',\n",
    "                        'std_test_logloss': 'std_test_log loss'})\n",
    "df_gam.set_index('Unnamed: 0', inplace=True)\n",
    "df_gam.index.name = None\n",
    "df_gam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in inter_no_comp_df:\n",
    "    temp = df_gam[df_gam.index == key]\n",
    "    temp = temp.rename(index={key: 'Gam'})\n",
    "    inter_no_comp_df[key] = pd.concat([inter_no_comp_df[key], temp])\n",
    "    \n",
    "    inter_no_comp_df[key]['mean_train_error'] = 1-inter_no_comp_df[key]['mean_train_accuracy']\n",
    "    inter_no_comp_df[key]['std_train_error'] = inter_no_comp_df[key]['std_train_accuracy']\n",
    "    inter_no_comp_df[key]['mean_test_error'] = 1-inter_no_comp_df[key]['mean_test_accuracy']\n",
    "    inter_no_comp_df[key]['std_test_error'] = inter_no_comp_df[key]['std_test_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "dic = dict(zip(inter_no_comp_df['sphere'].columns.tolist(), \n",
    "               [[] for _ in range(len(inter_no_comp_df['sphere'].columns.tolist()))]))\n",
    "model_dic = dict(zip(['LR', 'Rf', 'Rufit', 'Gam'], [deepcopy(dic) for _ in range(4)]))\n",
    "\n",
    "for key in inter_no_comp_df:\n",
    "    for col in inter_no_comp_df[key]:\n",
    "        for indx in ['LR', 'Rf', 'Rufit', 'Gam']:\n",
    "            model_dic[indx][col].append(inter_no_comp_df[key][col][indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in model_dic:\n",
    "    for col in model_dic[key]:\n",
    "        model_dic[key][col] = np.mean(model_dic[key][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_df = pd.DataFrame(model_dic).T\n",
    "average_df = average_df.reindex(['LR', 'Gam', 'Rufit', 'Rf'])\n",
    "\n",
    "average_df.to_csv('inter_average_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_log loss</th>\n",
       "      <th>std_train_log loss</th>\n",
       "      <th>mean_test_log loss</th>\n",
       "      <th>std_test_log loss</th>\n",
       "      <th>mean_train_error</th>\n",
       "      <th>std_train_error</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.713231</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.712061</td>\n",
       "      <td>0.092212</td>\n",
       "      <td>0.727174</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.128536</td>\n",
       "      <td>0.286769</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.287939</td>\n",
       "      <td>0.092212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gam</th>\n",
       "      <td>0.887055</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.262494</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>0.424988</td>\n",
       "      <td>0.337170</td>\n",
       "      <td>0.112945</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.134868</td>\n",
       "      <td>0.001617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufit</th>\n",
       "      <td>0.989501</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.923553</td>\n",
       "      <td>0.058483</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.279032</td>\n",
       "      <td>0.207822</td>\n",
       "      <td>0.010499</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.076447</td>\n",
       "      <td>0.058483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rf</th>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.932851</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.286925</td>\n",
       "      <td>0.336166</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.067149</td>\n",
       "      <td>0.054240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "LR                0.713231            0.004747            0.712061   \n",
       "Gam               0.887055            0.002369            0.865132   \n",
       "Rufit             0.989501            0.002760            0.923553   \n",
       "Rf                0.999898            0.000188            0.932851   \n",
       "\n",
       "       std_test_accuracy  mean_train_log loss  std_train_log loss  \\\n",
       "LR              0.092212             0.727174            0.004368   \n",
       "Gam             0.001617             0.262494            0.013987   \n",
       "Rufit           0.058483             0.085185            0.004568   \n",
       "Rf              0.054240             0.064982            0.001980   \n",
       "\n",
       "       mean_test_log loss  std_test_log loss  mean_train_error  \\\n",
       "LR               0.732412           0.128536          0.286769   \n",
       "Gam              0.424988           0.337170          0.112945   \n",
       "Rufit            0.279032           0.207822          0.010499   \n",
       "Rf               0.286925           0.336166          0.000102   \n",
       "\n",
       "       std_train_error  mean_test_error  std_test_error  \n",
       "LR            0.004747         0.287939        0.092212  \n",
       "Gam           0.002369         0.134868        0.001617  \n",
       "Rufit         0.002760         0.076447        0.058483  \n",
       "Rf            0.000188         0.067149        0.054240  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
